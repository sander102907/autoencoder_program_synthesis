{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "131072"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import json\n",
    "import csv\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import sys\n",
    "sys.path.append(\"utils/\")\n",
    "from datasets.AstDataset import AstDataset\n",
    "from utils.TreeLstmUtils import batch_tree_input\n",
    "from utils.TreePlotter import TreePlotter\n",
    "from models.Vae import Vae\n",
    "from loss_functions.TreeVaeLoss import TreeVaeLoss, TreeVaeLossComplete\n",
    "from utils.TreeNode import Node\n",
    "from anytree.exporter import JsonExporter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = torch.device(\"cpu\")\n",
    "csv.field_size_limit(sys.maxsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HYPERPARAMETERS\n",
    "params = {\n",
    "    'LEAF_EMBEDDING_DIM': 100,\n",
    "    'EMBEDDING_DIM': 30,\n",
    "    'HIDDEN_SIZE': 512,\n",
    "    'LATENT_DIM': 512,\n",
    "    'LEARNING_RATE': 0.005,\n",
    "    'EPOCHS': 10,\n",
    "    'BATCH_SIZE': 1,\n",
    "    'NUM_WORKERS': 0,\n",
    "    'CLIP': 5,\n",
    "    'KL_LOSS_WEIGHT': 0.001,\n",
    "}\n",
    "\n",
    "def load_token_vocabulary(path):\n",
    "    if os.path.isfile(path):\n",
    "        # Load the reserved tokens dictionary\n",
    "        with open(path, 'r') as json_f:\n",
    "            json_data = json_f.read()\n",
    "\n",
    "        # To JSON format (dictionary)\n",
    "        tokens = json.loads(json_data)\n",
    "\n",
    "    else:\n",
    "        tokens = {}\n",
    "\n",
    "        for dirpath, _, files in os.walk(path):\n",
    "            for file in files:\n",
    "                if file.endswith('.json'):\n",
    "                    with open(os.path.join(dirpath, file), 'r') as json_f:\n",
    "                        json_data = json_f.read()\n",
    "\n",
    "                    # To JSON format (dictionary)\n",
    "                    for k,v in json.loads(json_data).items():\n",
    "                            if k in tokens:\n",
    "                                tokens[k] += v\n",
    "                            else:\n",
    "                                tokens[k] = v\n",
    "\n",
    "    return tokens\n",
    "\n",
    "\n",
    "def train(dataset_path, tokens_paths=None, tokenized=False):\n",
    "    token_vocabs = {}\n",
    "    label_to_idx = None\n",
    "    idx_to_label = None\n",
    "    \n",
    "    for k, path in tokens_paths.items():\n",
    "        token_vocabs[k] = load_token_vocabulary(path)\n",
    "        params[f'{k}_VOCAB_SIZE'] = len(token_vocabs[k])\n",
    "        \n",
    "    if len(tokens_paths) > 1:\n",
    "        # Load loss\n",
    "        vae_loss = TreeVaeLossComplete(params['KL_LOSS_WEIGHT'])\n",
    "    else:       \n",
    "        vae_loss = TreeVaeLoss(params['KL_LOSS_WEIGHT'])\n",
    "            \n",
    "    \n",
    "    if not tokenized:\n",
    "        label_to_idx = {}\n",
    "        idx_to_label = {}\n",
    "        for k, vocab in token_vocabs.items():\n",
    "            label_to_idx[k] = {k:i for i, k in enumerate(vocab.keys())}\n",
    "            idx_to_label[k] = {v:k for k, v in label_to_idx[k].items()}\n",
    "            \n",
    "    non_res_tokens = len(tokens_paths) > 1\n",
    "    \n",
    "    ast_dataset = AstDataset(dataset_path, label_to_idx, max_tree_size=-1, remove_non_res=not non_res_tokens)\n",
    "\n",
    "    loader = DataLoader(ast_dataset, batch_size=params['BATCH_SIZE'], collate_fn=batch_tree_input, num_workers=params['NUM_WORKERS'])\n",
    "    \n",
    "    # set model\n",
    "    vae = Vae(device, params)\n",
    "        \n",
    "    # Train\n",
    "#     vae.train(loader, params['EPOCHS'], save_dir='checkpoints/')\n",
    "    return vae, loader, idx_to_label, label_to_idx\n",
    "    # Train\n",
    "#     vae.train(loader, params['EPOCHS'])\n",
    "    \n",
    "tokens_paths = {\n",
    "    'RES': '../data/ast_trees/reserved_tokens.json',\n",
    "    'NAME': '../data/ast_trees/name_tokens.json',\n",
    "    'TYPE': '../data/ast_trees/type_tokens.json',\n",
    "    'LITERAL': '../data/ast_trees/literal_tokens.json',\n",
    "}\n",
    "dataset_path = '../data/ast_trees/asts.csv.bz2'\n",
    "\n",
    "\n",
    "vae, loader, idx_to_label, label_to_idx = train(dataset_path, tokens_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae.load_model('checkpoints/VAE_epoch1_15-04-2021_22:03.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0batch [00:00, ?batch/s]\u001b[A\n",
      "0batch [00:00, ?batch/s, loss=1.9, kl_loss=8.31, recon_loss=1.89]\u001b[A\n",
      "1batch [00:00,  6.97batch/s, loss=1.9, kl_loss=8.31, recon_loss=1.89]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "[0] [0] [1]\n",
      "0 torch.Size([1, 512]) torch.Size([1, 512]) torch.Size([1, 1]) (1,)\n",
      "7\n",
      "tensor([0, 0, 0, 0, 0, 0, 0]) [0] [7]\n",
      "0 torch.Size([1, 512]) torch.Size([1, 512]) torch.Size([1, 1]) (1,)\n",
      "15\n",
      "tensor([ 1,  1,  8,  8, 15, 15, 22, 22, 31, 31, 43, 43, 55, 55, 55]) [ 0  2  4  6  8 10 12] [2 2 2 2 2 2 3]\n",
      "0 torch.Size([7, 512]) torch.Size([7, 512]) torch.Size([7, 1]) (7,)\n",
      "24\n",
      "tensor([ 2,  6,  9, 13, 16, 20, 23, 26, 26, 32, 35, 35, 44, 47, 47, 56, 58, 61,\n",
      "        61, 61, 61, 61, 61, 61]) [ 0  1  2  3  4  5  6  7  9 10 12 13 15 16 17] [1 1 1 1 1 1 1 2 1 2 1 2 1 1 7]\n",
      "0 torch.Size([15, 512]) torch.Size([15, 512]) torch.Size([15, 1]) (15,)\n",
      "34\n",
      "tensor([  3,  10,  17,  24,  27,  29,  33,  36,  38,  38,  45,  48,  50,  50,\n",
      "         59,  62,  62,  62,  70,  70,  75,  75,  75,  75,  75, 115, 115, 129,\n",
      "        129, 129, 129, 240, 240, 248]) [ 0  1  2  3  4  5  6  7  8 10 11 12 14 15 18 20 25 27 31 33] [1 1 1 1 1 1 1 1 2 1 1 2 1 3 2 5 2 4 2 1]\n",
      "0 torch.Size([20, 512]) torch.Size([20, 512]) torch.Size([20, 1]) (20,)\n",
      "38\n",
      "tensor([  4,  11,  18,  39,  41,  51,  53,  63,  65,  68,  71,  73,  76,  76,\n",
      "         83,  83,  90,  90,  97,  97, 106, 106, 116, 118, 118, 130, 147, 147,\n",
      "        159, 162, 162, 162, 162, 162, 241, 243, 243, 249]) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 14 16 18 20 22 23 25 26 28 29 34\n",
      " 35 37] [1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 1 2 1 2 1 5 1 2 1]\n",
      "0 torch.Size([26, 512]) torch.Size([26, 512]) torch.Size([26, 1]) (26,)\n",
      "35\n",
      "tensor([ 66,  77,  80,  84,  87,  91,  94,  98, 101, 101, 107, 110, 110, 119,\n",
      "        119, 127, 131, 131, 148, 150, 150, 150, 160, 163, 163, 171, 171, 209,\n",
      "        209, 217, 217, 225, 225, 244, 246]) [ 0  1  2  3  4  5  6  7  8 10 11 13 15 16 18 19 22 23 25 27 29 31 33 34] [1 1 1 1 1 1 1 1 2 1 2 2 1 2 1 3 1 2 2 2 2 2 1 1]\n",
      "0 torch.Size([24, 512]) torch.Size([24, 512]) torch.Size([24, 1]) (24,)\n",
      "39\n",
      "tensor([ 78,  81,  85,  88,  92,  95,  99, 102, 104, 108, 111, 113, 120, 122,\n",
      "        122, 132, 135, 135, 151, 154, 156, 164, 166, 166, 172, 172, 177, 177,\n",
      "        177, 177, 210, 212, 212, 218, 220, 220, 226, 226, 236]) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 15 16 18 19 20 21 22 24 26 30\n",
      " 31 33 34 36 38] [1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 2 1 1 1 1 2 2 4 1 2 1 2 2 1]\n",
      "0 torch.Size([29, 512]) torch.Size([29, 512]) torch.Size([29, 1]) (29,)\n",
      "28\n",
      "tensor([123, 125, 133, 136, 138, 138, 138, 152, 157, 167, 169, 173, 175, 178,\n",
      "        181, 181, 186, 186, 191, 191, 191, 213, 215, 221, 223, 227, 233, 237]) [ 0  1  2  3  4  7  8  9 10 11 12 13 14 16 18 21 22 23 24 25 26 27] [1 1 1 1 3 1 1 1 1 1 1 1 2 2 3 1 1 1 1 1 1 1]\n",
      "0 torch.Size([22, 512]) torch.Size([22, 512]) torch.Size([22, 1]) (22,)\n",
      "16\n",
      "tensor([139, 142, 144, 179, 182, 184, 187, 189, 192, 192, 197, 203, 228, 228,\n",
      "        234, 238]) [ 0  1  2  3  4  5  6  7  8 10 11 12 14 15] [1 1 1 1 1 1 1 1 2 1 1 2 1 1]\n",
      "0 torch.Size([14, 512]) torch.Size([14, 512]) torch.Size([14, 1]) (14,)\n",
      "10\n",
      "tensor([140, 145, 193, 195, 198, 198, 204, 204, 229, 231]) [0 1 2 3 4 6 8 9] [1 1 1 1 2 2 1 1]\n",
      "0 torch.Size([8, 512]) torch.Size([8, 512]) torch.Size([8, 1]) (8,)\n",
      "4\n",
      "tensor([199, 201, 205, 207]) [0 1 2 3] [1 1 1 1]\n",
      "0 torch.Size([4, 512]) torch.Size([4, 512]) torch.Size([4, 1]) (4,)\n",
      "--------------------\n",
      "1\n",
      "[0] [0] [1]\n",
      "0 torch.Size([1, 512]) torch.Size([1, 512]) torch.Size([1, 1]) (1,)\n",
      "5\n",
      "tensor([0, 0, 0, 0, 0]) [0] [5]\n",
      "0 torch.Size([1, 512]) torch.Size([1, 512]) torch.Size([1, 1]) (1,)\n",
      "11\n",
      "tensor([ 1,  1, 12, 12, 23, 23, 34, 34, 45, 45, 45]) [0 2 4 6 8] [2 2 2 2 3]\n",
      "0 torch.Size([5, 512]) torch.Size([5, 512]) torch.Size([5, 1]) (5,)\n",
      "28\n",
      "tensor([ 2,  9, 13, 20, 24, 31, 35, 42, 46, 48, 51, 51, 51, 51, 51, 51, 51, 51,\n",
      "        51, 51, 51, 51, 51, 51, 51, 51, 51, 51]) [ 0  1  2  3  4  5  6  7  8  9 10] [ 1  1  1  1  1  1  1  1  1  1 18]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1batch [00:00,  6.97batch/s, loss=2.06, kl_loss=6.36, recon_loss=2.05]\u001b[A\n",
      "2batch [00:00,  4.78batch/s, loss=2.06, kl_loss=6.36, recon_loss=2.05]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 torch.Size([11, 512]) torch.Size([11, 512]) torch.Size([11, 1]) (11,)\n",
      "54\n",
      "tensor([  3,   3,  10,  14,  14,  21,  25,  25,  32,  36,  36,  43,  49,  52,\n",
      "         52,  52,  74,  74,  82,  91,  91, 221, 231, 239, 239, 247, 247, 247,\n",
      "        247, 273, 273, 287, 287, 301, 301, 318, 318, 318, 318, 358, 358, 358,\n",
      "        385, 385, 385, 412, 412, 426, 426, 426, 426, 466, 466, 474]) [ 0  2  3  5  6  8  9 11 12 13 16 18 19 21 22 23 25 29 31 33 35 39 42 45\n",
      " 47 51 53] [2 1 2 1 2 1 2 1 1 3 2 1 2 1 1 2 4 2 2 2 4 3 3 2 4 2 1]\n",
      "0 torch.Size([27, 512]) torch.Size([27, 512]) torch.Size([27, 1]) (27,)\n",
      "71\n",
      "tensor([  4,   6,  15,  17,  26,  28,  37,  39,  53,  53,  60,  60,  67,  67,\n",
      "         75,  77,  77,  83,  83,  92,  95,  95, 222, 222, 232, 232, 240, 242,\n",
      "        242, 248, 248, 253, 253, 258, 261, 274, 276, 276, 288, 290, 290, 302,\n",
      "        304, 304, 319, 319, 324, 324, 329, 332, 359, 359, 367, 370, 386, 386,\n",
      "        394, 397, 413, 415, 415, 427, 427, 432, 432, 446, 449, 467, 469, 469,\n",
      "        475]) [ 0  1  2  3  4  5  6  7  8 10 12 14 15 17 19 20 22 24 26 27 29 31 33 34\n",
      " 35 36 38 39 41 42 44 46 48 49 50 52 53 54 56 57 58 59 61 63 65 66 67 68\n",
      " 70] [1 1 1 1 1 1 1 1 2 2 2 1 2 2 1 2 2 2 1 2 2 2 1 1 1 2 1 2 1 2 2 2 1 1 2 1 1\n",
      " 2 1 1 1 2 2 2 1 1 1 2 1]\n",
      "0 torch.Size([49, 512]) torch.Size([49, 512]) torch.Size([49, 1]) (49,)\n",
      "81\n",
      "tensor([  7,  18,  29,  40,  54,  57,  61,  64,  68,  71,  78,  80,  84,  88,\n",
      "         93,  96,  96, 110, 110, 110, 223, 226, 226, 233, 236, 243, 245, 249,\n",
      "        251, 254, 256, 259, 262, 262, 277, 277, 282, 282, 291, 291, 296, 296,\n",
      "        305, 307, 307, 320, 322, 325, 327, 330, 333, 333, 360, 362, 362, 368,\n",
      "        371, 371, 371, 387, 389, 389, 395, 398, 398, 398, 416, 416, 421, 421,\n",
      "        428, 430, 433, 433, 441, 441, 447, 450, 450, 470, 472]) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 17 20 21 23 24 25 26 27\n",
      " 28 29 30 31 32 34 36 38 40 42 43 45 46 47 48 49 50 52 53 55 56 59 60 62\n",
      " 63 66 68 70 71 72 74 76 77 79 80] [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 1 2 1 1 1 1 1 1 1 1 1 2 2 2 2 2 1 2 1 1\n",
      " 1 1 1 2 1 2 1 3 1 2 1 3 2 2 1 1 2 2 1 2 1 1]\n",
      "0 torch.Size([59, 512]) torch.Size([59, 512]) torch.Size([59, 1]) (59,)\n",
      "62\n",
      "tensor([ 55,  58,  62,  65,  69,  72,  85,  89,  97,  99,  99, 111, 111, 134,\n",
      "        144, 144, 144, 224, 227, 229, 234, 237, 263, 265, 265, 278, 280, 283,\n",
      "        285, 292, 294, 297, 299, 308, 308, 313, 313, 334, 336, 336, 363, 365,\n",
      "        372, 374, 383, 390, 392, 399, 401, 410, 417, 419, 422, 424, 434, 436,\n",
      "        436, 442, 444, 451, 453, 453]) [ 0  1  2  3  4  5  6  7  8  9 11 13 14 17 18 19 20 21 22 23 25 26 27 28\n",
      " 29 30 31 32 33 35 37 38 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55\n",
      " 57 58 59 60] [1 1 1 1 1 1 1 1 1 2 2 1 3 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 2 2 1 2 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 2 1 1 1 2]\n",
      "0 torch.Size([52, 512]) torch.Size([52, 512]) torch.Size([52, 1]) (52,)\n",
      "34\n",
      "tensor([ 86, 100, 100, 108, 112, 112, 123, 123, 135, 135, 135, 145, 145, 168,\n",
      "        178, 178, 178, 266, 268, 268, 309, 311, 314, 316, 337, 340, 375, 375,\n",
      "        402, 402, 437, 439, 454, 457]) [ 0  1  3  4  6  8 11 13 14 17 18 20 21 22 23 24 25 26 28 30 31 32 33] [1 2 1 2 2 3 2 1 3 1 2 1 1 1 1 1 1 2 2 1 1 1 1]\n",
      "0 torch.Size([23, 512]) torch.Size([23, 512]) torch.Size([23, 1]) (23,)\n",
      "37\n",
      "tensor([101, 103, 103, 113, 113, 121, 124, 124, 132, 136, 138, 142, 146, 146,\n",
      "        157, 157, 169, 169, 169, 179, 179, 202, 211, 269, 271, 338, 341, 341,\n",
      "        376, 378, 378, 403, 405, 405, 455, 458, 458]) [ 0  1  3  5  6  8  9 10 11 12 14 16 19 21 22 23 24 25 26 28 29 31 32 34\n",
      " 35] [1 2 2 1 2 1 1 1 1 2 2 3 2 1 1 1 1 1 2 1 2 1 2 1 2]\n",
      "0 torch.Size([25, 512]) torch.Size([25, 512]) torch.Size([25, 1]) (25,)\n",
      "39\n",
      "tensor([104, 106, 114, 116, 116, 125, 127, 127, 139, 147, 147, 155, 158, 158,\n",
      "        166, 170, 172, 176, 180, 180, 191, 191, 203, 203, 203, 212, 212, 212,\n",
      "        342, 342, 350, 350, 379, 381, 406, 408, 459, 461, 461]) [ 0  1  2  3  5  6  8  9 11 12 14 15 16 17 18 20 22 25 28 30 32 33 34 35\n",
      " 36 37] [1 1 1 2 1 2 1 2 1 2 1 1 1 1 2 2 3 3 2 2 1 1 1 1 1 2]\n",
      "0 torch.Size([26, 512]) torch.Size([26, 512]) torch.Size([26, 1]) (26,)\n",
      "32\n",
      "tensor([117, 119, 128, 130, 140, 148, 150, 150, 159, 161, 161, 173, 181, 181,\n",
      "        189, 192, 192, 200, 204, 206, 209, 213, 215, 219, 343, 345, 345, 351,\n",
      "        353, 353, 462, 464]) [ 0  1  2  3  4  5  6  8  9 11 12 14 15 17 18 19 20 21 22 23 24 25 27 28\n",
      " 30 31] [1 1 1 1 1 1 2 1 2 1 2 1 2 1 1 1 1 1 1 1 1 2 1 2 1 1]\n",
      "0 torch.Size([26, 512]) torch.Size([26, 512]) torch.Size([26, 1]) (26,)\n",
      "17\n",
      "tensor([151, 153, 162, 164, 174, 182, 184, 184, 193, 195, 195, 207, 216, 346,\n",
      "        348, 354, 356]) [ 0  1  2  3  4  5  6  8  9 11 12 13 14 15 16] [1 1 1 1 1 1 2 1 2 1 1 1 1 1 1]\n",
      "0 torch.Size([15, 512]) torch.Size([15, 512]) torch.Size([15, 1]) (15,)\n",
      "5\n",
      "tensor([185, 187, 196, 198, 217]) [0 1 2 3 4] [1 1 1 1 1]\n",
      "0 torch.Size([5, 512]) torch.Size([5, 512]) torch.Size([5, 1]) (5,)\n",
      "--------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2batch [00:00,  4.78batch/s, loss=1.9, kl_loss=8.27, recon_loss=1.9]  \u001b[A\n",
      "3batch [00:00,  5.24batch/s, loss=1.9, kl_loss=8.27, recon_loss=1.9]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "[0] [0] [1]\n",
      "0 torch.Size([1, 512]) torch.Size([1, 512]) torch.Size([1, 1]) (1,)\n",
      "7\n",
      "tensor([0, 0, 0, 0, 0, 0, 0]) [0] [7]\n",
      "0 torch.Size([1, 512]) torch.Size([1, 512]) torch.Size([1, 1]) (1,)\n",
      "15\n",
      "tensor([ 1,  1,  8,  8, 15, 15, 22, 22, 31, 31, 43, 43, 55, 55, 55]) [ 0  2  4  6  8 10 12] [2 2 2 2 2 2 3]\n",
      "0 torch.Size([7, 512]) torch.Size([7, 512]) torch.Size([7, 1]) (7,)\n",
      "31\n",
      "tensor([ 2,  6,  9, 13, 16, 20, 23, 26, 26, 32, 35, 35, 44, 47, 47, 56, 58, 61,\n",
      "        61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61]) [ 0  1  2  3  4  5  6  7  9 10 12 13 15 16 17] [ 1  1  1  1  1  1  1  2  1  2  1  2  1  1 14]\n",
      "0 torch.Size([15, 512]) torch.Size([15, 512]) torch.Size([15, 1]) (15,)\n",
      "51\n",
      "tensor([  3,  10,  17,  24,  27,  29,  33,  36,  38,  38,  45,  48,  50,  50,\n",
      "         59,  62,  62,  62,  70,  70,  75,  75,  75,  75,  75,  75, 126, 138,\n",
      "        138, 152, 152, 152, 152, 205, 205, 226, 226, 234, 234, 239, 239, 239,\n",
      "        239, 307, 307, 328, 328, 342, 342, 342, 367]) [ 0  1  2  3  4  5  6  7  8 10 11 12 14 15 18 20 26 27 29 33 35 37 39 43\n",
      " 45 47 50] [1 1 1 1 1 1 1 1 2 1 1 2 1 3 2 6 1 2 4 2 2 2 4 2 2 3 1]\n",
      "0 torch.Size([27, 512]) torch.Size([27, 512]) torch.Size([27, 1]) (27,)\n",
      "62\n",
      "tensor([  4,  11,  18,  39,  41,  51,  53,  63,  65,  68,  71,  73,  76,  76,\n",
      "         83,  83,  90,  90, 101, 101, 110, 110, 117, 117, 127, 127, 139, 141,\n",
      "        141, 153, 170, 170, 182, 185, 185, 206, 206, 214, 214, 227, 229, 229,\n",
      "        235, 237, 240, 257, 257, 269, 272, 272, 308, 308, 316, 316, 329, 331,\n",
      "        331, 343, 343, 350, 352, 368]) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 14 16 18 20 22 24 26 27 29 30 32\n",
      " 33 35 37 39 40 42 43 44 45 47 48 50 52 54 55 57 59 60 61] [1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 1 2 1 2 1 2 2 2 1 2 1 1 1 2 1 2 2 2\n",
      " 1 2 2 1 1 1]\n",
      "0 torch.Size([43, 512]) torch.Size([43, 512]) torch.Size([43, 1]) (43,)\n",
      "63\n",
      "tensor([ 66,  77,  80,  84,  87,  91,  98, 102, 105, 105, 111, 114, 118, 121,\n",
      "        121, 128, 135, 142, 142, 150, 154, 154, 171, 173, 173, 173, 183, 186,\n",
      "        186, 197, 197, 207, 207, 212, 215, 215, 223, 230, 232, 241, 241, 258,\n",
      "        260, 260, 260, 270, 273, 273, 281, 281, 309, 309, 314, 317, 317, 325,\n",
      "        332, 332, 340, 344, 347, 353, 353]) [ 0  1  2  3  4  5  6  7  8 10 11 12 13 15 16 17 19 20 22 23 26 27 29 31\n",
      " 33 34 36 37 38 39 41 42 45 46 48 50 52 53 55 56 58 59 60 61] [1 1 1 1 1 1 1 1 2 1 1 1 2 1 1 2 1 2 1 3 1 2 2 2 1 2 1 1 1 2 1 3 1 2 2 2 1\n",
      " 2 1 2 1 1 1 2]\n",
      "0 torch.Size([44, 512]) torch.Size([44, 512]) torch.Size([44, 1]) (44,)\n",
      "66\n",
      "tensor([ 78,  81,  85,  88,  92,  92,  99, 103, 106, 108, 112, 115, 119, 122,\n",
      "        124, 129, 129, 136, 143, 145, 145, 155, 158, 158, 174, 177, 179, 187,\n",
      "        189, 189, 198, 200, 200, 208, 210, 216, 218, 218, 224, 242, 245, 245,\n",
      "        261, 264, 266, 274, 276, 276, 282, 282, 290, 290, 310, 312, 318, 320,\n",
      "        320, 326, 333, 335, 335, 345, 348, 354, 356, 356]) [ 0  1  2  3  4  6  7  8  9 10 11 12 13 14 15 17 18 19 21 22 24 25 26 27\n",
      " 28 30 31 33 34 35 36 38 39 40 42 43 44 45 46 48 50 52 53 54 55 57 58 59\n",
      " 61 62 63 64] [1 1 1 1 2 1 1 1 1 1 1 1 1 1 2 1 1 2 1 2 1 1 1 1 2 1 2 1 1 1 2 1 1 2 1 1 1\n",
      " 1 2 2 2 1 1 1 2 1 1 2 1 1 1 2]\n",
      "0 torch.Size([52, 512]) torch.Size([52, 512]) torch.Size([52, 1]) (52,)\n",
      "44\n",
      "tensor([ 93,  95, 130, 132, 146, 148, 156, 159, 161, 161, 161, 175, 180, 190,\n",
      "        192, 192, 201, 203, 219, 221, 243, 246, 248, 248, 248, 262, 267, 277,\n",
      "        279, 283, 283, 288, 291, 291, 291, 302, 302, 321, 323, 336, 338, 357,\n",
      "        357, 365]) [ 0  1  2  3  4  5  6  7  8 11 12 13 14 16 17 18 19 20 21 22 25 26 27 28\n",
      " 29 31 32 35 37 38 39 40 41 43] [1 1 1 1 1 1 1 1 3 1 1 1 2 1 1 1 1 1 1 3 1 1 1 1 2 1 3 2 1 1 1 1 2 1]\n",
      "0 torch.Size([34, 512]) torch.Size([34, 512]) torch.Size([34, 1]) (34,)\n",
      "20\n",
      "tensor([ 96, 133, 162, 165, 167, 193, 195, 249, 252, 254, 284, 286, 292, 294,\n",
      "        300, 303, 305, 358, 360, 360]) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18] [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2]\n",
      "0 torch.Size([19, 512]) torch.Size([19, 512]) torch.Size([19, 1]) (19,)\n",
      "8\n",
      "tensor([163, 168, 250, 255, 295, 295, 361, 363]) [0 1 2 3 4 6 7] [1 1 1 1 2 1 1]\n",
      "0 torch.Size([7, 512]) torch.Size([7, 512]) torch.Size([7, 1]) (7,)\n",
      "2\n",
      "tensor([296, 298]) [0 1] [1 1]\n",
      "0 torch.Size([2, 512]) torch.Size([2, 512]) torch.Size([2, 1]) (2,)\n",
      "--------------------\n",
      "1\n",
      "[0] [0] [1]\n",
      "0 torch.Size([1, 512]) torch.Size([1, 512]) torch.Size([1, 1]) (1,)\n",
      "7\n",
      "tensor([0, 0, 0, 0, 0, 0, 0]) [0] [7]\n",
      "0 torch.Size([1, 512]) torch.Size([1, 512]) torch.Size([1, 1]) (1,)\n",
      "15\n",
      "tensor([ 1,  1,  8,  8, 15, 15, 27, 27, 38, 38, 49, 49, 62, 62, 62]) [ 0  2  4  6  8 10 12] [2 2 2 2 2 2 3]\n",
      "0 torch.Size([7, 512]) torch.Size([7, 512]) torch.Size([7, 1]) (7,)\n",
      "26\n",
      "tensor([ 2,  6,  9, 13, 16, 19, 19, 28, 35, 39, 46, 50, 59, 63, 65, 68, 68, 68,\n",
      "        68, 68, 68, 68, 68, 68, 68, 68]) [ 0  1  2  3  4  5  7  8  9 10 11 12 13 14 15] [ 1  1  1  1  1  2  1  1  1  1  1  1  1  1 11]\n",
      "0 torch.Size([15, 512]) torch.Size([15, 512]) torch.Size([15, 1]) (15,)\n",
      "43\n",
      "tensor([  3,  10,  17,  20,  22,  22,  29,  29,  36,  40,  40,  47,  51,  51,\n",
      "         60,  66,  69,  69,  69,  77,  77,  77,  85,  85,  85,  93,  93, 108,\n",
      "        108, 122, 132, 142, 142, 142, 142, 173, 173, 173, 173, 262, 262, 269,\n",
      "        269]) [ 0  1  2  3  4  6  8  9 11 12 14 15 16 19 22 25 27 29 30 31 35 39 41] [1 1 1 1 2 2 1 2 1 2 1 1 3 3 3 2 2 1 1 4 4 2 2]\n",
      "0 torch.Size([23, 512]) torch.Size([23, 512]) torch.Size([23, 1]) (23,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "3batch [00:00,  5.24batch/s, loss=1.85, kl_loss=6.61, recon_loss=1.84]\u001b[A\n",
      "4batch [00:00,  5.26batch/s, loss=1.85, kl_loss=6.61, recon_loss=1.84]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46\n",
      "tensor([  4,  11,  23,  25,  30,  32,  41,  43,  52,  54,  54,  70,  72,  75,\n",
      "         78,  80,  83,  86,  88,  91,  94,  94, 101, 101, 109, 111, 111, 123,\n",
      "        123, 133, 133, 143, 153, 153, 158, 161, 174, 184, 184, 189, 192, 263,\n",
      "        265, 270, 272, 272]) [ 0  1  2  3  4  5  6  7  8  9 11 12 13 14 15 16 17 18 19 20 22 24 25 27\n",
      " 29 31 32 34 35 36 37 39 40 41 42 43 44] [1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 2 2 1 2 2 2 1 2 1 1 1 2 1 1 1 1 1 2]\n",
      "0 torch.Size([37, 512]) torch.Size([37, 512]) torch.Size([37, 1]) (37,)\n",
      "39\n",
      "tensor([ 33,  44,  55,  57,  73,  81,  89,  95,  98, 102, 105, 112, 112, 120,\n",
      "        124, 127, 127, 134, 137, 137, 144, 144, 154, 156, 159, 162, 162, 175,\n",
      "        175, 185, 187, 190, 193, 193, 193, 266, 273, 273, 281]) [ 0  1  2  3  4  5  6  7  8  9 10 11 13 14 15 17 18 20 22 23 24 25 27 29\n",
      " 30 31 32 35 36 38] [1 1 1 1 1 1 1 1 1 1 1 2 1 1 2 1 2 2 1 1 1 2 2 1 1 1 3 1 2 1]\n",
      "0 torch.Size([30, 512]) torch.Size([30, 512]) torch.Size([30, 1]) (30,)\n",
      "32\n",
      "tensor([ 96,  99, 103, 106, 113, 115, 115, 125, 128, 130, 135, 138, 140, 145,\n",
      "        148, 148, 163, 165, 165, 176, 179, 179, 194, 196, 196, 240, 240, 240,\n",
      "        267, 274, 276, 276]) [ 0  1  2  3  4  5  7  8  9 10 11 12 13 14 16 17 19 20 22 23 25 28 29 30] [1 1 1 1 1 2 1 1 1 1 1 1 1 2 1 2 1 2 1 2 3 1 1 2]\n",
      "0 torch.Size([24, 512]) torch.Size([24, 512]) torch.Size([24, 1]) (24,)\n",
      "24\n",
      "tensor([116, 118, 146, 149, 151, 166, 168, 168, 177, 180, 182, 197, 197, 205,\n",
      "        205, 205, 241, 241, 249, 249, 257, 257, 277, 279]) [ 0  1  2  3  4  5  6  8  9 10 11 13 16 18 20 22 23] [1 1 1 1 1 1 2 1 1 1 2 3 2 2 2 1 1]\n",
      "0 torch.Size([17, 512]) torch.Size([17, 512]) torch.Size([17, 1]) (17,)\n",
      "19\n",
      "tensor([169, 171, 198, 200, 200, 206, 206, 211, 211, 220, 220, 242, 244, 244,\n",
      "        250, 252, 252, 258, 260]) [ 0  1  2  3  5  7  9 11 12 14 15 17 18] [1 1 1 2 2 2 2 1 2 1 2 1 1]\n",
      "0 torch.Size([13, 512]) torch.Size([13, 512]) torch.Size([13, 1]) (13,)\n",
      "15\n",
      "tensor([201, 203, 207, 209, 212, 215, 215, 221, 221, 226, 226, 245, 247, 253,\n",
      "        255]) [ 0  1  2  3  4  5  7  9 11 12 13 14] [1 1 1 1 1 2 2 2 1 1 1 1]\n",
      "0 torch.Size([12, 512]) torch.Size([12, 512]) torch.Size([12, 1]) (12,)\n",
      "9\n",
      "tensor([213, 216, 218, 222, 224, 227, 227, 235, 235]) [0 1 2 3 4 5 7] [1 1 1 1 1 2 2]\n",
      "0 torch.Size([7, 512]) torch.Size([7, 512]) torch.Size([7, 1]) (7,)\n",
      "5\n",
      "tensor([228, 230, 230, 236, 238]) [0 1 3 4] [1 2 1 1]\n",
      "0 torch.Size([4, 512]) torch.Size([4, 512]) torch.Size([4, 1]) (4,)\n",
      "2\n",
      "tensor([231, 233]) [0 1] [1 1]\n",
      "0 torch.Size([2, 512]) torch.Size([2, 512]) torch.Size([2, 1]) (2,)\n",
      "--------------------\n",
      "1\n",
      "[0] [0] [1]\n",
      "0 torch.Size([1, 512]) torch.Size([1, 512]) torch.Size([1, 1]) (1,)\n",
      "4\n",
      "tensor([0, 0, 0, 0]) [0] [4]\n",
      "0 torch.Size([1, 512]) torch.Size([1, 512]) torch.Size([1, 1]) (1,)\n",
      "10\n",
      "tensor([  1,   1,   8,   8,  19,  19,  19, 338, 338, 338]) [0 2 4 7] [2 2 3 3]\n",
      "0 torch.Size([4, 512]) torch.Size([4, 512]) torch.Size([4, 1]) (4,)\n",
      "24\n",
      "tensor([  2,   6,   9,  17,  20,  22,  25,  25,  25,  25,  25,  25,  25,  25,\n",
      "         25,  25,  25,  25, 339, 341, 344, 344, 344, 344]) [ 0  1  2  3  4  5  6 18 19 20] [ 1  1  1  1  1  1 12  1  1  4]\n",
      "0 torch.Size([10, 512]) torch.Size([10, 512]) torch.Size([10, 1]) (10,)\n",
      "39\n",
      "tensor([  3,  10,  23,  26,  26,  41,  41,  55,  70,  80,  80,  80,  80, 125,\n",
      "        125, 144, 153, 153, 172, 172, 172, 172, 235, 235, 260, 260, 268, 268,\n",
      "        268, 268, 342, 345, 345, 345, 353, 353, 353, 361, 364]) [ 0  1  2  3  5  7  8  9 13 15 16 18 22 24 26 30 31 34 37 38] [1 1 1 2 2 1 1 4 2 1 2 4 2 2 4 1 3 3 1 1]\n",
      "0 torch.Size([20, 512]) torch.Size([20, 512]) torch.Size([20, 1]) (20,)\n",
      "56\n",
      "tensor([  4,  11,  11,  27,  27,  34,  34,  42,  44,  44,  56,  56,  71,  71,\n",
      "         81,  91,  91,  96,  99,  99, 126, 126, 134, 134, 145, 145, 154, 154,\n",
      "        163, 163, 173, 183, 183, 188, 191, 191, 236, 236, 250, 250, 261, 263,\n",
      "        263, 269, 279, 279, 293, 296, 346, 348, 351, 354, 356, 359, 362, 365]) [ 0  1  3  5  7  8 10 12 14 15 17 18 20 22 24 26 28 30 31 33 34 36 38 40\n",
      " 41 43 44 46 47 48 49 50 51 52 53 54 55] [1 2 2 2 1 2 2 2 1 2 1 2 2 2 2 2 2 1 2 1 2 2 2 1 2 1 2 1 1 1 1 1 1 1 1 1 1]\n",
      "0 torch.Size([37, 512]) torch.Size([37, 512]) torch.Size([37, 1]) (37,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "4batch [00:00,  5.26batch/s, loss=1.99, kl_loss=6.74, recon_loss=1.98]\u001b[A\n",
      "5batch [00:00,  5.12batch/s, loss=1.99, kl_loss=6.74, recon_loss=1.98]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61\n",
      "tensor([ 12,  14,  28,  31,  35,  38,  45,  45,  53,  57,  61,  61,  72,  75,\n",
      "         75,  82,  82,  92,  94,  97, 100, 100, 114, 114, 127, 127, 132, 135,\n",
      "        135, 146, 150, 155, 158, 158, 164, 167, 167, 174, 174, 184, 186, 189,\n",
      "        192, 192, 207, 207, 237, 248, 251, 251, 264, 266, 270, 270, 280, 282,\n",
      "        294, 297, 297, 349, 357]) [ 0  1  2  3  4  5  6  8  9 10 12 13 15 17 18 19 20 22 24 26 27 29 30 31\n",
      " 32 34 35 37 39 40 41 42 44 46 47 48 50 51 52 54 55 56 57 59 60] [1 1 1 1 1 1 2 1 1 2 1 2 2 1 1 1 2 2 2 1 2 1 1 1 2 1 2 2 1 1 1 2 2 1 1 2 1\n",
      " 1 2 1 1 1 2 1 1]\n",
      "0 torch.Size([45, 512]) torch.Size([45, 512]) torch.Size([45, 1]) (45,)\n",
      "61\n",
      "tensor([ 15,  29,  32,  36,  39,  46,  48,  48,  58,  62,  64,  64,  73,  76,\n",
      "         78,  83,  86,  86, 101, 103, 103, 115, 117, 117, 128, 130, 136, 138,\n",
      "        138, 147, 151, 156, 159, 161, 165, 168, 170, 175, 178, 178, 193, 193,\n",
      "        204, 208, 208, 216, 216, 216, 238, 238, 252, 254, 254, 271, 274, 274,\n",
      "        283, 283, 298, 300, 300]) [ 0  1  2  3  4  5  6  8  9 10 12 13 14 15 16 18 19 21 22 24 25 26 27 29\n",
      " 30 31 32 33 34 35 36 37 38 40 42 43 45 48 50 51 53 54 56 58 59] [1 1 1 1 1 1 2 1 1 2 1 1 1 1 2 1 2 1 2 1 1 1 2 1 1 1 1 1 1 1 1 1 2 2 1 2 3\n",
      " 2 1 2 1 2 2 1 2]\n",
      "0 torch.Size([45, 512]) torch.Size([45, 512]) torch.Size([45, 1]) (45,)\n",
      "48\n",
      "tensor([ 49,  51,  59,  65,  67,  84,  87,  89, 104, 106, 106, 118, 120, 120,\n",
      "        139, 141, 148, 176, 179, 181, 194, 196, 196, 205, 209, 211, 211, 217,\n",
      "        217, 217, 225, 225, 230, 230, 239, 242, 242, 255, 257, 272, 275, 277,\n",
      "        284, 287, 287, 301, 301, 315]) [ 0  1  2  3  4  5  6  7  8  9 11 12 14 15 16 17 18 19 20 21 23 24 25 27\n",
      " 30 32 34 35 37 38 39 40 41 42 43 45 47] [1 1 1 1 1 1 1 1 1 2 1 2 1 1 1 1 1 1 1 2 1 1 2 3 2 2 1 2 1 1 1 1 1 1 2 2 1]\n",
      "0 torch.Size([37, 512]) torch.Size([37, 512]) torch.Size([37, 1]) (37,)\n",
      "30\n",
      "tensor([ 68, 107, 109, 109, 121, 123, 197, 199, 199, 212, 214, 218, 220, 223,\n",
      "        226, 228, 231, 233, 240, 243, 245, 285, 288, 290, 302, 304, 304, 316,\n",
      "        316, 316]) [ 0  1  2  4  5  6  7  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25\n",
      " 27] [1 1 2 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3]\n",
      "0 torch.Size([25, 512]) torch.Size([25, 512]) torch.Size([25, 1]) (25,)\n",
      "14\n",
      "tensor([110, 112, 200, 202, 221, 246, 291, 305, 307, 307, 317, 317, 334, 336]) [ 0  1  2  3  4  5  6  7  8 10 12 13] [1 1 1 1 1 1 1 1 2 2 1 1]\n",
      "0 torch.Size([12, 512]) torch.Size([12, 512]) torch.Size([12, 1]) (12,)\n",
      "6\n",
      "tensor([308, 310, 310, 318, 320, 320]) [0 1 3 4] [1 2 1 2]\n",
      "0 torch.Size([4, 512]) torch.Size([4, 512]) torch.Size([4, 1]) (4,)\n",
      "4\n",
      "tensor([311, 313, 321, 332]) [0 1 2 3] [1 1 1 1]\n",
      "0 torch.Size([4, 512]) torch.Size([4, 512]) torch.Size([4, 1]) (4,)\n",
      "2\n",
      "tensor([322, 322]) [0] [2]\n",
      "0 torch.Size([1, 512]) torch.Size([1, 512]) torch.Size([1, 1]) (1,)\n",
      "3\n",
      "tensor([323, 326, 326]) [0 1] [1 2]\n",
      "0 torch.Size([2, 512]) torch.Size([2, 512]) torch.Size([2, 1]) (2,)\n",
      "3\n",
      "tensor([324, 327, 329]) [0 1 2] [1 1 1]\n",
      "0 torch.Size([3, 512]) torch.Size([3, 512]) torch.Size([3, 1]) (3,)\n",
      "1\n",
      "tensor([330]) [0] [1]\n",
      "0 torch.Size([1, 512]) torch.Size([1, 512]) torch.Size([1, 1]) (1,)\n",
      "--------------------\n",
      "1\n",
      "[0] [0] [1]\n",
      "0 torch.Size([1, 512]) torch.Size([1, 512]) torch.Size([1, 1]) (1,)\n",
      "13\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]) [0] [13]\n",
      "0 torch.Size([1, 512]) torch.Size([1, 512]) torch.Size([1, 1]) (1,)\n",
      "46\n",
      "tensor([  1,   1,   8,   8,  20,  20,  20,  20,  65,  65,  65,  65,  65, 153,\n",
      "        153, 163, 163, 163, 179, 179, 179, 179, 179, 222, 222, 222, 222, 222,\n",
      "        259, 259, 259, 259, 259, 259, 359, 359, 359, 359, 359, 387, 387, 418,\n",
      "        418, 449, 449, 449]) [ 0  2  4  8 13 15 18 23 28 34 39 41 43] [2 2 4 5 2 3 5 5 6 5 2 2 3]\n",
      "0 torch.Size([13, 512]) torch.Size([13, 512]) torch.Size([13, 1]) (13,)\n",
      "77\n",
      "tensor([  2,   6,   9,  12,  12,  21,  23,  26,  26,  33,  33,  66,  68,  71,\n",
      "         71,  78,  78,  85,  85,  85,  85, 154, 157, 157, 164, 166, 169, 180,\n",
      "        182, 185, 185, 192, 192, 199, 199, 223, 225, 228, 228, 235, 235, 242,\n",
      "        260, 262, 265, 265, 272, 272, 279, 279, 288, 288, 288, 288, 360, 362,\n",
      "        365, 365, 372, 372, 379, 388, 395, 395, 419, 426, 426, 450, 452, 455,\n",
      "        455, 455, 455, 455, 455, 455, 455]) [ 0  1  2  3  5  6  7  9 11 12 13 15 17 21 22 24 25 26 27 28 29 31 33 35\n",
      " 36 37 39 41 42 43 44 46 48 50 54 55 56 58 60 61 62 64 65 67 68 69] [1 1 1 2 1 1 2 2 1 1 2 2 4 1 2 1 1 1 1 1 2 2 2 1 1 2 2 1 1 1 2 2 2 4 1 1 2\n",
      " 2 1 1 2 1 2 1 1 8]\n",
      "0 torch.Size([46, 512]) torch.Size([46, 512]) torch.Size([46, 1]) (46,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "5batch [00:01,  5.12batch/s, loss=2.41, kl_loss=6.38, recon_loss=2.4] \u001b[A\n",
      "6batch [00:01,  4.62batch/s, loss=2.41, kl_loss=6.38, recon_loss=2.4]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99\n",
      "tensor([  3,  10,  13,  15,  15,  24,  27,  30,  34,  34,  62,  69,  72,  75,\n",
      "         79,  82,  86,  96,  96, 114, 114, 114, 114, 150, 155, 158, 160, 167,\n",
      "        170, 170, 183, 186, 189, 193, 196, 200, 200, 210, 226, 229, 232, 236,\n",
      "        239, 243, 263, 266, 269, 273, 276, 280, 283, 283, 289, 299, 299, 307,\n",
      "        307, 356, 363, 366, 369, 373, 376, 380, 389, 389, 396, 398, 398, 398,\n",
      "        398, 398, 398, 398, 398, 420, 420, 427, 429, 429, 429, 429, 429, 429,\n",
      "        429, 429, 453, 456, 456, 456, 464, 464, 469, 469, 475, 485, 485, 712,\n",
      "        715]) [ 0  1  2  3  5  6  7  8 10 11 12 13 14 15 16 17 19 23 24 25 26 27 28 30\n",
      " 31 32 33 34 35 37 38 39 40 41 42 43 44 45 46 47 48 49 50 52 53 55 57 58\n",
      " 59 60 61 62 63 64 66 67 75 77 78 86 87 90 92 94 95 97 98] [1 1 1 2 1 1 1 2 1 1 1 1 1 1 1 2 4 1 1 1 1 1 2 1 1 1 1 1 2 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 2 1 2 2 1 1 1 1 1 1 1 2 1 8 2 1 8 1 3 2 2 1 2 1 1]\n",
      "0 torch.Size([67, 512]) torch.Size([67, 512]) torch.Size([67, 1]) (67,)\n",
      "109\n",
      "tensor([  4,  16,  18,  28,  31,  35,  35,  40,  40,  40,  63,  73,  76,  80,\n",
      "         83,  87,  87,  97,  97, 105, 115, 125, 125, 130, 133, 133, 151, 161,\n",
      "        171, 173, 173, 187, 190, 194, 197, 201, 201, 206, 211, 211, 230, 233,\n",
      "        237, 240, 244, 267, 270, 274, 277, 281, 284, 286, 290, 290, 300, 302,\n",
      "        302, 308, 308, 313, 313, 313, 357, 367, 370, 374, 377, 381, 390, 392,\n",
      "        399, 401, 403, 405, 407, 409, 412, 415, 421, 423, 430, 432, 434, 436,\n",
      "        439, 442, 445, 447, 457, 459, 462, 465, 467, 470, 472, 476, 476, 486,\n",
      "        489, 489, 489, 489, 489, 489, 489, 489, 489, 713, 716]) [  0   1   2   3   4   5   7  10  11  12  13  14  15  17  19  20  21  23\n",
      "  24  26  27  28  29  31  32  33  34  35  37  38  40  41  42  43  44  45\n",
      "  46  47  48  49  50  51  52  54  55  57  59  62  63  64  65  66  67  68\n",
      "  69  70  71  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86\n",
      "  87  88  89  90  91  92  93  94  95  97  98 107 108] [1 1 1 1 1 2 3 1 1 1 1 1 2 2 1 1 2 1 2 1 1 1 2 1 1 1 1 2 1 2 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 2 1 2 2 3 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 2 1 9 1 1]\n",
      "0 torch.Size([85, 512]) torch.Size([85, 512]) torch.Size([85, 1]) (85,)\n",
      "84\n",
      "tensor([ 36,  38,  41,  41,  47,  47,  53,  53,  88,  91,  91,  98, 100, 100,\n",
      "        106, 106, 116, 116, 126, 128, 131, 134, 134, 142, 142, 174, 177, 202,\n",
      "        204, 207, 212, 214, 214, 245, 245, 291, 294, 294, 303, 305, 309, 311,\n",
      "        314, 314, 336, 336, 341, 341, 382, 382, 393, 410, 413, 416, 424, 437,\n",
      "        440, 443, 460, 477, 480, 480, 487, 490, 490, 505, 505, 519, 531, 531,\n",
      "        531, 531, 562, 562, 581, 581, 581, 581, 663, 663, 681, 681, 704, 704]) [ 0  1  2  4  6  8  9 11 12 14 16 18 19 20 21 23 25 26 27 28 29 30 31 33\n",
      " 35 36 38 39 40 41 42 44 46 48 50 51 52 53 54 55 56 57 58 59 60 62 63 65\n",
      " 67 68 72 74 78 80 82] [1 1 2 2 2 1 2 1 2 2 2 1 1 1 2 2 1 1 1 1 1 1 2 2 1 2 1 1 1 1 2 2 2 2 1 1 1\n",
      " 1 1 1 1 1 1 1 2 1 2 2 1 4 2 4 2 2 2]\n",
      "0 torch.Size([55, 512]) torch.Size([55, 512]) torch.Size([55, 1]) (55,)\n",
      "80\n",
      "tensor([ 42,  44,  48,  50,  54,  56,  89,  92,  94, 101, 103, 107, 109, 109,\n",
      "        117, 120, 120, 135, 137, 137, 143, 145, 145, 175, 208, 215, 217, 217,\n",
      "        246, 246, 257, 292, 295, 297, 315, 315, 320, 337, 339, 342, 344, 344,\n",
      "        383, 385, 478, 481, 483, 491, 491, 498, 498, 506, 508, 508, 520, 520,\n",
      "        532, 542, 542, 547, 550, 563, 563, 572, 572, 582, 592, 592, 600, 603,\n",
      "        603, 664, 666, 666, 682, 682, 700, 705, 707, 707]) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 14 15 17 18 20 21 23 24 25 26 28\n",
      " 30 31 32 33 34 36 37 38 39 40 42 43 44 45 46 47 49 51 52 54 56 57 59 60\n",
      " 61 63 65 66 68 69 71 72 74 76 77 78] [1 1 1 1 1 1 1 1 1 1 1 1 2 1 2 1 2 1 2 1 1 1 2 2 1 1 1 1 2 1 1 1 1 2 1 1 1\n",
      " 1 1 2 2 1 2 2 1 2 1 1 2 2 1 2 1 2 1 2 2 1 1 2]\n",
      "0 torch.Size([60, 512]) torch.Size([60, 512]) torch.Size([60, 1]) (60,)\n",
      "65\n",
      "tensor([ 45,  51,  57,  57, 110, 112, 118, 121, 123, 138, 140, 146, 148, 218,\n",
      "        220, 247, 249, 249, 316, 318, 321, 321, 345, 354, 492, 495, 499, 502,\n",
      "        509, 509, 517, 521, 528, 533, 533, 543, 545, 548, 551, 551, 564, 567,\n",
      "        567, 573, 576, 576, 583, 583, 593, 595, 595, 601, 604, 604, 619, 619,\n",
      "        619, 667, 679, 683, 683, 698, 701, 708, 710]) [ 0  1  2  4  5  6  7  8  9 10 11 12 13 14 15 16 18 19 20 22 23 24 25 26\n",
      " 27 28 30 31 32 33 35 36 37 38 40 41 43 44 46 48 49 51 52 54 57 58 59 61\n",
      " 62 63 64] [1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 2 1 1 1 1 1 1 2 1 1 1 2 1 1 1 2 1 2 1\n",
      " 2 2 1 2 1 2 3 1 1 2 1 1 1 1]\n",
      "0 torch.Size([51, 512]) torch.Size([51, 512]) torch.Size([51, 1]) (51,)\n",
      "50\n",
      "tensor([ 58,  60, 250, 252, 252, 322, 324, 324, 346, 346, 493, 496, 500, 503,\n",
      "        510, 512, 512, 522, 522, 529, 534, 537, 537, 552, 554, 554, 565, 568,\n",
      "        570, 574, 577, 579, 584, 587, 587, 596, 598, 605, 607, 607, 620, 620,\n",
      "        638, 638, 647, 668, 668, 684, 696, 702]) [ 0  1  2  3  5  6  8 10 11 12 13 14 15 17 19 20 21 23 24 26 27 28 29 30\n",
      " 31 32 33 35 36 37 38 40 42 44 45 47 48 49] [1 1 1 2 1 2 2 1 1 1 1 1 2 2 1 1 2 1 2 1 1 1 1 1 1 1 2 1 1 1 2 2 2 1 2 1 1\n",
      " 1]\n",
      "0 torch.Size([38, 512]) torch.Size([38, 512]) torch.Size([38, 1]) (38,)\n",
      "35\n",
      "tensor([253, 255, 325, 334, 347, 347, 352, 513, 515, 523, 525, 535, 538, 540,\n",
      "        555, 557, 557, 585, 588, 590, 608, 617, 621, 623, 623, 639, 642, 642,\n",
      "        648, 648, 669, 669, 677, 685, 685]) [ 0  1  2  3  4  6  7  8  9 10 11 12 13 14 15 17 18 19 20 21 22 23 25 26\n",
      " 28 30 32 33] [1 1 1 1 2 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 2 1 2 2 2 1 2]\n",
      "0 torch.Size([28, 512]) torch.Size([28, 512]) torch.Size([28, 1]) (28,)\n",
      "24\n",
      "tensor([326, 326, 348, 350, 526, 558, 560, 609, 609, 624, 624, 636, 640, 643,\n",
      "        645, 649, 651, 651, 670, 672, 672, 686, 686, 694]) [ 0  2  3  4  5  6  7  9 11 12 13 14 15 16 18 19 21 23] [2 1 1 1 1 1 2 2 1 1 1 1 1 2 1 2 2 1]\n",
      "0 torch.Size([18, 512]) torch.Size([18, 512]) torch.Size([18, 1]) (18,)\n",
      "15\n",
      "tensor([327, 327, 332, 610, 610, 615, 625, 634, 652, 661, 673, 675, 687, 689,\n",
      "        689]) [ 0  2  3  5  6  7  8  9 10 11 12 13] [2 1 2 1 1 1 1 1 1 1 1 2]\n",
      "0 torch.Size([12, 512]) torch.Size([12, 512]) torch.Size([12, 1]) (12,)\n",
      "10\n",
      "tensor([328, 330, 611, 613, 626, 626, 653, 653, 690, 692]) [0 1 2 3 4 6 8 9] [1 1 1 1 2 2 1 1]\n",
      "0 torch.Size([8, 512]) torch.Size([8, 512]) torch.Size([8, 1]) (8,)\n",
      "6\n",
      "tensor([627, 627, 632, 654, 654, 659]) [0 2 3 5] [2 1 2 1]\n",
      "0 torch.Size([4, 512]) torch.Size([4, 512]) torch.Size([4, 1]) (4,)\n",
      "4\n",
      "tensor([628, 630, 655, 657]) [0 1 2 3] [1 1 1 1]\n",
      "0 torch.Size([4, 512]) torch.Size([4, 512]) torch.Size([4, 1]) (4,)\n",
      "--------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "6batch [00:01,  4.62batch/s, loss=2.49, kl_loss=7.22, recon_loss=2.48]\u001b[A\n",
      "7batch [00:01,  4.29batch/s, loss=2.49, kl_loss=7.22, recon_loss=2.48]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "[0] [0] [1]\n",
      "0 torch.Size([1, 512]) torch.Size([1, 512]) torch.Size([1, 1]) (1,)\n",
      "1\n",
      "tensor([0]) [0] [1]\n",
      "0 torch.Size([1, 512]) torch.Size([1, 512]) torch.Size([1, 1]) (1,)\n",
      "3\n",
      "tensor([1, 1, 1]) [0] [3]\n",
      "0 torch.Size([1, 512]) torch.Size([1, 512]) torch.Size([1, 1]) (1,)\n",
      "23\n",
      "tensor([2, 4, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7]) [0 1 2] [ 1  1 21]\n",
      "0 torch.Size([3, 512]) torch.Size([3, 512]) torch.Size([3, 1]) (3,)\n",
      "53\n",
      "tensor([  5,   8,  20,  32,  44,  56,  68,  68,  68,  68,  68,  68,  68,  68,\n",
      "         68, 140, 140, 157, 166, 166, 174, 174, 174, 174, 281, 281, 299, 299,\n",
      "        317, 317, 335, 335, 335, 335, 367, 367, 375, 375, 375, 375, 425, 425,\n",
      "        430, 430, 430, 520, 520, 538, 538, 538, 538, 579, 579]) [ 0  1  2  3  4  5  6 15 17 18 20 24 26 28 30 34 36 40 42 45 47 51] [1 1 1 1 1 1 9 2 1 2 4 2 2 2 4 2 4 2 3 2 4 2]\n",
      "0 torch.Size([22, 512]) torch.Size([22, 512]) torch.Size([22, 1]) (22,)\n",
      "92\n",
      "tensor([  9,   9,  21,  21,  33,  33,  45,  45,  57,  57,  69,  69,  78,  78,\n",
      "         87,  87,  96,  96, 105, 105, 112, 112, 119, 119, 126, 126, 133, 133,\n",
      "        141, 141, 150, 150, 158, 158, 167, 169, 169, 175, 175, 180, 180, 185,\n",
      "        188, 188, 188, 282, 284, 284, 284, 300, 302, 302, 302, 318, 320, 320,\n",
      "        320, 336, 336, 341, 341, 349, 352, 368, 370, 370, 376, 376, 381, 381,\n",
      "        398, 401, 426, 428, 431, 431, 442, 475, 475, 521, 523, 523, 523, 539,\n",
      "        539, 544, 544, 561, 564, 580, 582, 582]) [ 0  2  4  6  8 10 12 14 16 18 20 22 24 26 28 30 32 34 35 37 39 41 42 45\n",
      " 46 49 50 53 54 57 59 61 62 63 64 66 68 70 71 72 73 74 76 77 79 80 83 85\n",
      " 87 88 89 90] [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 1 3 1 3 1 3 1 3 2 2 1 1 1 2 2 2\n",
      " 1 1 1 1 2 1 2 1 3 2 2 1 1 1 2]\n",
      "0 torch.Size([52, 512]) torch.Size([52, 512]) torch.Size([52, 1]) (52,)\n",
      "117\n",
      "tensor([ 10,  17,  22,  29,  34,  41,  46,  53,  58,  65,  70,  73,  73,  79,\n",
      "         82,  82,  88,  91,  91,  97, 100, 100, 106, 109, 113, 116, 120, 123,\n",
      "        127, 130, 134, 137, 142, 145, 145, 151, 154, 159, 163, 170, 172, 176,\n",
      "        178, 181, 183, 186, 189, 189, 197, 197, 205, 205, 205, 285, 285, 290,\n",
      "        290, 295, 295, 303, 303, 308, 308, 313, 313, 321, 321, 326, 326, 331,\n",
      "        331, 337, 339, 342, 344, 344, 350, 353, 353, 371, 373, 377, 379, 382,\n",
      "        384, 384, 399, 402, 402, 432, 432, 437, 437, 443, 443, 443, 443, 476,\n",
      "        476, 487, 524, 524, 529, 529, 534, 534, 540, 542, 545, 547, 547, 562,\n",
      "        565, 565, 583, 583, 591]) [  0   1   2   3   4   5   6   7   8   9  10  11  13  14  16  17  19  20\n",
      "  22  23  24  25  26  27  28  29  30  31  32  33  35  36  37  38  39  40\n",
      "  41  42  43  44  45  46  48  50  53  55  57  59  61  63  65  67  69  71\n",
      "  72  73  74  76  77  79  80  81  82  83  84  86  87  89  91  93  97  99\n",
      " 100 102 104 106 107 108 109 111 112 114 116] [1 1 1 1 1 1 1 1 1 1 1 2 1 2 1 2 1 2 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1\n",
      " 1 1 1 1 2 2 3 2 2 2 2 2 2 2 2 2 1 1 1 2 1 2 1 1 1 1 1 2 1 2 2 2 4 2 1 2 2\n",
      " 2 1 1 1 2 1 2 2 1]\n",
      "0 torch.Size([83, 512]) torch.Size([83, 512]) torch.Size([83, 1]) (83,)\n",
      "113\n",
      "tensor([ 11,  11,  18,  23,  23,  30,  35,  35,  42,  47,  47,  54,  59,  59,\n",
      "         66,  71,  74,  76,  80,  83,  85,  89,  92,  94,  98, 101, 103, 107,\n",
      "        110, 114, 117, 121, 124, 128, 131, 135, 138, 143, 146, 148, 152, 155,\n",
      "        160, 164, 190, 192, 192, 198, 200, 200, 206, 215, 224, 224, 224, 286,\n",
      "        288, 291, 293, 296, 304, 306, 309, 311, 314, 322, 324, 327, 329, 332,\n",
      "        345, 347, 354, 356, 356, 385, 387, 387, 403, 405, 405, 433, 435, 438,\n",
      "        440, 444, 444, 449, 449, 457, 460, 477, 477, 482, 482, 488, 488, 488,\n",
      "        488, 525, 527, 530, 532, 535, 548, 550, 550, 566, 568, 568, 584, 586,\n",
      "        586]) [  0   2   3   5   6   8   9  11  12  14  15  16  17  18  19  20  21  22\n",
      "  23  24  25  26  27  28  29  30  31  32  33  34  35  36  37  38  39  40\n",
      "  41  42  43  44  45  47  48  50  51  52  55  56  57  58  59  60  61  62\n",
      "  63  64  65  66  67  68  69  70  71  72  73  75  76  78  79  81  82  83\n",
      "  84  85  87  89  90  91  93  95  99 100 101 102 103 104 105 107 108 110\n",
      " 111] [2 1 2 1 2 1 2 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 2 1 2 1 1 3 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 2 1 2 1 1 1 1 2\n",
      " 2 1 1 2 2 4 1 1 1 1 1 1 2 1 2 1 2]\n",
      "0 torch.Size([91, 512]) torch.Size([91, 512]) torch.Size([91, 1]) (91,)\n",
      "65\n",
      "tensor([ 12,  14,  24,  26,  36,  38,  48,  50,  60,  62, 161, 193, 195, 201,\n",
      "        203, 207, 207, 207, 216, 216, 216, 225, 234, 243, 243, 243, 357, 359,\n",
      "        359, 388, 388, 393, 393, 406, 406, 417, 417, 445, 447, 450, 452, 452,\n",
      "        458, 461, 461, 461, 478, 480, 483, 485, 489, 489, 494, 494, 502, 505,\n",
      "        551, 551, 556, 556, 569, 571, 571, 587, 589]) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 18 21 22 23 26 27 29 31\n",
      " 33 35 37 38 39 40 42 43 46 47 48 49 50 52 54 55 56 58 60 61 63 64] [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 3 3 1 1 3 1 2 2 2 2 2 1 1 1 2 1 3 1 1 1 1 2\n",
      " 2 1 1 2 2 1 2 1 1]\n",
      "0 torch.Size([46, 512]) torch.Size([46, 512]) torch.Size([46, 1]) (46,)\n",
      "55\n",
      "tensor([ 15,  27,  39,  51,  63, 208, 210, 213, 217, 219, 222, 226, 226, 226,\n",
      "        235, 235, 235, 244, 253, 262, 262, 360, 362, 362, 389, 391, 394, 396,\n",
      "        407, 409, 409, 418, 420, 420, 453, 455, 462, 464, 473, 490, 492, 495,\n",
      "        497, 497, 503, 506, 506, 506, 552, 554, 557, 559, 572, 574, 574]) [ 0  1  2  3  4  5  6  7  8  9 10 11 14 17 18 19 21 22 24 25 26 27 28 29\n",
      " 31 32 34 35 36 37 38 39 40 41 42 44 45 48 49 50 51 52 53] [1 1 1 1 1 1 1 1 1 1 1 3 3 1 1 2 1 2 1 1 1 1 1 2 1 2 1 1 1 1 1 1 1 1 2 1 3\n",
      " 1 1 1 1 1 2]\n",
      "0 torch.Size([43, 512]) torch.Size([43, 512]) torch.Size([43, 1]) (43,)\n",
      "32\n",
      "tensor([211, 220, 227, 229, 232, 236, 238, 241, 245, 245, 245, 254, 254, 254,\n",
      "        263, 272, 363, 365, 410, 412, 412, 421, 423, 465, 465, 498, 500, 507,\n",
      "        509, 518, 575, 577]) [ 0  1  2  3  4  5  6  7  8 11 14 15 16 17 18 19 21 22 23 25 26 27 28 29\n",
      " 30 31] [1 1 1 1 1 1 1 1 3 3 1 1 1 1 1 2 1 1 2 1 1 1 1 1 1 1]\n",
      "0 torch.Size([26, 512]) torch.Size([26, 512]) torch.Size([26, 1]) (26,)\n",
      "21\n",
      "tensor([230, 239, 246, 248, 251, 255, 257, 260, 264, 264, 264, 273, 273, 273,\n",
      "        413, 415, 466, 468, 468, 510, 510]) [ 0  1  2  3  4  5  6  7  8 11 14 15 16 17 19] [1 1 1 1 1 1 1 1 3 3 1 1 1 2 2]\n",
      "0 torch.Size([15, 512]) torch.Size([15, 512]) torch.Size([15, 1]) (15,)\n",
      "13\n",
      "tensor([249, 258, 265, 267, 270, 274, 276, 279, 469, 471, 511, 513, 513]) [ 0  1  2  3  4  5  6  7  8  9 10 11] [1 1 1 1 1 1 1 1 1 1 1 2]\n",
      "0 torch.Size([12, 512]) torch.Size([12, 512]) torch.Size([12, 1]) (12,)\n",
      "4\n",
      "tensor([268, 277, 514, 516]) [0 1 2 3] [1 1 1 1]\n",
      "0 torch.Size([4, 512]) torch.Size([4, 512]) torch.Size([4, 1]) (4,)\n",
      "--------------------\n",
      "1\n",
      "[0] [0] [1]\n",
      "0 torch.Size([1, 512]) torch.Size([1, 512]) torch.Size([1, 1]) (1,)\n",
      "23\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]) [0] [23]\n",
      "0 torch.Size([1, 512]) torch.Size([1, 512]) torch.Size([1, 1]) (1,)\n",
      "47\n",
      "tensor([   1,    1,    8,    8,   15,   15,   22,   22,  118,  118, 1487, 1487,\n",
      "        1502, 1502, 1517, 1517, 1528, 1528, 1539, 1539, 1550, 1550, 1557, 1557,\n",
      "        1564, 1564, 1571, 1571, 1578, 1578, 1585, 1585, 1592, 1592, 1599, 1599,\n",
      "        1606, 1606, 1613, 1613, 1620, 1620, 1627, 1627, 1634, 1634, 1634]) [ 0  2  4  6  8 10 12 14 16 18 20 22 24 26 28 30 32 34 36 38 40 42 44] [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3]\n",
      "0 torch.Size([23, 512]) torch.Size([23, 512]) torch.Size([23, 1]) (23,)\n",
      "74\n",
      "tensor([   2,    6,    9,   13,   16,   20,   23,   25,   25,   25,   25,   25,\n",
      "         119,  121,  121,  121,  121,  121,  121,  121,  121,  121,  121,  121,\n",
      "         121,  121,  121,  121,  121,  121,  121,  121,  121, 1488, 1499, 1503,\n",
      "        1514, 1518, 1525, 1529, 1536, 1540, 1547, 1551, 1554, 1558, 1561, 1565,\n",
      "        1568, 1572, 1575, 1579, 1582, 1586, 1589, 1593, 1596, 1600, 1603, 1607,\n",
      "        1610, 1614, 1617, 1621, 1624, 1628, 1631, 1635, 1637, 1640, 1640, 1640,\n",
      "        1640, 1640]) [ 0  1  2  3  4  5  6  7 12 13 33 34 35 36 37 38 39 40 41 42 43 44 45 46\n",
      " 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69] [ 1  1  1  1  1  1  1  5  1 20  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  5]\n",
      "0 torch.Size([47, 512]) torch.Size([47, 512]) torch.Size([47, 1]) (47,)\n",
      "152\n",
      "tensor([   3,   10,   17,   26,   26,   26,   35,   35,   35,   44,   44,   44,\n",
      "          53,   53,   53,   62,   62,   62,   62,   62,   62,   62,  122,  122,\n",
      "         122,  135,  135,  135,  148,  148,  148,  161,  161,  161,  178,  178,\n",
      "         178,  195,  195,  195,  204,  204,  204,  213,  213,  213,  222,  222,\n",
      "         222,  231,  231,  231,  244,  244,  244,  257,  257,  257,  270,  270,\n",
      "         270,  283,  283,  283,  283,  283,  382,  382,  382,  382,  558,  558,\n",
      "         558,  558,  558,  558,  770,  770,  770,  770, 1159, 1159, 1159, 1159,\n",
      "        1241, 1241, 1241, 1241, 1241, 1241, 1241, 1355, 1355, 1355, 1355, 1355,\n",
      "        1355, 1489, 1489, 1500, 1504, 1504, 1515, 1519, 1519, 1526, 1530, 1530,\n",
      "        1537, 1541, 1541, 1548, 1552, 1555, 1559, 1562, 1566, 1569, 1573, 1576,\n",
      "        1580, 1583, 1587, 1590, 1594, 1597, 1601, 1604, 1608, 1611, 1615, 1618,\n",
      "        1622, 1625, 1629, 1632, 1638, 1641, 1641, 1641, 1649, 1649, 1649, 1657,\n",
      "        1657, 1657, 1665, 1665, 1673, 1673, 1673, 1673]) [  0   1   2   3   6   9  12  15  22  25  28  31  34  37  40  43  46  49\n",
      "  52  55  58  61  66  70  76  80  84  91  97  99 100 102 103 105 106 108\n",
      " 109 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127\n",
      " 128 129 130 131 132 133 134 135 136 137 140 143 146 148] [1 1 1 3 3 3 3 7 3 3 3 3 3 3 3 3 3 3 3 3 3 5 4 6 4 4 7 6 2 1 2 1 2 1 2 1 2\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 3 3 3 2 4]\n",
      "0 torch.Size([68, 512]) torch.Size([68, 512]) torch.Size([68, 1]) (68,)\n",
      "182\n",
      "tensor([   4,   11,   18,   27,   29,   32,   36,   38,   41,   45,   47,   50,\n",
      "          54,   56,   59,   63,   65,   67,   67,   74,   74,   81,   81,   88,\n",
      "          88,   97,   97,   97,   97,  123,  125,  132,  136,  138,  145,  149,\n",
      "         151,  158,  162,  164,  175,  179,  181,  192,  196,  198,  201,  205,\n",
      "         207,  210,  214,  216,  219,  223,  225,  228,  232,  234,  241,  245,\n",
      "         247,  254,  258,  260,  267,  271,  273,  280,  284,  286,  288,  291,\n",
      "         291,  298,  383,  385,  387,  390,  390,  390,  390,  390,  390,  559,\n",
      "         561,  563,  566,  566,  573,  573,  580,  580,  580,  580,  771,  773,\n",
      "         775,  778,  778,  778,  778,  778,  778,  778,  778,  778,  778,  778,\n",
      "        1160, 1162, 1164, 1164, 1173, 1173, 1173, 1173, 1242, 1244, 1246, 1249,\n",
      "        1249, 1256, 1256, 1263, 1263, 1270, 1270, 1270, 1270, 1270, 1356, 1358,\n",
      "        1360, 1363, 1363, 1370, 1370, 1377, 1377, 1377, 1377, 1377, 1377, 1490,\n",
      "        1490, 1496, 1505, 1505, 1511, 1520, 1522, 1531, 1533, 1542, 1544, 1642,\n",
      "        1644, 1647, 1650, 1652, 1655, 1658, 1660, 1663, 1666, 1668, 1668, 1674,\n",
      "        1674, 1679, 1679, 1684, 1687, 1687, 1687, 1687, 1687, 1687, 1687, 1687,\n",
      "        1687, 1687]) [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  19  21  23  25  29  30  31  32  33  34  35  36  37  38  39  40  41  42\n",
      "  43  44  45  46  47  48  49  50  51  52  53  54  55  56  57  58  59  60\n",
      "  61  62  63  64  65  66  67  68  69  70  71  73  74  75  76  77  83  84\n",
      "  85  86  88  90  94  95  96  97 108 109 110 112 116 117 118 119 121 123\n",
      " 125 130 131 132 133 135 137 143 145 146 148 149 150 151 152 153 154 155\n",
      " 156 157 158 159 160 161 162 163 164 165 167 169 171 172] [ 1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  2  2  2  2  4  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  2  1  1  1  1  6  1  1\n",
      "  1  2  2  4  1  1  1 11  1  1  2  4  1  1  1  2  2  2  5  1  1  1  2  2\n",
      "  6  2  1  2  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  2  2  2\n",
      "  1 10]\n",
      "0 torch.Size([122, 512]) torch.Size([122, 512]) torch.Size([122, 1]) (122,)\n",
      "227\n",
      "tensor([  30,   33,   39,   42,   48,   51,   57,   60,   68,   71,   75,   78,\n",
      "          82,   85,   89,   92,   92,   98,   98,  103,  103,  108,  108,  113,\n",
      "         113,  126,  126,  133,  139,  139,  146,  152,  152,  159,  165,  165,\n",
      "         176,  182,  182,  193,  199,  202,  208,  211,  217,  220,  226,  229,\n",
      "         235,  235,  242,  248,  248,  255,  261,  261,  268,  274,  274,  281,\n",
      "         289,  292,  295,  299,  299,  299,  388,  391,  391,  391,  391,  419,\n",
      "         419,  427,  427,  427,  435,  435,  456,  456,  456,  456,  484,  484,\n",
      "         484,  484,  564,  567,  570,  574,  577,  581,  581,  591,  591,  601,\n",
      "         601,  601,  601,  767,  776,  779,  779,  817,  817,  825,  825,  825,\n",
      "         825,  942,  942,  950,  950,  950,  950, 1020, 1020, 1028, 1028, 1028,\n",
      "        1028, 1098, 1098, 1106, 1106, 1106, 1106, 1143, 1143, 1151, 1151, 1165,\n",
      "        1168, 1168, 1174, 1174, 1179, 1179, 1179, 1179, 1231, 1231, 1236, 1236,\n",
      "        1247, 1250, 1253, 1257, 1260, 1264, 1267, 1271, 1287, 1287, 1287, 1308,\n",
      "        1308, 1308, 1322, 1322, 1322, 1341, 1341, 1341, 1361, 1364, 1367, 1371,\n",
      "        1374, 1378, 1378, 1383, 1383, 1388, 1388, 1393, 1403, 1403, 1411, 1411,\n",
      "        1491, 1493, 1497, 1506, 1508, 1512, 1523, 1534, 1545, 1645, 1653, 1661,\n",
      "        1669, 1671, 1675, 1677, 1680, 1682, 1685, 1688, 1688, 1708, 1729, 1729,\n",
      "        1729, 1729, 1760, 1760, 1760, 1760, 1831, 1831, 1831, 1831, 1894, 1894,\n",
      "        1899, 1899, 1899, 1899, 1983, 1983, 2002, 2002, 2002, 2265, 2265]) [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  17  19\n",
      "  21  23  25  27  28  30  31  33  34  36  37  39  40  41  42  43  44  45\n",
      "  46  47  48  50  51  53  54  56  57  59  60  61  62  63  66  67  71  73\n",
      "  76  78  82  86  87  88  89  90  91  93  95  99 100 101 103 105 109 111\n",
      " 115 117 121 123 127 129 131 132 134 136 140 142 144 145 146 147 148 149\n",
      " 150 151 152 155 158 161 164 165 166 167 168 169 171 173 175 176 178 180\n",
      " 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198\n",
      " 199 201 202 206 210 214 216 220 222 225] [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 1 2 1 2 1 2 1 2 1 1 1 1 1 1 1 1\n",
      " 1 2 1 2 1 2 1 2 1 1 1 1 3 1 4 2 3 2 4 4 1 1 1 1 1 2 2 4 1 1 2 2 4 2 4 2 4\n",
      " 2 4 2 2 1 2 2 4 2 2 1 1 1 1 1 1 1 1 3 3 3 3 1 1 1 1 1 2 2 2 1 2 2 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 4 4 4 2 4 2 3 2]\n",
      "0 torch.Size([136, 512]) torch.Size([136, 512]) torch.Size([136, 1]) (136,)\n",
      "252\n",
      "tensor([  69,   72,   76,   79,   83,   86,   90,   93,   95,   99,  101,  104,\n",
      "         106,  109,  111,  114,  116,  127,  129,  140,  142,  153,  155,  166,\n",
      "         166,  172,  183,  183,  189,  236,  238,  249,  251,  262,  264,  275,\n",
      "         277,  293,  296,  300,  300,  307,  307,  312,  392,  402,  402,  407,\n",
      "         410,  420,  420,  425,  428,  430,  433,  436,  436,  441,  441,  457,\n",
      "         467,  467,  472,  475,  485,  495,  495,  503,  506,  568,  571,  575,\n",
      "         578,  582,  582,  587,  592,  592,  597,  602,  602,  613,  613,  627,\n",
      "         633,  633,  633,  633,  633,  633,  633,  768,  780,  782,  782,  818,\n",
      "         820,  820,  826,  836,  836,  844,  847,  943,  945,  945,  951,  961,\n",
      "         961,  966,  969,  969,  969, 1021, 1023, 1023, 1029, 1039, 1039, 1044,\n",
      "        1047, 1047, 1047, 1099, 1101, 1101, 1107, 1117, 1117, 1122, 1125, 1144,\n",
      "        1146, 1146, 1152, 1154, 1154, 1166, 1169, 1171, 1175, 1177, 1180, 1190,\n",
      "        1190, 1195, 1198, 1198, 1198, 1198, 1232, 1234, 1237, 1239, 1251, 1254,\n",
      "        1258, 1261, 1265, 1268, 1272, 1272, 1288, 1290, 1306, 1309, 1311, 1317,\n",
      "        1317, 1323, 1325, 1339, 1342, 1344, 1350, 1350, 1365, 1368, 1372, 1375,\n",
      "        1379, 1381, 1384, 1386, 1389, 1391, 1394, 1394, 1404, 1406, 1406, 1412,\n",
      "        1414, 1414, 1414, 1414, 1414, 1494, 1509, 1689, 1691, 1691, 1709, 1709,\n",
      "        1730, 1730, 1735, 1735, 1740, 1743, 1743, 1761, 1761, 1766, 1766, 1771,\n",
      "        1774, 1774, 1774, 1774, 1832, 1832, 1837, 1837, 1842, 1845, 1845, 1845,\n",
      "        1895, 1897, 1900, 1900, 1905, 1905, 1910, 1913, 1913, 1913, 1984, 1986,\n",
      "        1986, 1986, 2003, 2003, 2008, 2041, 2041, 2041, 2041, 2266, 2268, 2268]) [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  25  26  28  29  30  31  32  33  34  35  36  37\n",
      "  38  39  41  43  44  45  47  48  49  51  52  53  54  55  57  59  60  62\n",
      "  63  64  65  67  68  69  70  71  72  73  75  76  78  79  81  83  84  91\n",
      "  92  93  95  96  98  99 101 102 103 104 106 107 109 110 113 114 116 117\n",
      " 119 120 123 124 126 127 129 130 131 132 134 135 137 138 139 140 141 142\n",
      " 143 145 146 150 151 152 153 154 155 156 157 158 159 160 162 163 164 165\n",
      " 166 167 169 170 171 172 173 174 176 177 178 179 180 181 182 183 184 185\n",
      " 186 188 189 191 192 197 198 199 200 202 204 206 208 209 211 213 215 216\n",
      " 220 222 224 225 228 229 230 232 234 235 238 239 242 244 245 249 250] [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 2 1 1 1 1 1 1 1 1 1 1 1\n",
      " 2 2 1 1 2 1 1 2 1 1 1 1 2 2 1 2 1 1 1 2 1 1 1 1 1 1 2 1 2 1 2 2 1 7 1 1 2\n",
      " 1 2 1 2 1 1 1 2 1 2 1 3 1 2 1 2 1 3 1 2 1 2 1 1 1 2 1 2 1 1 1 1 1 1 2 1 4\n",
      " 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 2 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 2 1 2 1\n",
      " 5 1 1 1 2 2 2 2 1 2 2 2 1 4 2 2 1 3 1 1 2 2 1 3 1 3 2 1 4 1 2]\n",
      "0 torch.Size([179, 512]) torch.Size([179, 512]) torch.Size([179, 1]) (179,)\n",
      "256\n",
      "tensor([ 130,  143,  156,  167,  169,  173,  184,  186,  190,  239,  252,  265,\n",
      "         278,  301,  304,  308,  310,  313,  313,  393,  393,  403,  405,  408,\n",
      "         411,  411,  421,  423,  431,  437,  439,  442,  442,  451,  451,  458,\n",
      "         458,  468,  470,  473,  476,  476,  486,  486,  496,  498,  498,  504,\n",
      "         507,  507,  583,  585,  588,  593,  595,  598,  603,  603,  608,  608,\n",
      "         614,  614,  619,  619,  628,  628,  634,  656,  656,  670,  724,  724,\n",
      "         730,  730,  743,  743,  764,  783,  783,  815,  821,  823,  827,  827,\n",
      "         837,  839,  839,  845,  848,  848,  946,  948,  952,  952,  962,  964,\n",
      "         967,  970,  970,  984,  984,  984, 1012, 1012, 1024, 1026, 1030, 1030,\n",
      "        1040, 1042, 1045, 1048, 1048, 1062, 1062, 1062, 1090, 1090, 1102, 1104,\n",
      "        1108, 1108, 1118, 1120, 1123, 1126, 1126, 1147, 1149, 1155, 1157, 1181,\n",
      "        1181, 1191, 1193, 1196, 1199, 1199, 1207, 1207, 1215, 1215, 1223, 1223,\n",
      "        1273, 1276, 1276, 1291, 1291, 1312, 1312, 1318, 1320, 1326, 1326, 1345,\n",
      "        1345, 1351, 1353, 1395, 1398, 1398, 1407, 1409, 1415, 1418, 1421, 1421,\n",
      "        1434, 1434, 1434, 1434, 1462, 1462, 1462, 1692, 1692, 1706, 1710, 1714,\n",
      "        1714, 1731, 1733, 1736, 1738, 1741, 1744, 1744, 1752, 1752, 1762, 1764,\n",
      "        1767, 1769, 1772, 1775, 1775, 1795, 1795, 1803, 1803, 1803, 1817, 1817,\n",
      "        1817, 1833, 1835, 1838, 1840, 1843, 1846, 1846, 1846, 1858, 1858, 1858,\n",
      "        1876, 1876, 1876, 1901, 1903, 1906, 1908, 1911, 1914, 1914, 1951, 1951,\n",
      "        1959, 1959, 1959, 1987, 1989, 1989, 2000, 2004, 2006, 2009, 2009, 2009,\n",
      "        2009, 2042, 2042, 2042, 2125, 2125, 2130, 2130, 2130, 2130, 2208, 2208,\n",
      "        2208, 2208, 2269, 2271]) [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  19  21  22  23  24  26  27  28  29  30  31  33  35  37  38  39  40  42\n",
      "  44  45  47  48  50  51  52  53  54  55  56  58  60  62  64  66  67  69\n",
      "  70  72  74  76  77  79  80  81  82  84  85  87  88  90  91  92  94  95\n",
      "  96  97  99 102 104 105 106 108 109 110 111 113 116 118 119 120 122 123\n",
      " 124 125 127 128 129 130 131 133 134 135 136 138 140 142 144 145 147 149\n",
      " 151 152 153 155 157 158 159 160 162 163 164 165 166 168 172 175 177 178\n",
      " 179 181 182 183 184 185 186 188 190 191 192 193 194 195 197 199 202 205\n",
      " 206 207 208 209 210 213 216 219 220 221 222 223 224 226 228 231 232 234\n",
      " 235 236 237 241 244 246 250 254 255] [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 1 1 1 2 1 1 1 1 1 2 2 2 1 1 1 2 2 1\n",
      " 2 1 2 1 1 1 1 1 1 2 2 2 2 2 1 2 1 2 2 2 1 2 1 1 1 2 1 2 1 2 1 1 2 1 1 1 2\n",
      " 3 2 1 1 2 1 1 1 2 3 2 1 1 2 1 1 1 2 1 1 1 1 2 1 1 1 2 2 2 2 1 2 2 2 1 1 2\n",
      " 2 1 1 1 2 1 1 1 1 2 4 3 2 1 1 2 1 1 1 1 1 2 2 1 1 1 1 1 2 2 3 3 1 1 1 1 1\n",
      " 3 3 3 1 1 1 1 1 2 2 3 1 2 1 1 1 4 3 2 4 4 1 1]\n",
      "0 torch.Size([171, 512]) torch.Size([171, 512]) torch.Size([171, 1]) (171,)\n",
      "234\n",
      "tensor([ 170,  187,  302,  305,  314,  314,  343,  343,  394,  397,  397,  412,\n",
      "         412,  417,  443,  445,  452,  454,  459,  462,  462,  477,  479,  479,\n",
      "         487,  490,  490,  499,  501,  508,  508,  538,  589,  599,  604,  606,\n",
      "         609,  611,  615,  617,  620,  622,  622,  629,  631,  635,  635,  657,\n",
      "         668,  671,  671,  725,  728,  731,  731,  741,  744,  744,  762,  765,\n",
      "         784,  786,  786,  828,  831,  831,  840,  842,  849,  851,  851,  953,\n",
      "         956,  956,  971,  973,  973,  985,  985,  992,  992,  997, 1013, 1015,\n",
      "        1015, 1031, 1034, 1034, 1049, 1051, 1051, 1063, 1063, 1070, 1070, 1075,\n",
      "        1091, 1093, 1093, 1109, 1112, 1112, 1127, 1129, 1129, 1182, 1185, 1185,\n",
      "        1200, 1202, 1202, 1208, 1210, 1210, 1216, 1216, 1221, 1224, 1224, 1229,\n",
      "        1274, 1277, 1279, 1279, 1292, 1294, 1294, 1294, 1294, 1313, 1315, 1327,\n",
      "        1329, 1329, 1329, 1346, 1348, 1396, 1399, 1401, 1416, 1419, 1422, 1422,\n",
      "        1430, 1435, 1445, 1445, 1450, 1453, 1463, 1463, 1478, 1481, 1693, 1695,\n",
      "        1695, 1711, 1715, 1717, 1717, 1745, 1747, 1747, 1753, 1755, 1755, 1776,\n",
      "        1778, 1778, 1796, 1796, 1801, 1804, 1806, 1809, 1809, 1818, 1820, 1823,\n",
      "        1823, 1847, 1849, 1849, 1849, 1856, 1859, 1861, 1861, 1861, 1874, 1877,\n",
      "        1879, 1879, 1879, 1892, 1915, 1917, 1952, 1954, 1954, 1960, 1962, 1962,\n",
      "        1962, 1981, 1990, 1992, 1992, 2010, 2010, 2015, 2015, 2020, 2023, 2043,\n",
      "        2043, 2050, 2050, 2054, 2126, 2128, 2131, 2131, 2136, 2136, 2141, 2144,\n",
      "        2209, 2209, 2214, 2214, 2219, 2222]) [  0   1   2   3   4   6   8   9  11  13  14  15  16  17  18  19  21  22\n",
      "  24  25  27  28  29  31  32  33  34  35  36  37  38  39  40  41  43  44\n",
      "  45  47  48  49  51  52  53  55  56  58  59  60  61  63  64  66  67  68\n",
      "  69  71  72  74  75  77  79  81  82  83  85  86  88  89  91  93  95  96\n",
      "  97  99 100 102 103 105 106 108 109 111 112 114 116 117 119 120 121 122\n",
      " 124 125 129 130 131 132 135 136 137 138 139 140 141 142 144 145 146 148\n",
      " 149 150 152 153 154 155 157 158 159 161 162 164 165 167 168 170 172 173\n",
      " 174 175 177 178 179 181 182 185 186 187 190 191 192 195 196 197 198 199\n",
      " 201 202 205 206 207 209 211 213 214 215 217 219 220 221 222 224 226 227\n",
      " 228 230 232 233] [1 1 1 1 2 2 1 2 2 1 1 1 1 1 1 2 1 2 1 2 1 1 2 1 1 1 1 1 1 1 1 1 1 2 1 1 2\n",
      " 1 1 2 1 1 2 1 2 1 1 1 2 1 2 1 1 1 2 1 2 1 2 2 2 1 1 2 1 2 1 2 2 2 1 1 2 1\n",
      " 2 1 2 1 2 1 2 1 2 2 1 2 1 1 1 2 1 4 1 1 1 3 1 1 1 1 1 1 1 2 1 1 2 1 1 2 1\n",
      " 1 1 2 1 1 2 1 2 1 2 1 2 2 1 1 1 2 1 1 2 1 3 1 1 3 1 1 3 1 1 1 1 2 1 3 1 1\n",
      " 2 2 2 1 1 2 2 1 1 1 2 2 1 1 2 2 1 1]\n",
      "0 torch.Size([166, 512]) torch.Size([166, 512]) torch.Size([166, 1]) (166,)\n",
      "204\n",
      "tensor([ 315,  326,  344,  344,  366,  366,  366,  395,  398,  400,  413,  415,\n",
      "         446,  446,  460,  463,  465,  480,  482,  488,  491,  493,  509,  509,\n",
      "         536,  539,  539,  539,  623,  625,  636,  639,  639,  658,  658,  672,\n",
      "         675,  675,  726,  733,  733,  746,  746,  787,  787,  813,  829,  832,\n",
      "         834,  852,  852,  940,  954,  957,  959,  974,  974,  982,  986,  989,\n",
      "         993,  995,  998,  998, 1016, 1018, 1032, 1035, 1037, 1052, 1052, 1060,\n",
      "        1064, 1067, 1071, 1073, 1076, 1076, 1094, 1096, 1110, 1113, 1115, 1130,\n",
      "        1130, 1141, 1183, 1186, 1188, 1203, 1205, 1211, 1213, 1217, 1219, 1225,\n",
      "        1227, 1280, 1280, 1285, 1295, 1297, 1299, 1299, 1304, 1330, 1332, 1334,\n",
      "        1334, 1423, 1423, 1428, 1431, 1436, 1436, 1446, 1448, 1451, 1454, 1454,\n",
      "        1464, 1467, 1467, 1479, 1482, 1482, 1696, 1696, 1704, 1712, 1718, 1720,\n",
      "        1748, 1750, 1756, 1758, 1779, 1779, 1790, 1790, 1797, 1799, 1807, 1810,\n",
      "        1812, 1812, 1821, 1824, 1826, 1826, 1850, 1852, 1854, 1862, 1864, 1864,\n",
      "        1872, 1880, 1882, 1882, 1890, 1918, 1918, 1918, 1955, 1957, 1963, 1963,\n",
      "        1968, 1968, 1976, 1976, 1993, 1993, 1998, 2011, 2013, 2016, 2018, 2021,\n",
      "        2024, 2024, 2044, 2047, 2052, 2055, 2055, 2132, 2134, 2137, 2139, 2142,\n",
      "        2145, 2145, 2145, 2145, 2210, 2212, 2215, 2217, 2220, 2223, 2223, 2223]) [  0   1   2   4   7   8   9  10  11  12  14  15  16  17  18  19  20  21\n",
      "  22  24  25  28  29  30  31  33  35  36  38  39  41  43  45  46  47  48\n",
      "  49  51  52  53  54  55  57  58  59  60  61  62  64  65  66  67  68  69\n",
      "  71  72  73  74  75  76  78  79  80  81  82  83  85  86  87  88  89  90\n",
      "  91  92  93  94  95  96  97  99 100 101 102 104 105 106 107 109 111 112\n",
      " 113 115 116 117 118 120 121 123 124 126 128 129 130 131 132 133 134 135\n",
      " 136 138 140 141 142 143 144 146 147 148 150 151 152 153 154 156 157 158\n",
      " 160 161 164 165 166 168 170 172 174 175 176 177 178 179 180 182 183 184\n",
      " 185 187 188 189 190 191 192 196 197 198 199 200 201] [1 1 2 3 1 1 1 1 1 2 1 1 1 1 1 1 1 1 2 1 3 1 1 1 2 2 1 2 1 2 2 2 1 1 1 1 2\n",
      " 1 1 1 1 2 1 1 1 1 1 2 1 1 1 1 1 2 1 1 1 1 1 2 1 1 1 1 1 2 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 2 1 1 1 2 1 1 1 2 2 1 1 2 1 1 1 2 1 2 1 2 2 1 1 1 1 1 1 1 1 2 2 1\n",
      " 1 1 1 2 1 1 2 1 1 1 1 2 1 1 2 1 3 1 1 2 2 2 2 1 1 1 1 1 1 2 1 1 1 2 1 1 1\n",
      " 1 1 4 1 1 1 1 1 3]\n",
      "0 torch.Size([157, 512]) torch.Size([157, 512]) torch.Size([157, 1]) (157,)\n",
      "136\n",
      "tensor([ 316,  316,  327,  327,  345,  345,  358,  358,  367,  369,  380,  447,\n",
      "         449,  510,  510,  523,  523,  540,  542,  545,  545,  637,  640,  642,\n",
      "         642,  660,  660,  673,  676,  678,  678,  734,  736,  736,  747,  749,\n",
      "         749,  788,  790,  790,  853,  855,  855,  975,  977,  977,  987,  990,\n",
      "         999, 1001, 1001, 1053, 1055, 1055, 1065, 1068, 1077, 1079, 1079, 1131,\n",
      "        1133, 1133, 1281, 1283, 1300, 1302, 1335, 1337, 1424, 1426, 1432, 1437,\n",
      "        1440, 1440, 1455, 1455, 1460, 1465, 1468, 1470, 1470, 1483, 1485, 1697,\n",
      "        1699, 1699, 1721, 1721, 1780, 1782, 1782, 1791, 1793, 1813, 1815, 1827,\n",
      "        1829, 1865, 1867, 1867, 1883, 1885, 1885, 1919, 1936, 1939, 1964, 1966,\n",
      "        1969, 1969, 1974, 1977, 1979, 1994, 1996, 2025, 2027, 2027, 2045, 2048,\n",
      "        2056, 2056, 2106, 2146, 2146, 2151, 2151, 2162, 2162, 2167, 2167, 2167,\n",
      "        2224, 2224, 2229, 2247]) [  0   2   4   6   8   9  10  11  12  13  15  17  18  19  21  22  23  25\n",
      "  27  28  29  31  32  34  35  37  38  40  41  43  44  46  47  48  49  51\n",
      "  52  54  55  56  57  59  60  62  63  64  65  66  67  68  69  70  71  72\n",
      "  74  76  77  78  79  81  82  83  84  86  88  89  91  92  93  94  95  96\n",
      "  97  98 100 101 103 104 105 106 107 108 110 111 112 113 114 115 116 118\n",
      " 119 120 122 123 125 127 129 132 134 135] [2 2 2 2 1 1 1 1 1 2 2 1 1 2 1 1 2 2 1 1 2 1 2 1 2 1 2 1 2 1 2 1 1 1 2 1 2\n",
      " 1 1 1 2 1 2 1 1 1 1 1 1 1 1 1 1 2 2 1 1 1 2 1 1 1 2 2 1 2 1 1 1 1 1 1 1 2\n",
      " 1 2 1 1 1 1 1 2 1 1 1 1 1 1 2 1 1 2 1 2 2 2 3 2 1 1]\n",
      "0 torch.Size([100, 512]) torch.Size([100, 512]) torch.Size([100, 1]) (100,)\n",
      "111\n",
      "tensor([ 318,  318,  328,  328,  341,  346,  348,  348,  359,  359,  364,  370,\n",
      "         370,  511,  513,  513,  524,  526,  526,  543,  546,  548,  548,  643,\n",
      "         645,  645,  661,  663,  663,  679,  681,  681,  737,  739,  750,  752,\n",
      "         752,  791,  791,  811,  856,  856,  930,  930,  978,  980, 1002, 1002,\n",
      "        1010, 1056, 1058, 1080, 1080, 1088, 1134, 1136, 1136, 1438, 1441, 1443,\n",
      "        1456, 1458, 1471, 1473, 1473, 1700, 1702, 1722, 1722, 1727, 1783, 1785,\n",
      "        1785, 1868, 1870, 1886, 1888, 1920, 1920, 1937, 1940, 1940, 1970, 1972,\n",
      "        2028, 2028, 2039, 2057, 2057, 2098, 2107, 2107, 2107, 2147, 2149, 2152,\n",
      "        2154, 2154, 2163, 2165, 2168, 2171, 2171, 2188, 2188, 2225, 2227, 2230,\n",
      "        2230, 2248, 2248]) [  0   2   4   5   6   8  10  11  13  14  16  17  19  20  21  23  24  26\n",
      "  27  29  30  32  33  34  35  37  39  40  42  44  45  46  48  49  50  51\n",
      "  53  54  55  57  58  59  60  61  62  63  65  66  67  69  70  71  73  74\n",
      "  75  76  77  79  80  82  83  84  86  87  89  90  93  94  95  96  98  99\n",
      " 100 101 103 105 106 107 109] [2 2 1 1 2 2 1 2 1 2 1 2 1 1 2 1 2 1 2 1 2 1 1 1 2 2 1 2 2 1 1 2 1 1 1 2 1\n",
      " 1 2 1 1 1 1 1 1 2 1 1 2 1 1 2 1 1 1 1 2 1 2 1 1 2 1 2 1 3 1 1 1 2 1 1 1 2\n",
      " 2 1 1 2 2]\n",
      "0 torch.Size([79, 512]) torch.Size([79, 512]) torch.Size([79, 1]) (79,)\n",
      "84\n",
      "tensor([ 319,  321,  321,  329,  331,  331,  350,  350,  360,  362,  372,  372,\n",
      "         515,  515,  528,  528,  550,  550,  646,  646,  651,  651,  664,  666,\n",
      "         682,  682,  692,  754,  754,  792,  794,  794,  857,  859,  859,  932,\n",
      "         932, 1003, 1005, 1005, 1081, 1083, 1083, 1137, 1139, 1474, 1476, 1723,\n",
      "        1725, 1786, 1788, 1921, 1924, 1941, 1941, 1949, 2029, 2031, 2031, 2058,\n",
      "        2058, 2087, 2099, 2099, 2108, 2110, 2115, 2115, 2155, 2157, 2157, 2169,\n",
      "        2172, 2172, 2186, 2189, 2189, 2206, 2231, 2233, 2233, 2249, 2251, 2251]) [ 0  1  3  4  6  8  9 10 12 14 16 18 20 22 23 24 26 27 29 30 32 33 35 37\n",
      " 38 40 41 43 44 45 46 47 48 49 50 51 52 53 55 56 57 59 61 62 64 65 66 68\n",
      " 69 71 72 74 75 77 78 79 81 82] [1 2 1 2 2 1 1 2 2 2 2 2 2 1 1 2 1 2 1 2 1 2 2 1 2 1 2 1 1 1 1 1 1 1 1 1 1\n",
      " 2 1 1 2 2 1 2 1 1 2 1 2 1 2 1 2 1 1 2 1 2]\n",
      "0 torch.Size([58, 512]) torch.Size([58, 512]) torch.Size([58, 1]) (58,)\n",
      "80\n",
      "tensor([ 322,  324,  333,  333,  351,  353,  353,  373,  375,  375,  516,  518,\n",
      "         518,  529,  531,  531,  551,  553,  553,  647,  649,  652,  654,  684,\n",
      "         684,  693,  693,  693,  755,  757,  757,  795,  795,  809,  860,  860,\n",
      "         928,  933,  935,  935, 1006, 1008, 1084, 1086, 1922, 1925, 1925, 1942,\n",
      "        1944, 1944, 2032, 2034, 2034, 2059, 2059, 2076, 2088, 2088, 2100, 2100,\n",
      "        2104, 2111, 2111, 2116, 2118, 2118, 2158, 2160, 2173, 2175, 2175, 2190,\n",
      "        2192, 2192, 2234, 2234, 2245, 2252, 2252, 2263]) [ 0  1  2  4  5  7  8 10 11 13 14 16 17 19 20 21 22 23 25 28 29 31 33 34\n",
      " 36 37 38 40 41 42 43 44 45 47 48 50 51 53 55 56 58 60 61 63 64 66 67 68\n",
      " 69 71 72 74 76 77 79] [1 1 2 1 2 1 2 1 2 1 2 1 2 1 1 1 1 2 3 1 2 2 1 2 1 1 2 1 1 1 1 1 2 1 2 1 2\n",
      " 2 1 2 2 1 2 1 2 1 1 1 2 1 2 2 1 2 1]\n",
      "0 torch.Size([55, 512]) torch.Size([55, 512]) torch.Size([55, 1]) (55,)\n",
      "61\n",
      "tensor([ 334,  336,  336,  354,  356,  376,  378,  519,  521,  532,  534,  554,\n",
      "         556,  685,  687,  687,  694,  710,  713,  758,  760,  796,  798,  798,\n",
      "         861,  863,  863,  936,  938, 1926, 1926, 1934, 1945, 1947, 2035, 2037,\n",
      "        2060, 2068, 2077, 2077, 2089, 2089, 2093, 2093, 2102, 2113, 2119, 2119,\n",
      "        2123, 2176, 2178, 2178, 2193, 2195, 2195, 2235, 2237, 2237, 2253, 2255,\n",
      "        2255]) [ 0  1  3  4  5  6  7  8  9 10 11 12 13 14 16 17 18 19 20 21 22 24 25 27\n",
      " 28 29 31 32 33 34 35 36 37 38 40 42 44 45 46 48 49 50 52 53 55 56 58 59] [1 2 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 2 1 2 1 1 2 1 1 1 1 1 1 1 2 2 2 1\n",
      " 1 2 1 1 2 1 2 1 2 1 2]\n",
      "0 torch.Size([48, 512]) torch.Size([48, 512]) torch.Size([48, 1]) (48,)\n",
      "44\n",
      "tensor([ 337,  339,  688,  690,  695,  695,  711,  714,  714,  799,  799,  807,\n",
      "         864,  864,  918,  918, 1927, 1929, 1929, 2061, 2061, 2069, 2069, 2078,\n",
      "        2078, 2082, 2082, 2091, 2094, 2096, 2121, 2179, 2179, 2184, 2196, 2196,\n",
      "        2201, 2201, 2238, 2240, 2240, 2256, 2258, 2258]) [ 0  1  2  3  4  6  7  9 11 12 14 16 17 19 21 23 25 27 28 29 30 31 33 34\n",
      " 36 38 39 41 42] [1 1 1 1 2 1 2 2 1 2 2 1 2 2 2 2 2 1 1 1 1 2 1 2 2 1 2 1 2]\n",
      "0 torch.Size([29, 512]) torch.Size([29, 512]) torch.Size([29, 1]) (29,)\n",
      "33\n",
      "tensor([ 696,  699,  716,  716,  800,  802,  802,  865,  867,  867,  920,  920,\n",
      "        1930, 1932, 2062, 2062, 2066, 2070, 2070, 2074, 2080, 2083, 2085, 2180,\n",
      "        2182, 2197, 2199, 2202, 2204, 2241, 2243, 2259, 2261]) [ 0  1  2  4  5  7  8 10 12 13 14 16 17 19 20 21 22 23 24 25 26 27 28 29\n",
      " 30 31 32] [1 1 2 1 2 1 2 2 1 1 2 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "0 torch.Size([27, 512]) torch.Size([27, 512]) torch.Size([27, 1]) (27,)\n",
      "16\n",
      "tensor([ 697,  700,  700,  717,  719,  719,  803,  805,  868,  868,  916,  921,\n",
      "         923,  923, 2064, 2072]) [ 0  1  3  4  6  7  8 10 11 12 14 15] [1 2 1 2 1 1 2 1 1 2 1 1]\n",
      "0 torch.Size([12, 512]) torch.Size([12, 512]) torch.Size([12, 1]) (12,)\n",
      "9\n",
      "tensor([702, 702, 720, 722, 869, 871, 871, 924, 926]) [0 2 3 4 5 7 8] [2 1 1 1 2 1 1]\n",
      "0 torch.Size([7, 512]) torch.Size([7, 512]) torch.Size([7, 1]) (7,)\n",
      "7\n",
      "tensor([703, 705, 705, 872, 872, 906, 906]) [0 1 3 5] [1 2 2 2]\n",
      "0 torch.Size([4, 512]) torch.Size([4, 512]) torch.Size([4, 1]) (4,)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-84-e18328568336>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/mnt/9C9AB7DB9AB7B05E/Linux/documents/Thesis-Autoencoders_as_Tools_for_Program_Synthesis/autoencoder_program_synthesis/models/Vae.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, data_loader, epochs, save_dir)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkl_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m                 \u001b[0mreconstruction_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkl_loss\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'KL_LOSS_WEIGHT'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mreconstruction_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m                 \u001b[0;31m# loss.backward()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/9C9AB7DB9AB7B05E/Linux/documents/Thesis-Autoencoders_as_Tools_for_Program_Synthesis/autoencoder_program_synthesis/venv/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/9C9AB7DB9AB7B05E/Linux/documents/Thesis-Autoencoders_as_Tools_for_Program_Synthesis/autoencoder_program_synthesis/models/TreeLstmDecoderComplete.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, z, target, idx_to_label)\u001b[0m\n\u001b[1;32m     71\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0miteration\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_order\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_order\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnode_order\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0miteration\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_p\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc_p\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_order\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_order\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madj_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocabs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'--------------------'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/9C9AB7DB9AB7B05E/Linux/documents/Thesis-Autoencoders_as_Tools_for_Program_Synthesis/autoencoder_program_synthesis/models/TreeLstmDecoderComplete.py\u001b[0m in \u001b[0;36mdecode_train\u001b[0;34m(self, iteration, z, h_p, c_p, h_s, c_s, node_order, edge_order, features, adj_list, vocabs)\u001b[0m\n\u001b[1;32m    139\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction_layer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprediction_layers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m                 \u001b[0;31m# Only do actual calculations when the amount of nodes for this node type > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh_pred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvocabs_mask\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m                     \u001b[0;31m# Get label predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m                     \u001b[0mlabel_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprediction_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh_pred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvocabs_mask\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "vae.train(loader, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('long long', 0),\n",
       " ('unsigned long long', 1),\n",
       " ('long double', 2),\n",
       " ('int', 3),\n",
       " ('vector', 4),\n",
       " ('ll', 5),\n",
       " ('long', 6),\n",
       " ('void', 7),\n",
       " ('map', 8),\n",
       " ('auto', 9)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(label_to_idx['TYPE'].items())[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in loader:\n",
    "    data = batch\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-3.3389e-01,  1.9751e-01, -1.8793e-01, -1.1980e-01, -5.9755e-02,\n",
       "          -3.5950e-02, -1.3164e-01,  1.6563e-01,  1.1352e-01,  2.8221e-01,\n",
       "          -6.6503e-02,  3.2711e-02, -5.0739e-02,  1.8506e-01, -2.4924e-01,\n",
       "           1.3487e-01,  2.4788e-01, -9.2555e-02, -9.6602e-02,  8.9380e-02,\n",
       "           1.8473e-01, -2.8173e-01,  1.2722e-01,  1.9223e-01,  4.4407e-01,\n",
       "          -1.6389e-01,  2.8739e-01,  1.3772e-01,  5.9671e-02,  2.7989e-01,\n",
       "           8.7814e-02,  6.1367e-02, -3.7368e-02,  5.5577e-02, -1.4348e-01,\n",
       "          -9.3703e-02,  3.2964e-03, -7.4134e-03,  4.3344e-02,  1.2830e-02,\n",
       "           2.4142e-02, -2.4710e-01,  4.3397e-02, -2.4350e-01, -6.1434e-02,\n",
       "           9.0893e-02,  2.3676e-01,  1.5519e-01,  2.6564e-01,  2.6258e-02,\n",
       "          -1.7048e-01,  2.1922e-01,  4.3186e-03,  1.1837e-01, -1.6589e-01,\n",
       "           5.2058e-04, -1.6203e-01, -1.7380e-01, -1.1375e-02, -3.0289e-01,\n",
       "           3.9496e-02,  9.3228e-02, -9.9607e-02, -2.3558e-02,  2.2975e-01,\n",
       "           7.9833e-02,  6.1431e-02, -1.9075e-01, -1.6046e-01, -3.4392e-01,\n",
       "           5.7048e-02, -1.5162e-01, -1.4556e-01, -4.0808e-01, -3.2614e-02,\n",
       "          -1.8683e-01,  7.7491e-03, -2.8587e-02, -2.9561e-01,  2.6121e-01,\n",
       "          -2.1461e-01, -2.9376e-02, -9.0018e-02, -3.6679e-02, -1.5301e-01,\n",
       "          -1.6102e-01, -3.0181e-02, -1.5578e-01,  1.4922e-01, -5.4942e-02,\n",
       "           7.1542e-02,  1.2572e-02, -1.6861e-01,  2.7564e-01, -2.0364e-02,\n",
       "          -9.7235e-02,  7.5342e-02, -1.7306e-02, -1.7573e-01, -7.1762e-02,\n",
       "           2.3215e-01, -9.3595e-02, -5.9807e-02, -9.2185e-03,  4.0712e-02,\n",
       "          -3.5213e-01,  1.4685e-01, -1.4119e-01, -1.0515e-01, -1.2518e-01,\n",
       "          -7.6423e-02, -1.2921e-01,  1.5676e-01, -9.3970e-02, -3.0202e-01,\n",
       "          -1.4102e-01,  1.9279e-01,  1.0410e-01,  2.0035e-03, -3.2434e-01,\n",
       "          -1.0826e-01, -1.0172e-01, -2.2138e-01,  1.9731e-01,  6.1567e-02,\n",
       "          -6.6943e-02,  6.2163e-02,  2.6128e-02, -3.7964e-02,  5.9740e-02,\n",
       "          -9.9493e-02,  1.2160e-01, -2.4528e-01,  1.5837e-01, -2.0025e-01,\n",
       "           5.6568e-03, -5.7444e-02, -9.5565e-02, -1.1917e-01,  7.6273e-02,\n",
       "          -1.6851e-01, -1.7371e-01, -4.2984e-01, -4.6291e-01, -1.9152e-01,\n",
       "          -2.8773e-01,  1.7024e-01, -2.0320e-01, -4.7235e-02,  1.2144e-01,\n",
       "          -6.0269e-02, -1.3576e-01, -1.3663e-01,  2.8432e-01, -2.8109e-02,\n",
       "          -4.4100e-02, -8.6377e-02,  3.5546e-01,  6.7880e-02, -1.6714e-01,\n",
       "          -1.6396e-03,  1.2593e-02,  2.0241e-01, -4.7576e-02,  1.3537e-02,\n",
       "           1.3610e-01, -2.4997e-01, -2.2413e-01, -7.6362e-02,  8.9856e-02,\n",
       "          -1.1110e-01,  1.6768e-01, -2.0177e-02,  2.6190e-01, -3.1310e-02,\n",
       "           3.5327e-03, -3.9763e-02,  1.8674e-02,  1.3717e-01, -1.4676e-01,\n",
       "           8.6326e-02,  1.4271e-01, -3.2854e-02,  3.7949e-02, -5.1824e-02,\n",
       "           5.9580e-02,  3.3151e-01,  2.0184e-01, -2.7473e-01, -6.4736e-02,\n",
       "           1.4706e-01, -1.3128e-01,  1.7810e-01, -6.4725e-02, -3.4742e-02,\n",
       "          -1.2618e-01,  5.3141e-02, -2.1271e-02,  1.6613e-01, -1.8554e-01,\n",
       "          -3.5337e-02,  2.0049e-01, -1.2301e-01,  3.0879e-01,  1.7044e-01,\n",
       "           1.4954e-01, -2.6827e-01,  7.2123e-02,  2.0819e-01,  3.5144e-03,\n",
       "           1.1824e-01, -1.7680e-01, -8.0293e-02,  2.0273e-02, -1.8895e-01,\n",
       "          -9.5892e-02, -1.6382e-01,  4.5953e-02, -1.1782e-01,  6.6913e-02,\n",
       "          -2.1042e-01, -2.2347e-01,  2.5346e-01, -2.5779e-01, -4.3694e-02,\n",
       "          -2.1180e-01, -2.1702e-01, -7.5756e-02,  4.5781e-02, -1.0468e-01,\n",
       "           9.5064e-02, -1.4892e-01, -1.2737e-01,  1.2108e-01, -1.2193e-01,\n",
       "          -3.8083e-01, -3.9335e-03, -2.2834e-02, -3.1963e-01, -2.7993e-01,\n",
       "           9.0125e-02,  1.1420e-01, -5.4750e-02,  1.2048e-02, -1.6127e-01,\n",
       "          -2.2003e-02,  6.8353e-02,  1.6219e-01,  2.4433e-01, -4.0754e-02,\n",
       "          -1.6490e-02, -5.2742e-02,  7.2757e-03, -1.5487e-01, -2.1306e-01,\n",
       "           2.6408e-01,  2.5428e-01,  2.7675e-01, -3.6982e-02,  1.0949e-01,\n",
       "          -2.0519e-01, -2.4906e-01,  9.2027e-02,  2.6616e-01, -1.3071e-01,\n",
       "          -1.2753e-01, -1.0744e-01, -7.7798e-02,  4.6519e-02, -7.5742e-02,\n",
       "          -1.4045e-01, -1.9851e-01,  9.3525e-02, -1.8591e-01, -5.3961e-02,\n",
       "           1.6470e-01, -1.6834e-01, -1.6239e-01, -2.5507e-01,  6.6477e-02,\n",
       "          -6.4972e-02, -1.0643e-01, -2.8823e-01,  1.8057e-01,  1.3810e-01,\n",
       "           7.7395e-02,  1.0308e-01, -1.6018e-01,  2.6945e-01, -1.7528e-02,\n",
       "          -2.6694e-01,  1.7138e-01,  5.9571e-02,  1.2901e-01, -5.9594e-02,\n",
       "          -1.5908e-01, -3.2063e-01, -1.5843e-01, -1.3535e-01,  1.5426e-01,\n",
       "           1.9122e-01,  3.4585e-01, -1.1136e-01,  7.2452e-02,  2.6695e-01,\n",
       "           3.1914e-01, -5.2291e-02, -2.7148e-01,  1.1921e-02,  4.6156e-02,\n",
       "          -2.2040e-01,  1.7332e-01,  4.2269e-03, -8.7711e-02,  3.7978e-01,\n",
       "          -1.6050e-01, -6.3418e-03, -1.0439e-01, -1.8673e-01,  4.2010e-01,\n",
       "           1.1761e-01, -6.6454e-02, -1.0489e-01, -1.8972e-01,  4.7839e-02,\n",
       "           1.2396e-01,  3.9637e-02, -4.6888e-02,  1.6824e-01, -4.9585e-02,\n",
       "           2.8166e-01,  9.8199e-02,  2.3827e-01,  1.9502e-02,  1.0394e-01,\n",
       "          -2.1274e-01, -2.1800e-01,  5.6674e-02,  1.5009e-01,  1.3150e-01,\n",
       "          -1.3708e-01,  2.1839e-01, -7.7740e-02,  1.0948e-01,  4.2989e-02,\n",
       "          -3.2493e-01,  1.0632e-01,  8.9702e-02,  2.8130e-01,  6.0856e-02,\n",
       "          -9.1441e-02,  1.0993e-01,  3.0729e-01, -1.1367e-01, -1.1267e-01,\n",
       "           3.6945e-01,  1.8798e-01,  2.0180e-01,  1.8281e-01, -5.5923e-02,\n",
       "          -2.9392e-01,  2.8208e-02,  1.0311e-01,  8.9275e-02, -1.6081e-01,\n",
       "          -1.2920e-01, -3.9539e-02,  2.6766e-02, -3.1869e-02,  2.8049e-01,\n",
       "           2.8355e-01,  6.5079e-03, -1.3941e-01, -2.3434e-01,  1.4579e-02,\n",
       "          -1.2305e-01, -1.4541e-02, -5.9836e-02,  3.2689e-01, -1.4028e-01,\n",
       "          -7.0651e-02, -1.1548e-01,  2.1095e-01, -5.1899e-02,  2.8885e-02,\n",
       "           3.0117e-01, -8.6066e-02, -2.2724e-01,  3.1987e-01, -1.8259e-01,\n",
       "          -2.4047e-01, -6.4792e-02,  1.0441e-01, -1.6730e-01,  6.8355e-02,\n",
       "           7.3236e-02,  1.3960e-01,  2.4269e-01,  3.8704e-03, -1.7855e-01,\n",
       "           1.2914e-01,  1.7798e-02,  1.0523e-01,  3.0704e-02, -2.1866e-02,\n",
       "          -5.3831e-02, -2.8953e-01,  2.0848e-01, -1.1353e-01,  1.8203e-01,\n",
       "          -1.7888e-01, -2.6361e-01, -2.0850e-01,  4.3858e-02,  1.8070e-02,\n",
       "          -1.0180e-01, -1.9369e-01,  1.2497e-01, -1.3521e-01,  2.0995e-01,\n",
       "           1.1014e-01, -3.2814e-01, -4.2991e-02,  1.0571e-01,  6.0475e-02,\n",
       "          -2.3436e-01, -3.0703e-01,  7.2166e-02,  6.8084e-02,  1.1497e-01,\n",
       "          -1.5404e-01, -2.4856e-01,  5.4773e-02, -2.2069e-02, -2.4037e-01,\n",
       "          -1.5752e-01, -1.8441e-01,  1.7015e-01, -1.4215e-01, -2.4946e-01,\n",
       "          -6.6432e-03, -4.7398e-02,  1.0674e-03,  1.3767e-01,  1.0153e-01,\n",
       "           7.9716e-02,  1.0508e-01, -1.4768e-01,  2.3675e-01,  1.7679e-01,\n",
       "           4.9629e-02, -7.9451e-02,  9.7243e-02,  2.6227e-01, -2.4591e-01,\n",
       "           1.4195e-01,  1.0855e-01, -7.0562e-02, -1.5264e-01,  4.0444e-02,\n",
       "           1.5103e-01,  1.9967e-01, -2.0832e-01, -2.0058e-01, -8.6569e-02,\n",
       "          -1.0498e-01,  7.0473e-02, -3.3932e-02, -2.8378e-01,  3.8895e-02,\n",
       "          -2.1230e-02, -2.5399e-01,  1.6179e-01, -1.3225e-01,  1.5563e-02,\n",
       "           3.2805e-01, -2.2076e-01,  1.6137e-01,  3.0362e-02,  7.9182e-03,\n",
       "           3.7538e-01, -5.3438e-03,  5.2338e-02, -2.1575e-01, -2.6385e-01,\n",
       "           2.8970e-01, -3.3177e-01, -1.0845e-04,  8.6665e-02,  1.6162e-02,\n",
       "          -2.6021e-02,  2.2077e-02, -1.2201e-01, -8.8547e-03, -2.2839e-01,\n",
       "           1.7844e-01, -9.3653e-02, -5.4909e-02, -8.7049e-02,  1.0972e-01,\n",
       "          -6.9259e-02, -3.7317e-01, -3.2953e-01,  2.2050e-02, -4.3427e-02,\n",
       "          -8.7204e-02, -2.0971e-01, -1.8413e-01,  7.5892e-02,  3.0942e-02,\n",
       "          -3.2214e-01, -3.0740e-01]], device='cuda:0', grad_fn=<AddmmBackward>),\n",
       " tensor(8.3070, device='cuda:0', grad_fn=<MulBackward0>))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vae.encoder(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-59-c513f6bfbaef>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-59-c513f6bfbaef>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    tensor([[1.]], device='cuda:0', grad_fn=<SigmoidBackward>) tensor([[6.8548e-08]], device='cuda:0', grad_fn=<SigmoidBackward>) tensor(-0.3339, device='cuda:0', grad_fn=<SelectBackward>) tensor(0., device='cuda:0')\u001b[0m\n\u001b[0m                                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "tensor([[1.]], device='cuda:0', grad_fn=<SigmoidBackward>) tensor([[6.8548e-08]], device='cuda:0', grad_fn=<SigmoidBackward>) tensor(-0.3339, device='cuda:0', grad_fn=<SelectBackward>) tensor(0., device='cuda:0')\n",
    "tensor([[1.]], device='cuda:0', grad_fn=<SigmoidBackward>) tensor([[1.0000]], device='cuda:0', grad_fn=<SigmoidBackward>) tensor(2.2138e-06, device='cuda:0', grad_fn=<SelectBackward>) tensor(0., device='cuda:0')\n",
    "tensor([[1.0000],\n",
    "        [0.6882],\n",
    "        [0.6882],\n",
    "        [0.6882],\n",
    "        [0.6882],\n",
    "        [0.6882],\n",
    "        [0.6882]], device='cuda:0', grad_fn=<SigmoidBackward>) tensor([[1.0000],\n",
    "        [0.4825],\n",
    "        [0.4825],\n",
    "        [0.4825],\n",
    "        [0.4825],\n",
    "        [0.4825],\n",
    "        [0.4825]], device='cuda:0', grad_fn=<SigmoidBackward>) tensor(0.2505, device='cuda:0', grad_fn=<SelectBackward>) tensor(0., device='cuda:0')\n",
    "tensor([[9.9898e-01],\n",
    "        [6.8815e-01]], device='cuda:0', grad_fn=<SigmoidBackward>) tensor([[1.4704e-07],\n",
    "        [4.8249e-01],\n",
    "        [4.8249e-01]], device='cuda:0', grad_fn=<SigmoidBackward>) tensor(0.0960, device='cuda:0', grad_fn=<SelectBackward>) tensor(0., device='cuda:0')\n",
    "tensor([[1.0000e+00],\n",
    "        [6.8815e-01]], device='cuda:0', grad_fn=<SigmoidBackward>) tensor([[7.1730e-06],\n",
    "        [7.6499e-08],"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4927]], device='cuda:0') tensor([[0.5126]], device='cuda:0') tensor(0.2420, device='cuda:0') tensor(0., device='cuda:0')\n",
      "tensor([[0.4898]], device='cuda:0') tensor([[0.4952]], device='cuda:0') tensor(0.0707, device='cuda:0') tensor(0., device='cuda:0')\n",
      "tensor([[0.4961]], device='cuda:0') tensor([[0.4933]], device='cuda:0') tensor(0.0707, device='cuda:0') tensor(-0.0598, device='cuda:0')\n",
      "tensor([[0.4897]], device='cuda:0') tensor([[0.4979]], device='cuda:0') tensor(0.0160, device='cuda:0') tensor(0., device='cuda:0')\n",
      "tensor([[0.4861]], device='cuda:0') tensor([[0.4997]], device='cuda:0') tensor(0.0160, device='cuda:0') tensor(-0.0035, device='cuda:0')\n",
      "tensor([[0.4939]], device='cuda:0') tensor([[0.4978]], device='cuda:0') tensor(0.0160, device='cuda:0') tensor(-0.0127, device='cuda:0')\n",
      "tensor([[0.4950]], device='cuda:0') tensor([[0.4949]], device='cuda:0') tensor(-0.0205, device='cuda:0') tensor(0., device='cuda:0')\n",
      "tensor([[0.4999]], device='cuda:0') tensor([[0.4967]], device='cuda:0') tensor(-0.0205, device='cuda:0') tensor(0.0585, device='cuda:0')\n",
      "tensor([[0.4963]], device='cuda:0') tensor([[0.4980]], device='cuda:0') tensor(-0.0205, device='cuda:0') tensor(0.0277, device='cuda:0')\n",
      "tensor([[0.4914]], device='cuda:0') tensor([[0.4974]], device='cuda:0') tensor(0.0131, device='cuda:0') tensor(0., device='cuda:0')\n",
      "tensor([[0.4914]], device='cuda:0') tensor([[0.4974]], device='cuda:0') tensor(0.0131, device='cuda:0') tensor(0., device='cuda:0')\n",
      "tensor([[0.4867]], device='cuda:0') tensor([[0.4991]], device='cuda:0') tensor(0.0131, device='cuda:0') tensor(-0.0069, device='cuda:0')\n",
      "tensor([[0.4842]], device='cuda:0') tensor([[0.4950]], device='cuda:0') tensor(0.0131, device='cuda:0') tensor(0.0036, device='cuda:0')\n",
      "tensor([[0.4873]], device='cuda:0') tensor([[0.4943]], device='cuda:0') tensor(0.0191, device='cuda:0') tensor(0., device='cuda:0')\n",
      "tensor([[0.4929]], device='cuda:0') tensor([[0.4959]], device='cuda:0') tensor(0.0275, device='cuda:0') tensor(0., device='cuda:0')\n",
      "tensor([[0.4882]], device='cuda:0') tensor([[0.4984]], device='cuda:0') tensor(0.0023, device='cuda:0') tensor(0., device='cuda:0')\n",
      "tensor([[0.4946]], device='cuda:0') tensor([[0.5053]], device='cuda:0') tensor(0.0023, device='cuda:0') tensor(-0.0259, device='cuda:0')\n",
      "tensor([[0.4908]], device='cuda:0') tensor([[0.5007]], device='cuda:0') tensor(-0.0094, device='cuda:0') tensor(0., device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "trees = vae.evaluate(data, idx_to_label['RES'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2., 3.],\n",
       "        [4., 5.]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat([torch.empty(0), torch.tensor([[2, 3], [4, 5]])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "for batch in loader:\n",
    "    data = batch\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = build_tree(data['adjacency_list'], data['features'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"token\": 0, \"res\": true, \"children\": [{\"token\": 2, \"res\": true, \"children\": [{\"token\": 3, \"res\": true, \"children\": [{\"token\": 0, \"res\": true}, {\"token\": 0, \"res\": true}]}, {\"token\": 4, \"res\": true, \"children\": [{\"token\": 2, \"res\": true}]}]}, {\"token\": 2, \"res\": true, \"children\": [{\"token\": 3, \"res\": true, \"children\": [{\"token\": 0, \"res\": true}, {\"token\": 0, \"res\": true}]}, {\"token\": 4, \"res\": true, \"children\": [{\"token\": 2, \"res\": true}]}]}, {\"token\": 2, \"res\": true, \"children\": [{\"token\": 3, \"res\": true, \"children\": [{\"token\": 0, \"res\": true}, {\"token\": 0, \"res\": true}]}, {\"token\": 4, \"res\": true, \"children\": [{\"token\": 2, \"res\": true}]}]}, {\"token\": 5, \"res\": true, \"children\": [{\"token\": 6, \"res\": true, \"children\": [{\"token\": 62, \"res\": true}]}, {\"token\": 7, \"res\": true, \"children\": [{\"token\": 8, \"res\": true, \"children\": [{\"token\": 11, \"res\": true}]}]}]}, {\"token\": 5, \"res\": true, \"children\": [{\"token\": 6, \"res\": true, \"children\": [{\"token\": 62, \"res\": true}, {\"token\": 14, \"res\": true}]}, {\"token\": 7, \"res\": true, \"children\": [{\"token\": 8, \"res\": true, \"children\": [{\"token\": 11, \"res\": true}]}, {\"token\": 9, \"res\": true, \"children\": [{\"token\": 10, \"res\": true, \"children\": [{\"token\": 38, \"res\": true}]}, {\"token\": 11, \"res\": true, \"children\": [{\"token\": 39, \"res\": true}]}]}]}]}]}'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exporter = JsonExporter()\n",
    "exporter.export(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_token_vocabulary(path):\n",
    "    if os.path.isfile(path):\n",
    "        # Load the reserved tokens dictionary\n",
    "        with open(path, 'r') as json_f:\n",
    "            json_data = json_f.read()\n",
    "\n",
    "        # To JSON format (dictionary)\n",
    "        tokens = json.loads(json_data)\n",
    "\n",
    "    else:\n",
    "        tokens = {}\n",
    "\n",
    "        for dirpath, _, files in os.walk(path):\n",
    "            for file in files:\n",
    "                if file.endswith('.json'):\n",
    "                    with open(os.path.join(dirpath, file), 'r') as json_f:\n",
    "                        json_data = json_f.read()\n",
    "\n",
    "                    # To JSON format (dictionary)\n",
    "                    for k,v in json.loads(json_data).items():\n",
    "                            if k in tokens:\n",
    "                                tokens[k] += v\n",
    "                            else:\n",
    "                                tokens[k] = v\n",
    "\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = load_token_vocabulary('../data/ast_trees_solutions600/reserved_tokens/')\n",
    "tokens = dict(sorted(tokens.items(), key=lambda x:x[1], reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_leafs = load_token_vocabulary('../data/ast_trees_solutions600/tokens/')\n",
    "tokens_leafs = dict(sorted(tokens_leafs.items(), key=lambda x:x[1], reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "type_refs = [('ll', 'long long')]\n",
    "types = [el.strip() for el in re.split('<', 'pair<ll, pair<long long, ll> >')[1].split('>')[0].split(',')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ll', 'pair']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('ll', 'long long')\n"
     ]
    }
   ],
   "source": [
    "for typ in types:\n",
    "    matches = [item for item in type_refs if item[0] == typ]\n",
    "    if len(matches) > 0:\n",
    "        print(matches[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "trees = pd.read_csv('../data/ast_trees/asts.csv.bz2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"token\": \"root\",\n",
      "  \"res\": true,\n",
      "  \"children\": [\n",
      "    {\n",
      "      \"token\": \"TYPEDEF_DECL\",\n",
      "      \"res\": true,\n",
      "      \"children\": [\n",
      "        {\n",
      "          \"token\": \"TYPE_DEF\",\n",
      "          \"res\": true,\n",
      "          \"children\": [\n",
      "            {\n",
      "              \"token\": \"TYPE_KIND\",\n",
      "              \"res\": true,\n",
      "              \"children\": [\n",
      "                {\n",
      "                  \"token\": \"TYPE\",\n",
      "                  \"res\": true,\n",
      "                  \"children\": [\n",
      "                    {\n",
      "                      \"token\": \"long long\",\n",
      "                      \"res\": false\n",
      "                    }\n",
      "                  ]\n",
      "                }\n",
      "              ]\n",
      "            }\n",
      "          ]\n",
      "        },\n",
      "        {\n",
      "          \"token\": \"IDENTIFIER\",\n",
      "          \"res\": true,\n",
      "          \"children\": [\n",
      "            {\n",
      "              \"token\": \"ll\",\n",
      "              \"res\": false\n",
      "            }\n",
      "          ]\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"token\": \"TYPEDEF_DECL\",\n",
      "      \"res\": true,\n",
      "      \"children\": [\n",
      "        {\n",
      "          \"token\": \"TYPE_DEF\",\n",
      "          \"res\": true,\n",
      "          \"children\": [\n",
      "            {\n",
      "              \"token\": \"TYPE_KIND\",\n",
      "              \"res\": true,\n",
      "              \"children\": [\n",
      "                {\n",
      "                  \"token\": \"TYPE\",\n",
      "                  \"res\": true,\n",
      "                  \"children\": [\n",
      "                    {\n",
      "                      \"token\": \"unsigned long long\",\n",
      "                      \"res\": false\n",
      "                    }\n",
      "                  ]\n",
      "                }\n",
      "              ]\n",
      "            }\n",
      "          ]\n",
      "        },\n",
      "        {\n",
      "          \"token\": \"IDENTIFIER\",\n",
      "          \"res\": true,\n",
      "          \"children\": [\n",
      "            {\n",
      "              \"token\": \"ull\",\n",
      "              \"res\": false\n",
      "            }\n",
      "          ]\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"token\": \"TYPEDEF_DECL\",\n",
      "      \"res\": true,\n",
      "      \"children\": [\n",
      "        {\n",
      "          \"token\": \"TYPE_DEF\",\n",
      "          \"res\": true,\n",
      "          \"children\": [\n",
      "            {\n",
      "              \"token\": \"TYPE_KIND\",\n",
      "              \"res\": true,\n",
      "              \"children\": [\n",
      "                {\n",
      "                  \"token\": \"TYPE\",\n",
      "                  \"res\": true,\n",
      "                  \"children\": [\n",
      "                    {\n",
      "                      \"token\": \"long double\",\n",
      "                      \"res\": false\n",
      "                    }\n",
      "                  ]\n",
      "                }\n",
      "              ]\n",
      "            }\n",
      "          ]\n",
      "        },\n",
      "        {\n",
      "          \"token\": \"IDENTIFIER\",\n",
      "          \"res\": true,\n",
      "          \"children\": [\n",
      "            {\n",
      "              \"token\": \"ld\",\n",
      "              \"res\": false\n",
      "            }\n",
      "          ]\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"token\": \"VAR_DECL\",\n",
      "      \"res\": true,\n",
      "      \"children\": [\n",
      "        {\n",
      "          \"token\": \"TYPE_KIND\",\n",
      "          \"res\": true,\n",
      "          \"children\": [\n",
      "            {\n",
      "              \"token\": \"TYPE\",\n",
      "              \"res\": true,\n",
      "              \"children\": [\n",
      "                {\n",
      "                  \"token\": \"long double\",\n",
      "                  \"res\": false\n",
      "                }\n",
      "              ]\n",
      "            }\n",
      "          ]\n",
      "        },\n",
      "        {\n",
      "          \"token\": \"DECLARATOR\",\n",
      "          \"res\": true,\n",
      "          \"children\": [\n",
      "            {\n",
      "              \"token\": \"NAME\",\n",
      "              \"res\": true,\n",
      "              \"children\": [\n",
      "                {\n",
      "                  \"token\": \"pi\",\n",
      "                  \"res\": false\n",
      "                }\n",
      "              ]\n",
      "            },\n",
      "            {\n",
      "              \"token\": \"FLOATING_LITERAL\",\n",
      "              \"res\": true,\n",
      "              \"children\": [\n",
      "                {\n",
      "                  \"token\": \"3.1415926536\",\n",
      "                  \"res\": false\n",
      "                }\n",
      "              ]\n",
      "            }\n",
      "          ]\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"token\": \"VAR_DECL\",\n",
      "      \"res\": true,\n",
      "      \"children\": [\n",
      "        {\n",
      "          \"token\": \"TYPE_KIND\",\n",
      "          \"res\": true,\n",
      "          \"children\": [\n",
      "            {\n",
      "              \"token\": \"TYPE\",\n",
      "              \"res\": true,\n",
      "              \"children\": [\n",
      "                {\n",
      "                  \"token\": \"long long\",\n",
      "                  \"res\": false\n",
      "                }\n",
      "              ]\n",
      "            }\n",
      "          ]\n",
      "        },\n",
      "        {\n",
      "          \"token\": \"DECLARATOR\",\n",
      "          \"res\": true,\n",
      "          \"children\": [\n",
      "            {\n",
      "              \"token\": \"NAME\",\n",
      "              \"res\": true,\n",
      "              \"children\": [\n",
      "                {\n",
      "                  \"token\": \"prime\",\n",
      "                  \"res\": false\n",
      "                }\n",
      "              ]\n",
      "            },\n",
      "            {\n",
      "              \"token\": \"BINARY_OPERATOR_+\",\n",
      "              \"res\": true,\n",
      "              \"children\": [\n",
      "                {\n",
      "                  \"token\": \"FLOATING_LITERAL\",\n",
      "                  \"res\": true,\n",
      "                  \"children\": [\n",
      "                    {\n",
      "                      \"token\": \"1e9\",\n",
      "                      \"res\": false\n",
      "                    }\n",
      "                  ]\n",
      "                },\n",
      "                {\n",
      "                  \"token\": \"INTEGER_LITERAL\",\n",
      "                  \"res\": true,\n",
      "                  \"children\": [\n",
      "                    {\n",
      "                      \"token\": \"7\",\n",
      "                      \"res\": false\n",
      "                    }\n",
      "                  ]\n",
      "                }\n",
      "              ]\n",
      "            }\n",
      "          ]\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"token\": \"VAR_DECL\",\n",
      "      \"res\": true,\n",
      "      \"children\": [\n",
      "        {\n",
      "          \"token\": \"TYPE_KIND\",\n",
      "          \"res\": true,\n",
      "          \"children\": [\n",
      "            {\n",
      "              \"token\": \"TYPE\",\n",
      "              \"res\": true,\n",
      "              \"children\": [\n",
      "                {\n",
      "                  \"token\": \"long long\",\n",
      "                  \"res\": false\n",
      "                }\n",
      "              ]\n",
      "            }\n",
      "          ]\n",
      "        },\n",
      "        {\n",
      "          \"token\": \"DECLARATOR\",\n",
      "          \"res\": true,\n",
      "          \"children\": [\n",
      "            {\n",
      "              \"token\": \"NAME\",\n",
      "              \"res\": true,\n",
      "              \"children\": [\n",
      "                {\n",
      "                  \"token\": \"maxN\",\n",
      "                  \"res\": false\n",
      "                }\n",
      "              ]\n",
      "            },\n",
      "            {\n",
      "              \"token\": \"BINARY_OPERATOR_+\",\n",
      "              \"res\": true,\n",
      "              \"children\": [\n",
      "                {\n",
      "                  \"token\": \"FLOATING_LITERAL\",\n",
      "                  \"res\": true,\n",
      "                  \"children\": [\n",
      "                    {\n",
      "                      \"token\": \"1e5\",\n",
      "                      \"res\": false\n",
      "                    }\n",
      "                  ]\n",
      "                },\n",
      "                {\n",
      "                  \"token\": \"INTEGER_LITERAL\",\n",
      "                  \"res\": true,\n",
      "                  \"children\": [\n",
      "                    {\n",
      "                      \"token\": \"3\",\n",
      "                      \"res\": false\n",
      "                    }\n",
      "                  ]\n",
      "                }\n",
      "              ]\n",
      "            }\n",
      "          ]\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"token\": \"FUNCTION_DECL\",\n",
      "      \"res\": true,\n",
      "      \"children\": [\n",
      "        {\n",
      "          \"token\": \"NAME\",\n",
      "          \"res\": true,\n",
      "          \"children\": [\n",
      "            {\n",
      "              \"token\": \"main\",\n",
      "              \"res\": false\n",
      "            }\n",
      "          ]\n",
      "        },\n",
      "        {\n",
      "          \"token\": \"TYPE_KIND\",\n",
      "          \"res\": true,\n",
      "          \"children\": [\n",
      "            {\n",
      "              \"token\": \"TYPE\",\n",
      "              \"res\": true,\n",
      "              \"children\": [\n",
      "                {\n",
      "                  \"token\": \"int\",\n",
      "                  \"res\": false\n",
      "                }\n",
      "              ]\n",
      "            }\n",
      "          ]\n",
      "        },\n",
      "        {\n",
      "          \"token\": \"COMPOUND_STMT\",\n",
      "          \"res\": true,\n",
      "          \"children\": [\n",
      "            {\n",
      "              \"token\": \"CALL_EXPR\",\n",
      "              \"res\": true,\n",
      "              \"children\": [\n",
      "                {\n",
      "                  \"token\": \"NAME\",\n",
      "                  \"res\": true,\n",
      "                  \"children\": [\n",
      "                    {\n",
      "                      \"token\": \"sync_with_stdio\",\n",
      "                      \"res\": false\n",
      "                    }\n",
      "                  ]\n",
      "                },\n",
      "                {\n",
      "                  \"token\": \"ARGUMENTS\",\n",
      "                  \"res\": true,\n",
      "                  \"children\": [\n",
      "                    {\n",
      "                      \"token\": \"CXX_BOOL_LITERAL_EXPR\",\n",
      "                      \"res\": true,\n",
      "                      \"children\": [\n",
      "                        {\n",
      "                          \"token\": \"false\",\n",
      "                          \"res\": false\n",
      "                        }\n",
      "                      ]\n",
      "                    }\n",
      "                  ]\n",
      "                },\n",
      "                {\n",
      "                  \"token\": \"TYPE_REF\",\n",
      "                  \"res\": true,\n",
      "                  \"children\": [\n",
      "                    {\n",
      "                      \"token\": \"std::ios_base\",\n",
      "                      \"res\": false\n",
      "                    }\n",
      "                  ]\n",
      "                }\n",
      "              ]\n",
      "            },\n",
      "            {\n",
      "              \"token\": \"CALL_EXPR\",\n",
      "              \"res\": true,\n",
      "              \"children\": [\n",
      "                {\n",
      "                  \"token\": \"NAME\",\n",
      "                  \"res\": true,\n",
      "                  \"children\": [\n",
      "                    {\n",
      "                      \"token\": \"tie\",\n",
      "                      \"res\": false\n",
      "                    }\n",
      "                  ]\n",
      "                },\n",
      "                {\n",
      "                  \"token\": \"DECL_REF_EXPR\",\n",
      "                  \"res\": true,\n",
      "                  \"children\": [\n",
      "                    {\n",
      "                      \"token\": \"cin\",\n",
      "                      \"res\": false\n",
      "                    }\n",
      "                  ]\n",
      "                }\n",
      "              ]\n",
      "            },\n",
      "            {\n",
      "              \"token\": \"DECL_STMT\",\n",
      "              \"res\": true,\n",
      "              \"children\": [\n",
      "                {\n",
      "                  \"token\": \"VAR_DECL\",\n",
      "                  \"res\": true,\n",
      "                  \"children\": [\n",
      "                    {\n",
      "                      \"token\": \"TYPE_KIND\",\n",
      "                      \"res\": true,\n",
      "                      \"children\": [\n",
      "                        {\n",
      "                          \"token\": \"TYPE\",\n",
      "                          \"res\": true,\n",
      "                          \"children\": [\n",
      "                            {\n",
      "                              \"token\": \"long long\",\n",
      "                              \"res\": false\n",
      "                            }\n",
      "                          ]\n",
      "                        }\n",
      "                      ]\n",
      "                    },\n",
      "                    {\n",
      "                      \"token\": \"DECLARATOR\",\n",
      "                      \"res\": true,\n",
      "                      \"children\": [\n",
      "                        {\n",
      "                          \"token\": \"NAME\",\n",
      "                          \"res\": true,\n",
      "                          \"children\": [\n",
      "                            {\n",
      "                              \"token\": \"n\",\n",
      "                              \"res\": false\n",
      "                            }\n",
      "                          ]\n",
      "                        }\n",
      "                      ]\n",
      "                    }\n",
      "                  ]\n",
      "                },\n",
      "                {\n",
      "                  \"token\": \"VAR_DECL\",\n",
      "                  \"res\": true,\n",
      "                  \"children\": [\n",
      "                    {\n",
      "                      \"token\": \"TYPE_KIND\",\n",
      "                      \"res\": true,\n",
      "                      \"children\": [\n",
      "                        {\n",
      "                          \"token\": \"TYPE\",\n",
      "                          \"res\": true,\n",
      "                          \"children\": [\n",
      "                            {\n",
      "                              \"token\": \"long long\",\n",
      "                              \"res\": false\n",
      "                            }\n",
      "                          ]\n",
      "                        }\n",
      "                      ]\n",
      "                    },\n",
      "                    {\n",
      "                      \"token\": \"DECLARATOR\",\n",
      "                      \"res\": true,\n",
      "                      \"children\": [\n",
      "                        {\n",
      "                          \"token\": \"NAME\",\n",
      "                          \"res\": true,\n",
      "                          \"children\": [\n",
      "                            {\n",
      "                              \"token\": \"k\",\n",
      "                              \"res\": false\n",
      "                            }\n",
      "                          ]\n",
      "                        }\n",
      "                      ]\n",
      "                    }\n",
      "                  ]\n",
      "                },\n",
      "                {\n",
      "                  \"token\": \"VAR_DECL\",\n",
      "                  \"res\": true,\n",
      "                  \"children\": [\n",
      "                    {\n",
      "                      \"token\": \"TYPE_KIND\",\n",
      "                      \"res\": true,\n",
      "                      \"children\": [\n",
      "                        {\n",
      "                          \"token\": \"TYPE\",\n",
      "                          \"res\": true,\n",
      "                          \"children\": [\n",
      "                            {\n",
      "                              \"token\": \"long long\",\n",
      "                              \"res\": false\n",
      "                            }\n",
      "                          ]\n",
      "                        }\n",
      "                      ]\n",
      "                    },\n",
      "                    {\n",
      "                      \"token\": \"DECLARATOR\",\n",
      "                      \"res\": true,\n",
      "                      \"children\": [\n",
      "                        {\n",
      "                          \"token\": \"NAME\",\n",
      "                          \"res\": true,\n",
      "                          \"children\": [\n",
      "                            {\n",
      "                              \"token\": \"a\",\n",
      "                              \"res\": false\n",
      "                            }\n",
      "                          ]\n",
      "                        }\n",
      "                      ]\n",
      "                    }\n",
      "                  ]\n",
      "                },\n",
      "                {\n",
      "                  \"token\": \"VAR_DECL\",\n",
      "                  \"res\": true,\n",
      "                  \"children\": [\n",
      "                    {\n",
      "                      \"token\": \"TYPE_KIND\",\n",
      "                      \"res\": true,\n",
      "                      \"children\": [\n",
      "                        {\n",
      "                          \"token\": \"TYPE\",\n",
      "                          \"res\": true,\n",
      "                          \"children\": [\n",
      "                            {\n",
      "                              \"token\": \"long long\",\n",
      "                              \"res\": false\n",
      "                            }\n",
      "                          ]\n",
      "                        }\n",
      "                      ]\n",
      "                    },\n",
      "                    {\n",
      "                      \"token\": \"DECLARATOR\",\n",
      "                      \"res\": true,\n",
      "                      \"children\": [\n",
      "                        {\n",
      "                          \"token\": \"NAME\",\n",
      "                          \"res\": true,\n",
      "                          \"children\": [\n",
      "                            {\n",
      "                              \"token\": \"ans\",\n",
      "                              \"res\": false\n",
      "                            }\n",
      "                          ]\n",
      "                        },\n",
      "                        {\n",
      "                          \"token\": \"INTEGER_LITERAL\",\n",
      "                          \"res\": true,\n",
      "                          \"children\": [\n",
      "                            {\n",
      "                              \"token\": \"0\",\n",
      "                              \"res\": false\n",
      "                            }\n",
      "                          ]\n",
      "                        }\n",
      "                      ]\n",
      "                    }\n",
      "                  ]\n",
      "                },\n",
      "                {\n",
      "                  \"token\": \"VAR_DECL\",\n",
      "                  \"res\": true,\n",
      "                  \"children\": [\n",
      "                    {\n",
      "                      \"token\": \"TYPE_KIND\",\n",
      "                      \"res\": true,\n",
      "                      \"children\": [\n",
      "                        {\n",
      "                          \"token\": \"TYPE\",\n",
      "                          \"res\": true,\n",
      "                          \"children\": [\n",
      "                            {\n",
      "                              \"token\": \"long long\",\n",
      "                              \"res\": false\n",
      "                            }\n",
      "                          ]\n",
      "                        }\n",
      "                      ]\n",
      "                    },\n",
      "                    {\n",
      "                      \"token\": \"DECLARATOR\",\n",
      "                      \"res\": true,\n",
      "                      \"children\": [\n",
      "                        {\n",
      "                          \"token\": \"NAME\",\n",
      "                          \"res\": true,\n",
      "                          \"children\": [\n",
      "                            {\n",
      "                              \"token\": \"left\",\n",
      "                              \"res\": false\n",
      "                            }\n",
      "                          ]\n",
      "                        },\n",
      "                        {\n",
      "                          \"token\": \"INTEGER_LITERAL\",\n",
      "                          \"res\": true,\n",
      "                          \"children\": [\n",
      "                            {\n",
      "                              \"token\": \"0\",\n",
      "                              \"res\": false\n",
      "                            }\n",
      "                          ]\n",
      "                        }\n",
      "                      ]\n",
      "                    }\n",
      "                  ]\n",
      "                }\n",
      "              ]\n",
      "            },\n",
      "            {\n",
      "              \"token\": \"CALL_EXPR\",\n",
      "              \"res\": true,\n",
      "              \"children\": [\n",
      "                {\n",
      "                  \"token\": \"NAME\",\n",
      "                  \"res\": true,\n",
      "                  \"children\": [\n",
      "                    {\n",
      "                      \"token\": \"operator>>\",\n",
      "                      \"res\": false\n",
      "                    }\n",
      "                  ]\n",
      "                },\n",
      "                {\n",
      "                  \"token\": \"ARGUMENTS\",\n",
      "                  \"res\": true,\n",
      "                  \"children\": [\n",
      "                    {\n",
      "                      \"token\": \"CALL_EXPR\",\n",
      "                      \"res\": true,\n",
      "                      \"children\": [\n",
      "                        {\n",
      "                          \"token\": \"NAME\",\n",
      "                          \"res\": true,\n",
      "                          \"children\": [\n",
      "                            {\n",
      "                              \"token\": \"operator>>\",\n",
      "                              \"res\": false\n",
      "                            }\n",
      "                          ]\n",
      "                        },\n",
      "                        {\n",
      "                          \"token\": \"ARGUMENTS\",\n",
      "                          \"res\": true,\n",
      "                          \"children\": [\n",
      "                            {\n",
      "                              \"token\": \"DECL_REF_EXPR\",\n",
      "                              \"res\": true,\n",
      "                              \"children\": [\n",
      "                                {\n",
      "                                  \"token\": \"cin\",\n",
      "                                  \"res\": false\n",
      "                                }\n",
      "                              ]\n",
      "                            },\n",
      "                            {\n",
      "                              \"token\": \"DECL_REF_EXPR\",\n",
      "                              \"res\": true,\n",
      "                              \"children\": [\n",
      "                                {\n",
      "                                  \"token\": \"n\",\n",
      "                                  \"res\": false\n",
      "                                }\n",
      "                              ]\n",
      "                            }\n",
      "                          ]\n",
      "                        }\n",
      "                      ]\n",
      "                    },\n",
      "                    {\n",
      "                      \"token\": \"DECL_REF_EXPR\",\n",
      "                      \"res\": true,\n",
      "                      \"children\": [\n",
      "                        {\n",
      "                          \"token\": \"k\",\n",
      "                          \"res\": false\n",
      "                        }\n",
      "                      ]\n",
      "                    }\n",
      "                  ]\n",
      "                }\n",
      "              ]\n",
      "            },\n",
      "            {\n",
      "              \"token\": \"FOR_STMT\",\n",
      "              \"res\": true,\n",
      "              \"children\": [\n",
      "                {\n",
      "                  \"token\": \"DECL_STMT\",\n",
      "                  \"res\": true,\n",
      "                  \"children\": [\n",
      "                    {\n",
      "                      \"token\": \"VAR_DECL\",\n",
      "                      \"res\": true,\n",
      "                      \"children\": [\n",
      "                        {\n",
      "                          \"token\": \"TYPE_KIND\",\n",
      "                          \"res\": true,\n",
      "                          \"children\": [\n",
      "                            {\n",
      "                              \"token\": \"TYPE\",\n",
      "                              \"res\": true,\n",
      "                              \"children\": [\n",
      "                                {\n",
      "                                  \"token\": \"long long\",\n",
      "                                  \"res\": false\n",
      "                                }\n",
      "                              ]\n",
      "                            }\n",
      "                          ]\n",
      "                        },\n",
      "                        {\n",
      "                          \"token\": \"DECLARATOR\",\n",
      "                          \"res\": true,\n",
      "                          \"children\": [\n",
      "                            {\n",
      "                              \"token\": \"NAME\",\n",
      "                              \"res\": true,\n",
      "                              \"children\": [\n",
      "                                {\n",
      "                                  \"token\": \"i\",\n",
      "                                  \"res\": false\n",
      "                                }\n",
      "                              ]\n",
      "                            },\n",
      "                            {\n",
      "                              \"token\": \"CSTYLE_CAST_EXPR\",\n",
      "                              \"res\": true,\n",
      "                              \"children\": [\n",
      "                                {\n",
      "                                  \"token\": \"TYPE_KIND\",\n",
      "                                  \"res\": true,\n",
      "                                  \"children\": [\n",
      "                                    {\n",
      "                                      \"token\": \"TYPE\",\n",
      "                                      \"res\": true,\n",
      "                                      \"children\": [\n",
      "                                        {\n",
      "                                          \"token\": \"long long\",\n",
      "                                          \"res\": false\n",
      "                                        }\n",
      "                                      ]\n",
      "                                    }\n",
      "                                  ]\n",
      "                                },\n",
      "                                {\n",
      "                                  \"token\": \"TYPE_REF\",\n",
      "                                  \"res\": true,\n",
      "                                  \"children\": [\n",
      "                                    {\n",
      "                                      \"token\": \"ll\",\n",
      "                                      \"res\": false\n",
      "                                    }\n",
      "                                  ]\n",
      "                                },\n",
      "                                {\n",
      "                                  \"token\": \"PAREN_EXPR\",\n",
      "                                  \"res\": true,\n",
      "                                  \"children\": [\n",
      "                                    {\n",
      "                                      \"token\": \"INTEGER_LITERAL\",\n",
      "                                      \"res\": true,\n",
      "                                      \"children\": [\n",
      "                                        {\n",
      "                                          \"token\": \"1\",\n",
      "                                          \"res\": false\n",
      "                                        }\n",
      "                                      ]\n",
      "                                    }\n",
      "                                  ]\n",
      "                                }\n",
      "                              ]\n",
      "                            }\n",
      "                          ]\n",
      "                        }\n",
      "                      ]\n",
      "                    }\n",
      "                  ]\n",
      "                },\n",
      "                {\n",
      "                  \"token\": \"BINARY_OPERATOR_<=\",\n",
      "                  \"res\": true,\n",
      "                  \"children\": [\n",
      "                    {\n",
      "                      \"token\": \"DECL_REF_EXPR\",\n",
      "                      \"res\": true,\n",
      "                      \"children\": [\n",
      "                        {\n",
      "                          \"token\": \"i\",\n",
      "                          \"res\": false\n",
      "                        }\n",
      "                      ]\n",
      "                    },\n",
      "                    {\n",
      "                      \"token\": \"CSTYLE_CAST_EXPR\",\n",
      "                      \"res\": true,\n",
      "                      \"children\": [\n",
      "                        {\n",
      "                          \"token\": \"TYPE_KIND\",\n",
      "                          \"res\": true,\n",
      "                          \"children\": [\n",
      "                            {\n",
      "                              \"token\": \"TYPE\",\n",
      "                              \"res\": true,\n",
      "                              \"children\": [\n",
      "                                {\n",
      "                                  \"token\": \"long long\",\n",
      "                                  \"res\": false\n",
      "                                }\n",
      "                              ]\n",
      "                            }\n",
      "                          ]\n",
      "                        },\n",
      "                        {\n",
      "                          \"token\": \"TYPE_REF\",\n",
      "                          \"res\": true,\n",
      "                          \"children\": [\n",
      "                            {\n",
      "                              \"token\": \"ll\",\n",
      "                              \"res\": false\n",
      "                            }\n",
      "                          ]\n",
      "                        },\n",
      "                        {\n",
      "                          \"token\": \"PAREN_EXPR\",\n",
      "                          \"res\": true,\n",
      "                          \"children\": [\n",
      "                            {\n",
      "                              \"token\": \"DECL_REF_EXPR\",\n",
      "                              \"res\": true,\n",
      "                              \"children\": [\n",
      "                                {\n",
      "                                  \"token\": \"n\",\n",
      "                                  \"res\": false\n",
      "                                }\n",
      "                              ]\n",
      "                            }\n",
      "                          ]\n",
      "                        }\n",
      "                      ]\n",
      "                    }\n",
      "                  ]\n",
      "                },\n",
      "                {\n",
      "                  \"token\": \"UNARY_OPERATOR_POST_++\",\n",
      "                  \"res\": true,\n",
      "                  \"children\": [\n",
      "                    {\n",
      "                      \"token\": \"DECL_REF_EXPR\",\n",
      "                      \"res\": true,\n",
      "                      \"children\": [\n",
      "                        {\n",
      "                          \"token\": \"i\",\n",
      "                          \"res\": false\n",
      "                        }\n",
      "                      ]\n",
      "                    }\n",
      "                  ]\n",
      "                },\n",
      "                {\n",
      "                  \"token\": \"COMPOUND_STMT\",\n",
      "                  \"res\": true,\n",
      "                  \"children\": [\n",
      "                    {\n",
      "                      \"token\": \"CALL_EXPR\",\n",
      "                      \"res\": true,\n",
      "                      \"children\": [\n",
      "                        {\n",
      "                          \"token\": \"NAME\",\n",
      "                          \"res\": true,\n",
      "                          \"children\": [\n",
      "                            {\n",
      "                              \"token\": \"operator>>\",\n",
      "                              \"res\": false\n",
      "                            }\n",
      "                          ]\n",
      "                        },\n",
      "                        {\n",
      "                          \"token\": \"ARGUMENTS\",\n",
      "                          \"res\": true,\n",
      "                          \"children\": [\n",
      "                            {\n",
      "                              \"token\": \"DECL_REF_EXPR\",\n",
      "                              \"res\": true,\n",
      "                              \"children\": [\n",
      "                                {\n",
      "                                  \"token\": \"cin\",\n",
      "                                  \"res\": false\n",
      "                                }\n",
      "                              ]\n",
      "                            },\n",
      "                            {\n",
      "                              \"token\": \"DECL_REF_EXPR\",\n",
      "                              \"res\": true,\n",
      "                              \"children\": [\n",
      "                                {\n",
      "                                  \"token\": \"a\",\n",
      "                                  \"res\": false\n",
      "                                }\n",
      "                              ]\n",
      "                            }\n",
      "                          ]\n",
      "                        }\n",
      "                      ]\n",
      "                    },\n",
      "                    {\n",
      "                      \"token\": \"IF_STMT\",\n",
      "                      \"res\": true,\n",
      "                      \"children\": [\n",
      "                        {\n",
      "                          \"token\": \"BINARY_OPERATOR_>\",\n",
      "                          \"res\": true,\n",
      "                          \"children\": [\n",
      "                            {\n",
      "                              \"token\": \"DECL_REF_EXPR\",\n",
      "                              \"res\": true,\n",
      "                              \"children\": [\n",
      "                                {\n",
      "                                  \"token\": \"left\",\n",
      "                                  \"res\": false\n",
      "                                }\n",
      "                              ]\n",
      "                            },\n",
      "                            {\n",
      "                              \"token\": \"INTEGER_LITERAL\",\n",
      "                              \"res\": true,\n",
      "                              \"children\": [\n",
      "                                {\n",
      "                                  \"token\": \"0\",\n",
      "                                  \"res\": false\n",
      "                                }\n",
      "                              ]\n",
      "                            }\n",
      "                          ]\n",
      "                        },\n",
      "                        {\n",
      "                          \"token\": \"COMPOUND_STMT\",\n",
      "                          \"res\": true,\n",
      "                          \"children\": [\n",
      "                            {\n",
      "                              \"token\": \"UNARY_OPERATOR_POST_++\",\n",
      "                              \"res\": true,\n",
      "                              \"children\": [\n",
      "                                {\n",
      "                                  \"token\": \"DECL_REF_EXPR\",\n",
      "                                  \"res\": true,\n",
      "                                  \"children\": [\n",
      "                                    {\n",
      "                                      \"token\": \"ans\",\n",
      "                                      \"res\": false\n",
      "                                    }\n",
      "                                  ]\n",
      "                                }\n",
      "                              ]\n",
      "                            },\n",
      "                            {\n",
      "                              \"token\": \"COMPOUND_ASSIGNMENT_OPERATOR_+=\",\n",
      "                              \"res\": true,\n",
      "                              \"children\": [\n",
      "                                {\n",
      "                                  \"token\": \"DECL_REF_EXPR\",\n",
      "                                  \"res\": true,\n",
      "                                  \"children\": [\n",
      "                                    {\n",
      "                                      \"token\": \"a\",\n",
      "                                      \"res\": false\n",
      "                                    }\n",
      "                                  ]\n",
      "                                },\n",
      "                                {\n",
      "                                  \"token\": \"DECL_REF_EXPR\",\n",
      "                                  \"res\": true,\n",
      "                                  \"children\": [\n",
      "                                    {\n",
      "                                      \"token\": \"left\",\n",
      "                                      \"res\": false\n",
      "                                    }\n",
      "                                  ]\n",
      "                                }\n",
      "                              ]\n",
      "                            },\n",
      "                            {\n",
      "                              \"token\": \"BINARY_OPERATOR_=\",\n",
      "                              \"res\": true,\n",
      "                              \"children\": [\n",
      "                                {\n",
      "                                  \"token\": \"DECL_REF_EXPR\",\n",
      "                                  \"res\": true,\n",
      "                                  \"children\": [\n",
      "                                    {\n",
      "                                      \"token\": \"left\",\n",
      "                                      \"res\": false\n",
      "                                    }\n",
      "                                  ]\n",
      "                                },\n",
      "                                {\n",
      "                                  \"token\": \"INTEGER_LITERAL\",\n",
      "                                  \"res\": true,\n",
      "                                  \"children\": [\n",
      "                                    {\n",
      "                                      \"token\": \"0\",\n",
      "                                      \"res\": false\n",
      "                                    }\n",
      "                                  ]\n",
      "                                }\n",
      "                              ]\n",
      "                            },\n",
      "                            {\n",
      "                              \"token\": \"IF_STMT\",\n",
      "                              \"res\": true,\n",
      "                              \"children\": [\n",
      "                                {\n",
      "                                  \"token\": \"BINARY_OPERATOR_>\",\n",
      "                                  \"res\": true,\n",
      "                                  \"children\": [\n",
      "                                    {\n",
      "                                      \"token\": \"DECL_REF_EXPR\",\n",
      "                                      \"res\": true,\n",
      "                                      \"children\": [\n",
      "                                        {\n",
      "                                          \"token\": \"a\",\n",
      "                                          \"res\": false\n",
      "                                        }\n",
      "                                      ]\n",
      "                                    },\n",
      "                                    {\n",
      "                                      \"token\": \"DECL_REF_EXPR\",\n",
      "                                      \"res\": true,\n",
      "                                      \"children\": [\n",
      "                                        {\n",
      "                                          \"token\": \"k\",\n",
      "                                          \"res\": false\n",
      "                                        }\n",
      "                                      ]\n",
      "                                    }\n",
      "                                  ]\n",
      "                                },\n",
      "                                {\n",
      "                                  \"token\": \"COMPOUND_STMT\",\n",
      "                                  \"res\": true,\n",
      "                                  \"children\": [\n",
      "                                    {\n",
      "                                      \"token\": \"COMPOUND_ASSIGNMENT_OPERATOR_-=\",\n",
      "                                      \"res\": true,\n",
      "                                      \"children\": [\n",
      "                                        {\n",
      "                                          \"token\": \"DECL_REF_EXPR\",\n",
      "                                          \"res\": true,\n",
      "                                          \"children\": [\n",
      "                                            {\n",
      "                                              \"token\": \"a\",\n",
      "                                              \"res\": false\n",
      "                                            }\n",
      "                                          ]\n",
      "                                        },\n",
      "                                        {\n",
      "                                          \"token\": \"DECL_REF_EXPR\",\n",
      "                                          \"res\": true,\n",
      "                                          \"children\": [\n",
      "                                            {\n",
      "                                              \"token\": \"k\",\n",
      "                                              \"res\": false\n",
      "                                            }\n",
      "                                          ]\n",
      "                                        }\n",
      "                                      ]\n",
      "                                    }\n",
      "                                  ]\n",
      "                                },\n",
      "                                {\n",
      "                                  \"token\": \"COMPOUND_STMT\",\n",
      "                                  \"res\": true,\n",
      "                                  \"children\": [\n",
      "                                    {\n",
      "                                      \"token\": \"BINARY_OPERATOR_=\",\n",
      "                                      \"res\": true,\n",
      "                                      \"children\": [\n",
      "                                        {\n",
      "                                          \"token\": \"DECL_REF_EXPR\",\n",
      "                                          \"res\": true,\n",
      "                                          \"children\": [\n",
      "                                            {\n",
      "                                              \"token\": \"a\",\n",
      "                                              \"res\": false\n",
      "                                            }\n",
      "                                          ]\n",
      "                                        },\n",
      "                                        {\n",
      "                                          \"token\": \"INTEGER_LITERAL\",\n",
      "                                          \"res\": true,\n",
      "                                          \"children\": [\n",
      "                                            {\n",
      "                                              \"token\": \"0\",\n",
      "                                              \"res\": false\n",
      "                                            }\n",
      "                                          ]\n",
      "                                        }\n",
      "                                      ]\n",
      "                                    }\n",
      "                                  ]\n",
      "                                }\n",
      "                              ]\n",
      "                            }\n",
      "                          ]\n",
      "                        }\n",
      "                      ]\n",
      "                    },\n",
      "                    {\n",
      "                      \"token\": \"COMPOUND_ASSIGNMENT_OPERATOR_+=\",\n",
      "                      \"res\": true,\n",
      "                      \"children\": [\n",
      "                        {\n",
      "                          \"token\": \"DECL_REF_EXPR\",\n",
      "                          \"res\": true,\n",
      "                          \"children\": [\n",
      "                            {\n",
      "                              \"token\": \"ans\",\n",
      "                              \"res\": false\n",
      "                            }\n",
      "                          ]\n",
      "                        },\n",
      "                        {\n",
      "                          \"token\": \"BINARY_OPERATOR_/\",\n",
      "                          \"res\": true,\n",
      "                          \"children\": [\n",
      "                            {\n",
      "                              \"token\": \"DECL_REF_EXPR\",\n",
      "                              \"res\": true,\n",
      "                              \"children\": [\n",
      "                                {\n",
      "                                  \"token\": \"a\",\n",
      "                                  \"res\": false\n",
      "                                }\n",
      "                              ]\n",
      "                            },\n",
      "                            {\n",
      "                              \"token\": \"DECL_REF_EXPR\",\n",
      "                              \"res\": true,\n",
      "                              \"children\": [\n",
      "                                {\n",
      "                                  \"token\": \"k\",\n",
      "                                  \"res\": false\n",
      "                                }\n",
      "                              ]\n",
      "                            }\n",
      "                          ]\n",
      "                        }\n",
      "                      ]\n",
      "                    },\n",
      "                    {\n",
      "                      \"token\": \"BINARY_OPERATOR_=\",\n",
      "                      \"res\": true,\n",
      "                      \"children\": [\n",
      "                        {\n",
      "                          \"token\": \"DECL_REF_EXPR\",\n",
      "                          \"res\": true,\n",
      "                          \"children\": [\n",
      "                            {\n",
      "                              \"token\": \"left\",\n",
      "                              \"res\": false\n",
      "                            }\n",
      "                          ]\n",
      "                        },\n",
      "                        {\n",
      "                          \"token\": \"BINARY_OPERATOR_%\",\n",
      "                          \"res\": true,\n",
      "                          \"children\": [\n",
      "                            {\n",
      "                              \"token\": \"DECL_REF_EXPR\",\n",
      "                              \"res\": true,\n",
      "                              \"children\": [\n",
      "                                {\n",
      "                                  \"token\": \"a\",\n",
      "                                  \"res\": false\n",
      "                                }\n",
      "                              ]\n",
      "                            },\n",
      "                            {\n",
      "                              \"token\": \"DECL_REF_EXPR\",\n",
      "                              \"res\": true,\n",
      "                              \"children\": [\n",
      "                                {\n",
      "                                  \"token\": \"k\",\n",
      "                                  \"res\": false\n",
      "                                }\n",
      "                              ]\n",
      "                            }\n",
      "                          ]\n",
      "                        }\n",
      "                      ]\n",
      "                    },\n",
      "                    {\n",
      "                      \"token\": \"IF_STMT\",\n",
      "                      \"res\": true,\n",
      "                      \"children\": [\n",
      "                        {\n",
      "                          \"token\": \"BINARY_OPERATOR_&&\",\n",
      "                          \"res\": true,\n",
      "                          \"children\": [\n",
      "                            {\n",
      "                              \"token\": \"PAREN_EXPR\",\n",
      "                              \"res\": true,\n",
      "                              \"children\": [\n",
      "                                {\n",
      "                                  \"token\": \"BINARY_OPERATOR_==\",\n",
      "                                  \"res\": true,\n",
      "                                  \"children\": [\n",
      "                                    {\n",
      "                                      \"token\": \"DECL_REF_EXPR\",\n",
      "                                      \"res\": true,\n",
      "                                      \"children\": [\n",
      "                                        {\n",
      "                                          \"token\": \"i\",\n",
      "                                          \"res\": false\n",
      "                                        }\n",
      "                                      ]\n",
      "                                    },\n",
      "                                    {\n",
      "                                      \"token\": \"DECL_REF_EXPR\",\n",
      "                                      \"res\": true,\n",
      "                                      \"children\": [\n",
      "                                        {\n",
      "                                          \"token\": \"n\",\n",
      "                                          \"res\": false\n",
      "                                        }\n",
      "                                      ]\n",
      "                                    }\n",
      "                                  ]\n",
      "                                }\n",
      "                              ]\n",
      "                            },\n",
      "                            {\n",
      "                              \"token\": \"PAREN_EXPR\",\n",
      "                              \"res\": true,\n",
      "                              \"children\": [\n",
      "                                {\n",
      "                                  \"token\": \"DECL_REF_EXPR\",\n",
      "                                  \"res\": true,\n",
      "                                  \"children\": [\n",
      "                                    {\n",
      "                                      \"token\": \"left\",\n",
      "                                      \"res\": false\n",
      "                                    }\n",
      "                                  ]\n",
      "                                }\n",
      "                              ]\n",
      "                            }\n",
      "                          ]\n",
      "                        },\n",
      "                        {\n",
      "                          \"token\": \"COMPOUND_STMT\",\n",
      "                          \"res\": true,\n",
      "                          \"children\": [\n",
      "                            {\n",
      "                              \"token\": \"UNARY_OPERATOR_POST_++\",\n",
      "                              \"res\": true,\n",
      "                              \"children\": [\n",
      "                                {\n",
      "                                  \"token\": \"DECL_REF_EXPR\",\n",
      "                                  \"res\": true,\n",
      "                                  \"children\": [\n",
      "                                    {\n",
      "                                      \"token\": \"ans\",\n",
      "                                      \"res\": false\n",
      "                                    }\n",
      "                                  ]\n",
      "                                }\n",
      "                              ]\n",
      "                            }\n",
      "                          ]\n",
      "                        }\n",
      "                      ]\n",
      "                    }\n",
      "                  ]\n",
      "                }\n",
      "              ]\n",
      "            },\n",
      "            {\n",
      "              \"token\": \"CALL_EXPR\",\n",
      "              \"res\": true,\n",
      "              \"children\": [\n",
      "                {\n",
      "                  \"token\": \"NAME\",\n",
      "                  \"res\": true,\n",
      "                  \"children\": [\n",
      "                    {\n",
      "                      \"token\": \"operator<<\",\n",
      "                      \"res\": false\n",
      "                    }\n",
      "                  ]\n",
      "                },\n",
      "                {\n",
      "                  \"token\": \"ARGUMENTS\",\n",
      "                  \"res\": true,\n",
      "                  \"children\": [\n",
      "                    {\n",
      "                      \"token\": \"DECL_REF_EXPR\",\n",
      "                      \"res\": true,\n",
      "                      \"children\": [\n",
      "                        {\n",
      "                          \"token\": \"cout\",\n",
      "                          \"res\": false\n",
      "                        }\n",
      "                      ]\n",
      "                    },\n",
      "                    {\n",
      "                      \"token\": \"DECL_REF_EXPR\",\n",
      "                      \"res\": true,\n",
      "                      \"children\": [\n",
      "                        {\n",
      "                          \"token\": \"ans\",\n",
      "                          \"res\": false\n",
      "                        }\n",
      "                      ]\n",
      "                    }\n",
      "                  ]\n",
      "                }\n",
      "              ]\n",
      "            },\n",
      "            {\n",
      "              \"token\": \"RETURN_STMT\",\n",
      "              \"res\": true,\n",
      "              \"children\": [\n",
      "                {\n",
      "                  \"token\": \"INTEGER_LITERAL\",\n",
      "                  \"res\": true,\n",
      "                  \"children\": [\n",
      "                    {\n",
      "                      \"token\": \"0\",\n",
      "                      \"res\": false\n",
      "                    }\n",
      "                  ]\n",
      "                }\n",
      "              ]\n",
      "            }\n",
      "          ]\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(trees.iloc[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'i': 31827347,\n",
       " 'int': 25890376,\n",
       " 'long': 18038509,\n",
       " '0': 16106854,\n",
       " '1': 15929649,\n",
       " 'n': 13349673,\n",
       " 'a': 10066010,\n",
       " 'operator<<': 7562627,\n",
       " 'x': 7226008,\n",
       " 'j': 7035975,\n",
       " '<': 6431762,\n",
       " '>': 6197419,\n",
       " 'operator[]': 6045917,\n",
       " 'operator>>': 5497929,\n",
       " 'b': 5326486,\n",
       " 'll': 4508242,\n",
       " 'cin': 4429537,\n",
       " 'cout': 4421382,\n",
       " 's': 4144000,\n",
       " 'ans': 3963303,\n",
       " 'k': 3961537,\n",
       " '[': 3909721,\n",
       " ']': 3909299,\n",
       " '2': 3870988,\n",
       " 'm': 3452776,\n",
       " '::': 3439870,\n",
       " 'v': 3242932,\n",
       " 'std': 3214599,\n",
       " 'y': 2859375,\n",
       " ',': 2716950,\n",
       " 'c': 2622521,\n",
       " 'main': 2611171,\n",
       " 'vector': 2599643,\n",
       " 'const': 2446546,\n",
       " 'p': 2323290,\n",
       " 'r': 2290901,\n",
       " 'l': 2263686,\n",
       " 't': 2011363,\n",
       " 'T': 1685724,\n",
       " 'pair': 1662798,\n",
       " 'endl': 1448796,\n",
       " '&': 1401756,\n",
       " 'void': 1390236,\n",
       " 'N': 1385845,\n",
       " 'u': 1379802,\n",
       " 'size': 1325908,\n",
       " 'cnt': 1296733,\n",
       " 'string': 1228257,\n",
       " 'scanf': 1212740,\n",
       " 'd': 1210295,\n",
       " 'sum': 1200130,\n",
       " 'q': 1132427,\n",
       " 'res': 1097368,\n",
       " 'tie': 1092758,\n",
       " 'f': 1074405,\n",
       " 'double': 1060846,\n",
       " 'printf': 1057509,\n",
       " 'bool': 1032033,\n",
       " 'push_back': 1015712,\n",
       " 'first': 1012935,\n",
       " 'false': 1008204,\n",
       " 'char': 983010,\n",
       " 'second': 979259,\n",
       " 'arr': 888143,\n",
       " '10': 859217,\n",
       " 'sync_with_stdio': 819254,\n",
       " 'dp': 770674,\n",
       " 'min': 753160,\n",
       " '3': 735297,\n",
       " 'mod': 690598,\n",
       " 'it': 687203,\n",
       " 'max': 686318,\n",
       " 'ch': 675398,\n",
       " \"'0'\": 646867,\n",
       " '\"%d\"': 617790,\n",
       " 'begin': 609956,\n",
       " 'mid': 609616,\n",
       " 'end': 605492,\n",
       " 'A': 591496,\n",
       " '\" \"': 580128,\n",
       " 'pos': 578132,\n",
       " 'true': 577239,\n",
       " 'num': 565239,\n",
       " 'g': 560596,\n",
       " 'std::ios_base': 527686,\n",
       " 'e': 507566,\n",
       " '4': 502652,\n",
       " 'maxn': 486581,\n",
       " 'flag': 480758,\n",
       " 'operator=': 470399,\n",
       " 'node': 460597,\n",
       " 'val': 460048,\n",
       " 'w': 451462,\n",
       " 'cur': 450377,\n",
       " 'sort': 449229,\n",
       " 'LL': 444719,\n",
       " 'temp': 444248,\n",
       " 'h': 439831,\n",
       " 'tmp': 437694,\n",
       " 'z': 435631,\n",
       " 'st': 428429,\n",
       " 'vis': 427271,\n",
       " '5': 425505,\n",
       " 'str': 422075,\n",
       " 'len': 409525,\n",
       " '7': 403774,\n",
       " 'operator*': 381575,\n",
       " '1e9': 379217,\n",
       " 'dfs': 362135,\n",
       " 'solve': 356960,\n",
       " 'now': 353903,\n",
       " 'MOD': 352728,\n",
       " 'mp': 349545,\n",
       " '\"\\\\n\"': 348271,\n",
       " 'map': 346045,\n",
       " 'count': 343124,\n",
       " 'gcd': 334005,\n",
       " 'ret': 329908,\n",
       " 'unsigned': 323738,\n",
       " 'mx': 322482,\n",
       " 'getchar': 319120,\n",
       " 'id': 318914,\n",
       " '*': 318679,\n",
       " 'M': 317626,\n",
       " '100005': 316066,\n",
       " 'B': 315167,\n",
       " 'set': 314144,\n",
       " 'read': 308352,\n",
       " \"'\\\\n'\": 302247,\n",
       " 'insert': 289033,\n",
       " 'vi': 285017,\n",
       " 'abs': 281245,\n",
       " 'std::ios': 278930,\n",
       " 's1': 275642,\n",
       " 'pii': 269734,\n",
       " '200005': 267472,\n",
       " '\"NO\"': 267046,\n",
       " 'L': 265678,\n",
       " 'R': 262575,\n",
       " '1000000007': 257031,\n",
       " 'ld': 244576,\n",
       " 'operator+': 243404,\n",
       " 'operator-': 241028,\n",
       " '\"YES\"': 237735,\n",
       " 'INF': 234865,\n",
       " \"'a'\": 234068,\n",
       " 'MAXN': 230057,\n",
       " 'S': 227814,\n",
       " 'allocator': 225193,\n",
       " 'o': 220797,\n",
       " 'operator==': 220109,\n",
       " '\"%d\\\\n\"': 219750,\n",
       " 'idx': 216405,\n",
       " 'vec': 212831,\n",
       " 'to': 212019,\n",
       " 'x1': 211434,\n",
       " 'sz': 210855,\n",
       " '100': 208935,\n",
       " 'tot': 205995,\n",
       " 'P': 203714,\n",
       " 'ostream': 203320,\n",
       " 's2': 203182,\n",
       " 'length': 200553,\n",
       " \"' '\": 199160,\n",
       " 'os': 197471,\n",
       " 'push': 194675,\n",
       " 'adj': 193969,\n",
       " 'memset': 193762,\n",
       " '6': 190398,\n",
       " 'operator!=': 189299,\n",
       " 'C': 189041,\n",
       " 'mn': 188887,\n",
       " 'operator': 188552,\n",
       " 'in': 185497,\n",
       " 'make_pair': 184740,\n",
       " 'find': 182643,\n",
       " 'puts': 181804,\n",
       " '30': 180275,\n",
       " '31': 178806,\n",
       " \"'1'\": 178076,\n",
       " 'pre': 174464,\n",
       " 'ii': 172077,\n",
       " 'check': 171301,\n",
       " '8': 171260,\n",
       " 'top': 170126,\n",
       " 'fa': 169983,\n",
       " 'tree': 169918,\n",
       " 'add': 169767,\n",
       " 'ok': 169020,\n",
       " 'inf': 167376,\n",
       " '26': 166202,\n",
       " 'ar': 163286,\n",
       " 'ull': 160770,\n",
       " 'p1': 160580,\n",
       " 'x2': 160544,\n",
       " \"'-'\": 160299,\n",
       " 'Point': 159900,\n",
       " '9': 156884,\n",
       " 'operator->': 156649,\n",
       " '\"%d%d\"': 156177,\n",
       " '20': 155062,\n",
       " '100010': 154456,\n",
       " \"'9'\": 154288,\n",
       " 'y1': 153807,\n",
       " 'last': 152091,\n",
       " 'empty': 152019,\n",
       " 'out': 150074,\n",
       " '1005': 148636,\n",
       " 'root': 148043,\n",
       " 'v1': 147158,\n",
       " '105': 143756,\n",
       " 'p2': 143428,\n",
       " 'ss': 142741,\n",
       " 'operator+=': 141382,\n",
       " '1000': 139833,\n",
       " 'erase': 139077,\n",
       " \"'.'\": 138882,\n",
       " 'lli': 138320,\n",
       " 'ind': 137587,\n",
       " '200010': 136794,\n",
       " 'V': 136308,\n",
       " 'point': 134184,\n",
       " '1e5': 132747,\n",
       " 'T1': 132042,\n",
       " '1LL': 131975,\n",
       " 'query': 131592,\n",
       " 'pop': 131417,\n",
       " 'base': 131183,\n",
       " 'swap': 131069,\n",
       " '1000005': 125833,\n",
       " 'cost': 125566,\n",
       " 'cerr': 125391,\n",
       " '\"%lld\"': 124730,\n",
       " 'T2': 124275,\n",
       " 'G': 124137,\n",
       " '1ll': 123219,\n",
       " 'pll': 122316,\n",
       " 'rt': 122226,\n",
       " 'left': 121645,\n",
       " 'X': 121328,\n",
       " 'queue': 120170,\n",
       " 'auto': 119792,\n",
       " 'power': 118973,\n",
       " 'c1': 117664,\n",
       " 'y2': 115987,\n",
       " 'Q': 114435,\n",
       " 'operator<': 114058,\n",
       " '\"No\"': 114033,\n",
       " 'a1': 113782,\n",
       " 'low': 111932,\n",
       " 'v2': 111420,\n",
       " 'nxt': 111320,\n",
       " 't1': 110911,\n",
       " 'K': 110817,\n",
       " 'less': 110239,\n",
       " 'par': 109627,\n",
       " 'start': 109084,\n",
       " 'U': 108162,\n",
       " 'used': 107982,\n",
       " '+': 107829,\n",
       " 'index': 106538,\n",
       " 'prime': 105612,\n",
       " 'iterator': 104222,\n",
       " 'struct': 103979,\n",
       " 'value_type': 103220,\n",
       " '\"%s\"': 101490,\n",
       " 'cmp': 101409,\n",
       " 'result': 101388,\n",
       " 'get': 101142,\n",
       " 'pr': 101102,\n",
       " 'curr': 100873,\n",
       " 'putchar': 99971,\n",
       " 'head': 98738,\n",
       " '1e18': 98305,\n",
       " 'sqrt': 97965,\n",
       " 'visited': 97570,\n",
       " 'right': 96178,\n",
       " 'priority_queue': 96119,\n",
       " '\"YES\\\\n\"': 95892,\n",
       " 'dist': 95105,\n",
       " 'dis': 94993,\n",
       " 'pi': 94266,\n",
       " 'int64_t': 94191,\n",
       " 'edge': 94099,\n",
       " 'operator++': 94011,\n",
       " 'MAX': 93709,\n",
       " '\"Yes\"': 93240,\n",
       " 'update': 93201,\n",
       " 'tr': 92008,\n",
       " 'ma': 90801,\n",
       " '1e6': 90583,\n",
       " 't2': 90576,\n",
       " 'sum1': 90138,\n",
       " '1.0': 89557,\n",
       " '100000': 88269,\n",
       " '\"NO\\\\n\"': 86011,\n",
       " 'Node': 85963,\n",
       " 'mi': 85842,\n",
       " '\"%lld\\\\n\"': 85484,\n",
       " '101': 85388,\n",
       " 'next': 84840,\n",
       " '2e5': 84449,\n",
       " '1000000': 83751,\n",
       " 'dep': 83596,\n",
       " '300005': 83498,\n",
       " 'a2': 83370,\n",
       " \"'*'\": 83001,\n",
       " 'D': 82412,\n",
       " '0x3f3f3f3f': 82288,\n",
       " '100001': 82247,\n",
       " 'lo': 82157,\n",
       " \"'A'\": 82111,\n",
       " '1010': 82025,\n",
       " 'c2': 81497,\n",
       " 'clear': 81065,\n",
       " 'front': 81050,\n",
       " 'resize': 80691,\n",
       " 'lower_bound': 80047,\n",
       " 'data': 79482,\n",
       " 'back': 79086,\n",
       " 'eps': 78241,\n",
       " '': 77449,\n",
       " 'dx': 77072,\n",
       " 'xx': 77039,\n",
       " '1000010': 76998,\n",
       " 'acos': 76851,\n",
       " 'mul': 76638,\n",
       " 'build': 75462,\n",
       " 'rem': 75411,\n",
       " '\"-1\"': 74913,\n",
       " 'init': 74576,\n",
       " '\"%d \"': 74501,\n",
       " 'operator%': 74126,\n",
       " '998244353': 73442,\n",
       " 'reverse': 72629,\n",
       " \"'#'\": 72301,\n",
       " 'inv': 72092,\n",
       " 'dy': 72007,\n",
       " '110': 71883,\n",
       " '60': 71878,\n",
       " 'sum2': 71814,\n",
       " 'vll': 71745,\n",
       " 'PI': 71692,\n",
       " 'aa': 71324,\n",
       " 'op': 71149,\n",
       " 'ans1': 70566,\n",
       " 'maxi': 70491,\n",
       " 'hi': 69282,\n",
       " 'prev': 69104,\n",
       " 'col': 68979,\n",
       " 'isdigit': 68627,\n",
       " 'int32_t': 67826,\n",
       " 'print': 67572,\n",
       " 'mm': 67456,\n",
       " '48': 66785,\n",
       " '\"%d %d\"': 66775,\n",
       " 'multiset': 66762,\n",
       " 'maxx': 66361,\n",
       " 'value': 66349,\n",
       " 'mark': 66065,\n",
       " 'pow': 66013,\n",
       " 'tt': 65730,\n",
       " '11': 65635,\n",
       " '1001': 65362,\n",
       " 'mask': 64598,\n",
       " 'strlen': 64388,\n",
       " 'mini': 64228,\n",
       " 'fact': 64124,\n",
       " 'pq': 63663,\n",
       " 'F': 63181,\n",
       " 'seg': 63075,\n",
       " 'pt': 62895,\n",
       " 'operator++_POST': 62421,\n",
       " '__gcd': 61983,\n",
       " 'H': 61620,\n",
       " 'bit': 61510,\n",
       " 'E': 61219,\n",
       " 'fixed': 60959,\n",
       " 'k1': 60347,\n",
       " 'size_t': 60172,\n",
       " '0x7fffffff': 59908,\n",
       " 'exit': 59855,\n",
       " '15': 59801,\n",
       " '\"0\"': 59701,\n",
       " 'ans2': 59579,\n",
       " 'write': 59169,\n",
       " '5005': 58880,\n",
       " '14': 58876,\n",
       " '50': 58551,\n",
       " 'vl': 58476,\n",
       " 'to_string': 58326,\n",
       " 'cc': 58093,\n",
       " 'setprecision': 57954,\n",
       " 'sol': 57629,\n",
       " 'Y': 57468,\n",
       " 'args': 57226,\n",
       " 'operator>': 56906,\n",
       " 'parent': 56853,\n",
       " 'minn': 56325,\n",
       " 'diff': 56110,\n",
       " 'type': 56036,\n",
       " 'stack': 55788,\n",
       " '2005': 55727,\n",
       " '200001': 55403,\n",
       " '12': 55156,\n",
       " 'operator()': 54869,\n",
       " 'vii': 54620,\n",
       " 'total': 54530,\n",
       " '55': 54411,\n",
       " 'fac': 54048,\n",
       " 'n1': 54021,\n",
       " 'md': 54019,\n",
       " 'graph': 53824,\n",
       " 'tp': 53709,\n",
       " 'l1': 53317,\n",
       " 'substr': 52737,\n",
       " 'r1': 52427,\n",
       " 'up': 51904,\n",
       " '_Rb_tree_const_iterator': 51820,\n",
       " 'answer': 51601,\n",
       " 'istream': 51106,\n",
       " 'unordered_map': 50972,\n",
       " 're': 50688,\n",
       " 'input': 50421,\n",
       " 'basic_string': 50379,\n",
       " 'm1': 49903,\n",
       " 'ara': 49883,\n",
       " 'EPS': 49636,\n",
       " \"'o'\": 49181,\n",
       " 'pp': 48840,\n",
       " 'itr': 48782,\n",
       " 'tl': 48770,\n",
       " 'ct': 48664,\n",
       " 'operator/': 48636,\n",
       " 'high': 48610,\n",
       " 'son': 48220,\n",
       " 'cnt1': 47983,\n",
       " 'greater': 47815,\n",
       " '1e-9': 47706,\n",
       " 'name': 47584,\n",
       " 'vvi': 47312,\n",
       " 'deg': 47235,\n",
       " '200000': 47229,\n",
       " 'k2': 47011,\n",
       " '__gnu_pbds': 46862,\n",
       " 'pref': 46620,\n",
       " 'sign': 46612,\n",
       " 'comp': 46491,\n",
       " 'db': 46395,\n",
       " 'que': 46291,\n",
       " 'buf': 46205,\n",
       " '\", \"': 46190,\n",
       " '200': 46151,\n",
       " 'yy': 46090,\n",
       " '\"-1\\\\n\"': 45967,\n",
       " 'operatorvoid*': 45785,\n",
       " 'operator void *': 45785,\n",
       " 'Args': 45632,\n",
       " '25': 45565,\n",
       " 'h1': 45499,\n",
       " 'calc': 45441,\n",
       " '\"\"': 45126,\n",
       " '10000': 44988,\n",
       " 'one': 44964,\n",
       " 'vv': 44944,\n",
       " 'b1': 44814,\n",
       " '1000001': 44630,\n",
       " '100100': 44606,\n",
       " 'lld': 44596,\n",
       " 'mat': 44179,\n",
       " 'bb': 44107,\n",
       " '__print': 44106,\n",
       " 'f1': 44085,\n",
       " 'neg': 44049,\n",
       " 'lcm': 43543,\n",
       " 'siz': 43504,\n",
       " 'pop_back': 43268,\n",
       " 'upper_bound': 43156,\n",
       " 'at': 43100,\n",
       " '500005': 42927,\n",
       " '300010': 42772,\n",
       " 'PII': 42698,\n",
       " 'li': 42163,\n",
       " \"'B'\": 42155,\n",
       " 'l2': 41718,\n",
       " 'stringstream': 41493,\n",
       " 'ed': 41224,\n",
       " 'line': 41221,\n",
       " 'aux': 41208,\n",
       " 'all': 40555,\n",
       " 'dfs2': 40443,\n",
       " 'rr': 40412,\n",
       " 'pw': 40232,\n",
       " 'VI': 39813,\n",
       " 'h2': 39811,\n",
       " 'n2': 39803,\n",
       " 'argc': 39761,\n",
       " 'counter': 39716,\n",
       " 'r2': 39668,\n",
       " 'vs': 39537,\n",
       " 'float': 39140,\n",
       " 'number': 39001,\n",
       " 'go': 38957,\n",
       " 'color': 38615,\n",
       " 'd1': 38523,\n",
       " 'nn': 38473,\n",
       " \"'i'\": 38426,\n",
       " 'I': 38405,\n",
       " '\"%d%d%d\"': 38351,\n",
       " 'argv': 38238,\n",
       " 'pa': 38215,\n",
       " '19': 38196,\n",
       " 'Max': 38036,\n",
       " 'names': 38001,\n",
       " \"'x'\": 37955,\n",
       " 'arg1': 37953,\n",
       " 'dfn': 37916,\n",
       " 'cnt2': 37812,\n",
       " 'rhs': 37766,\n",
       " 'sub': 37657,\n",
       " 'exp': 37656,\n",
       " 'emplace_back': 37572,\n",
       " \"'u'\": 37502,\n",
       " 'hh': 37491,\n",
       " 'best': 37455,\n",
       " 'deque': 37438,\n",
       " 'time': 37296,\n",
       " 'ls': 37293,\n",
       " 'from': 37206,\n",
       " 'freq': 37089,\n",
       " 'no': 37051,\n",
       " 'en': 36810,\n",
       " 'edges': 36776,\n",
       " 'is': 36600,\n",
       " \"'e'\": 36495,\n",
       " 'Mod': 36357,\n",
       " 'lst': 36278,\n",
       " 'zero': 36022,\n",
       " 'ps': 35752,\n",
       " 'vc': 35540,\n",
       " 'mt19937': 35486,\n",
       " 'nx': 35481,\n",
       " 'bfs': 35432,\n",
       " 'ta': 35375,\n",
       " 'lim': 35282,\n",
       " 'test': 35278,\n",
       " 'kk': 35035,\n",
       " 'fl': 35001,\n",
       " \"'S'\": 34931,\n",
       " 'si': 34921,\n",
       " 'rs': 34705,\n",
       " 'f2': 34698,\n",
       " 'row': 34180,\n",
       " '\"No\\\\n\"': 33910,\n",
       " 'PT': 33889,\n",
       " '\"Yes\\\\n\"': 33765,\n",
       " 'q1': 33750,\n",
       " '1000000000': 33718,\n",
       " 'primes': 33699,\n",
       " 'sm': 33492,\n",
       " 'm2': 33440,\n",
       " 'W': 33440,\n",
       " \"'Q'\": 33360,\n",
       " 'fb': 33151,\n",
       " '\"1\"': 33010,\n",
       " 'an': 32959,\n",
       " 'Edge': 32946,\n",
       " 'depth': 32888,\n",
       " \"'D'\": 32878,\n",
       " '505': 32789,\n",
       " 'Ans': 32715,\n",
       " 'i64': 32690,\n",
       " 'x3': 32350,\n",
       " 'child': 32335,\n",
       " '32': 32239,\n",
       " 'nums': 32219,\n",
       " 'tm': 32211,\n",
       " 'dfs1': 32196,\n",
       " 'i1': 32156,\n",
       " 'Arg1': 31916,\n",
       " 'tab': 31850,\n",
       " 'sa': 31639,\n",
       " 'qr': 31554,\n",
       " 'nd': 31506,\n",
       " 'operator&': 31329,\n",
       " \"'R'\": 31240,\n",
       " 'bigint': 31158,\n",
       " 'del': 31121,\n",
       " 'tb': 30843,\n",
       " '\"%I64d\"': 30806,\n",
       " 'array': 30720,\n",
       " \"'U'\": 30703,\n",
       " 'step': 30692,\n",
       " '_': 30648,\n",
       " 'dd': 30564,\n",
       " '18': 30478,\n",
       " '_Rb_tree_iterator': 30202,\n",
       " 'T3': 30039,\n",
       " 'can': 29854,\n",
       " 'ptr': 29852,\n",
       " 'operator++_PRE': 29842,\n",
       " 'rev': 29819,\n",
       " 'upd': 29764,\n",
       " '200100': 29759,\n",
       " 'se': 29746,\n",
       " '_iterator': 29714,\n",
       " '24': 29710,\n",
       " 'need': 29628,\n",
       " 'operator--': 29614,\n",
       " 'int64': 29552,\n",
       " 'MX': 29475,\n",
       " 'mint': 29268,\n",
       " 'Line': 29146,\n",
       " 'lazy': 29131,\n",
       " 'd2': 29120,\n",
       " \"'?'\": 29087,\n",
       " '10005': 29083,\n",
       " '16': 28878,\n",
       " 'sq': 28795,\n",
       " 'two': 28721,\n",
       " '17': 28605,\n",
       " 'Vector': 28530,\n",
       " \"'z'\": 28468,\n",
       " 'nod': 28282,\n",
       " 'ceil': 28250,\n",
       " 'operator--_POST': 28173,\n",
       " 'merge': 28170,\n",
       " '100007': 28152,\n",
       " '2010': 28014,\n",
       " 'rec': 27958,\n",
       " 'grid': 27934,\n",
       " 'complex': 27933,\n",
       " 'key': 27900,\n",
       " 'dif': 27899,\n",
       " 'nodes': 27806,\n",
       " 'Min': 27672,\n",
       " 'odd': 27641,\n",
       " 'ql': 27624,\n",
       " \"'('\": 27454,\n",
       " 'visit': 27286,\n",
       " '21': 27269,\n",
       " '5010': 27239,\n",
       " 'tc': 27216,\n",
       " 'other': 27141,\n",
       " 'cont': 27046,\n",
       " 'nr': 27027,\n",
       " 'co': 26886,\n",
       " '0LL': 26804,\n",
       " '13': 26799,\n",
       " 'lint': 26740,\n",
       " '22': 26728,\n",
       " 'trie': 26635,\n",
       " 'lb': 26619,\n",
       " 'inp': 26476,\n",
       " 'ff': 26256,\n",
       " '2000': 26206,\n",
       " 'b2': 26154,\n",
       " 'ty': 26143,\n",
       " '&&': 26113,\n",
       " 'tag': 26043,\n",
       " 'fabs': 25976,\n",
       " '_outputPtr': 25919,\n",
       " '200007': 25906,\n",
       " 'pl': 25837,\n",
       " 'MAX_N': 25812,\n",
       " '__normal_iterator': 25672,\n",
       " 'rd': 25633,\n",
       " \"'X'\": 25575,\n",
       " 'it1': 25561,\n",
       " 'it2': 25559,\n",
       " 'bs': 25491,\n",
       " \"'W'\": 25369,\n",
       " '3e5': 25368,\n",
       " '\"%c\"': 25287,\n",
       " 'tail': 25212,\n",
       " 'comma': 24944,\n",
       " '27': 24788,\n",
       " '500010': 24639,\n",
       " 'cl': 24561,\n",
       " 'level': 24510,\n",
       " 'fr': 24382,\n",
       " 'str1': 24378,\n",
       " 'suma': 24363,\n",
       " 'bitset': 24258,\n",
       " 'suf': 24222,\n",
       " '28': 24134,\n",
       " '&...': 24032,\n",
       " 'q2': 23924,\n",
       " 'split': 23907,\n",
       " 'dir': 23883,\n",
       " 'found': 23873,\n",
       " 'sb': 23839,\n",
       " 'seq': 23715,\n",
       " '\"%I64d\\\\n\"': 23714,\n",
       " 'sy': 23684,\n",
       " 'rnd': 23522,\n",
       " 'ex': 23459,\n",
       " 'po': 23457,\n",
       " 'change': 23410,\n",
       " 'chk': 23296,\n",
       " 'le': 23209,\n",
       " 'done': 23089,\n",
       " 'mo': 23075,\n",
       " 'y3': 23005,\n",
       " 'oo': 22873,\n",
       " 'sp': 22827,\n",
       " 'null_type': 22802,\n",
       " 'i2': 22789,\n",
       " 'rbegin': 22765,\n",
       " 'key_type': 22737,\n",
       " '2e9': 22667,\n",
       " 'path': 22653,\n",
       " 'rest': 22647,\n",
       " '__f': 22635,\n",
       " 'rb_tree_tag': 22612,\n",
       " '_a': 22577,\n",
       " 'ax': 22540,\n",
       " 'tree_order_statistics_node_update': 22522,\n",
       " '_b': 22491,\n",
       " '_y': 22480,\n",
       " 've': 22439,\n",
       " '_x': 22406,\n",
       " '300000': 22396,\n",
       " 'even': 22379,\n",
       " 'max1': 22311,\n",
       " 'ri': 22290,\n",
       " 'fin': 22205,\n",
       " '\"HARD\"': 22195,\n",
       " 'src': 22170,\n",
       " 'uint64_t': 22110,\n",
       " 'isPrime': 22096,\n",
       " 'cd': 22069,\n",
       " 'DFS': 22055,\n",
       " 'log': 22023,\n",
       " 'lc': 22012,\n",
       " 'vb': 21857,\n",
       " 'sieve': 21834,\n",
       " 'ms': 21767,\n",
       " 'mas': 21744,\n",
       " 'gr': 21740,\n",
       " '\"%d %d\\\\n\"': 21680,\n",
       " 'ny': 21656,\n",
       " 'stk': 21534,\n",
       " 'vp': 21533,\n",
       " '\"%lld%lld\"': 21470,\n",
       " '\"EASY\"': 21378,\n",
       " 'br': 21335,\n",
       " 'la': 21302,\n",
       " 'bl': 21236,\n",
       " 's3': 21234,\n",
       " 'cs': 21232,\n",
       " '\"(\"': 21226,\n",
       " 'itl': 21200,\n",
       " 'sx': 21085,\n",
       " 'cal': 21069,\n",
       " 'as': 21062,\n",
       " '1000007': 21061,\n",
       " 'num1': 20979,\n",
       " '\"]\"': 20859,\n",
       " '100009': 20834,\n",
       " 'list': 20828,\n",
       " 'precision': 20656,\n",
       " 'maxN': 20497,\n",
       " 'gc': 20467,\n",
       " 'ab': 20429,\n",
       " \"'C'\": 20361,\n",
       " '\")\"': 20338,\n",
       " '\",\"': 20328,\n",
       " 'current': 20255,\n",
       " '400005': 20207,\n",
       " 'sc': 20189,\n",
       " \"')'\": 20164,\n",
       " \"','\": 20105,\n",
       " 'str2': 20105,\n",
       " '_i': 20105,\n",
       " '29': 20073,\n",
       " 'tuple': 20063,\n",
       " 'LD': 20031,\n",
       " 'v3': 20017,\n",
       " 'jj': 19996,\n",
       " 'el': 19980,\n",
       " 'cx': 19942,\n",
       " 'arr2': 19856,\n",
       " 'div': 19856,\n",
       " '\"0\\\\n\"': 19848,\n",
       " 'good': 19760,\n",
       " 'iter': 19642,\n",
       " 'work': 19627,\n",
       " '2.0': 19622,\n",
       " 'dp2': 19619,\n",
       " 'nc': 19586,\n",
       " 'gg': 19460,\n",
       " '23': 19307,\n",
       " 'func': 19301,\n",
       " 'maxm': 19252,\n",
       " '2000005': 19201,\n",
       " 'vt': 19192,\n",
       " 'assign': 19140,\n",
       " 'state': 19120,\n",
       " 'ask': 19077,\n",
       " 'opt': 19069,\n",
       " 'cn': 18998,\n",
       " '0.0': 18963,\n",
       " '__gnu_cxx': 18925,\n",
       " 'ins': 18917,\n",
       " 'isprime': 18914,\n",
       " 'time_since_epoch': 18908,\n",
       " '0ll': 18885,\n",
       " 'down': 18816,\n",
       " 'sta': 18806,\n",
       " 'uint': 18777,\n",
       " '1e3': 18722,\n",
       " 'GCD': 18658,\n",
       " 'limit': 18655,\n",
       " 'brr': 18625,\n",
       " 'vpii': 18619,\n",
       " 'mult': 18581,\n",
       " 'spf': 18578,\n",
       " \"'b'\": 18519,\n",
       " 'nex': 18497,\n",
       " 'fun': 18491,\n",
       " '102': 18474,\n",
       " 'arr1': 18458,\n",
       " 'unique': 18418,\n",
       " '1000100': 18416,\n",
       " 'order': 18316,\n",
       " '111': 18310,\n",
       " '500': 18234,\n",
       " '0x7fffffffffffffffLL': 18134,\n",
       " 'tx': 18053,\n",
       " '3005': 17899,\n",
       " 'ts': 17871,\n",
       " 'ac': 17849,\n",
       " 'sgn': 17808,\n",
       " \"'2'\": 17742,\n",
       " 'lca': 17696,\n",
       " '5000': 17693,\n",
       " '\"}\"': 17685,\n",
       " 'cy': 17655,\n",
       " 'dr': 17588,\n",
       " 'lt': 17563,\n",
       " 'err': 17559,\n",
       " 'dp1': 17557,\n",
       " 'debug': 17551,\n",
       " 'fx': 17494,\n",
       " 'fill': 17490,\n",
       " '1000006': 17490,\n",
       " 'ne': 17489,\n",
       " 'ay': 17450,\n",
       " 'gn': 17397,\n",
       " '\"[\"': 17366,\n",
       " 'tim': 17350,\n",
       " 'qq': 17319,\n",
       " 'matrix': 17223,\n",
       " 'qpow': 17217,\n",
       " '\" : \"': 17206,\n",
       " '1000000009': 17173,\n",
       " 'temp1': 17170,\n",
       " '200009': 17165,\n",
       " 'output': 17147,\n",
       " 'Solve': 17129,\n",
       " \"'\\\\0'\": 17127,\n",
       " 'valid': 17082,\n",
       " 'Int': 17069,\n",
       " 'num2': 17031,\n",
       " '300001': 17031,\n",
       " 'lhs': 17007,\n",
       " 'nw': 16883,\n",
       " 'sqr': 16816,\n",
       " 'pdd': 16731,\n",
       " 'clock': 16712,\n",
       " '5001': 16695,\n",
       " 'stream': 16686,\n",
       " 'lf': 16678,\n",
       " 'sl': 16660,\n",
       " '51': 16657,\n",
       " 'ver': 16648,\n",
       " 'rand': 16613,\n",
       " '1e-8': 16548,\n",
       " 'cap': 16546,\n",
       " 'cp': 16520,\n",
       " 'SZ': 16516,\n",
       " 'memo': 16497,\n",
       " 'seed': 16405,\n",
       " 'modify': 16402,\n",
       " 'temp2': 16398,\n",
       " 'sumb': 16390,\n",
       " 'cross': 16376,\n",
       " 'bc': 16345,\n",
       " 'rc': 16337,\n",
       " 'x0': 16320,\n",
       " 'dat': 16315,\n",
       " 'day': 16271,\n",
       " 'normal': 16263,\n",
       " 'ck': 16214,\n",
       " 'compare': 16139,\n",
       " 'ip': 16126,\n",
       " '\"Ehab\"': 16082,\n",
       " 'delta': 16062,\n",
       " 'carry': 16047,\n",
       " '\"%d %d %d\"': 16021,\n",
       " 'ti': 16002,\n",
       " 'ai': 15978,\n",
       " '100002': 15961,\n",
       " 'rng': 15954,\n",
       " 'lvl': 15863,\n",
       " 'qu': 15860,\n",
       " 'ones': 15797,\n",
       " '10001': 15781,\n",
       " 'e1': 15758,\n",
       " 'ULL': 15746,\n",
       " 'area': 15737,\n",
       " 'srand': 15730,\n",
       " '\"Mahmoud\"': 15729,\n",
       " 'count1': 15700,\n",
       " '1e-6': 15683,\n",
       " 'link': 15674,\n",
       " 'unordered_set': 15657,\n",
       " 'LINF': 15654,\n",
       " '&&...': 15605,\n",
       " 'was': 15529,\n",
       " 'ds': 15460,\n",
       " 'tem': 15456,\n",
       " 'pd': 15445,\n",
       " 'bx': 15442,\n",
       " '_out': 15441,\n",
       " 'vx': 15423,\n",
       " 'np': 15419,\n",
       " '0x3f3f3f3f3f3f3f3f': 15373,\n",
       " '10010': 15353,\n",
       " 'pb': 15337,\n",
       " '300': 15328,\n",
       " 'xs': 15315,\n",
       " 'iii': 15307,\n",
       " 'points': 15289,\n",
       " 'lol': 15272,\n",
       " '200002': 15227,\n",
       " '400010': 15224,\n",
       " '2LL': 15125,\n",
       " 'x4': 15036,\n",
       " \"'n'\": 15032,\n",
       " '2001': 14999,\n",
       " 't3': 14997,\n",
       " '\"=\"': 14961,\n",
       " 'dq': 14958,\n",
       " '10000000': 14935,\n",
       " 'sr': 14911,\n",
       " 'ord': 14862,\n",
       " 'npos': 14852,\n",
       " 'kol': 14837,\n",
       " 'PLL': 14789,\n",
       " 'cr': 14775,\n",
       " 'tmp2': 14728,\n",
       " '\"%lld \"': 14724,\n",
       " 'px': 14684,\n",
       " '_W': 14657,\n",
       " 'target': 14635,\n",
       " 'ModInt': 14625,\n",
       " 'std::chrono::_V2::steady_clock': 14609,\n",
       " 'dem': 14569,\n",
       " '40': 14498,\n",
       " 'fy': 14466,\n",
       " 'flg': 14454,\n",
       " '2000010': 14399,\n",
       " 'powmod': 14394,\n",
       " 'book': 14390,\n",
       " '_inputPtr': 14387,\n",
       " \"'L'\": 14383,\n",
       " 'min1': 14377,\n",
       " 'judge': 14372,\n",
       " 'loc': 14350,\n",
       " 'fail': 14345,\n",
       " 'INT': 14335,\n",
       " 'ns': 14325,\n",
       " 'prefix': 14287,\n",
       " 'nb': 14277,\n",
       " 'lp': 14247,\n",
       " 'lx': 14223,\n",
       " 'mp1': 14196,\n",
       " '1002': 14166,\n",
       " 'floor': 14159,\n",
       " 'modint': 14133,\n",
       " 'big': 14130,\n",
       " 'Query': 14104,\n",
       " '1e-10': 14096,\n",
       " 'tmp1': 14055,\n",
       " 'hash': 14003,\n",
       " 'typename': 13967,\n",
       " '\"%lld %lld\"': 13930,\n",
       " 'use': 13925,\n",
       " 'DP': 13896,\n",
       " 'by': 13890,\n",
       " 'has': 13845,\n",
       " 'typeof': 13800,\n",
       " 'req': 13774,\n",
       " '_n': 13769,\n",
       " '5e5': 13756,\n",
       " '256': 13755,\n",
       " 'dig': 13729,\n",
       " 'inc': 13706,\n",
       " ...}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_leafs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dict = dict((reversed(item) for item in reserved_tokens.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=['id', 'AST'])\n",
    "for index, tree in enumerate(trees):\n",
    "    ast = exporter.export(tree)\n",
    "    df = df.append([{'id': index, 'AST' : ast}], ignore_index=True)\n",
    "    \n",
    "df.to_csv('asts.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 256])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = torch.tensor([np.random.normal(loc=0.0, scale=1.0, size=params['LATENT_DIM']) for i in range(5)], device=device).float()\n",
    "z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_trees = vae.generate(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "TreePlotter.plot_predicted_tree(generated_trees[0], 'generated_tree.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in loader:\n",
    "    for key in batch.keys():\n",
    "        if key != 'tree_sizes':\n",
    "            batch[key] = batch[key].to(device)\n",
    "            \n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "    z, _, _ = encoder(batch)\n",
    "    trees = decoder(z)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_to_label = dict((reversed(item) for item in label_to_idx.items()))\n",
    "idx_to_res_label = dict((reversed(item) for item in res_label_to_idx.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('tokens.json', 'w') as f:\n",
    "    f.write(json.dumps(label_to_idx))\n",
    "    \n",
    "with open('reserved_tokens.json', 'w') as f:\n",
    "    f.write(json.dumps(res_label_to_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "trees = pd.read_csv('../data/ast_trees/asts.csv.bz2')\n",
    "tree = trees.iloc[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from anytree.importer import JsonImporter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "import_() takes 2 positional arguments but 3 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-402a5c5fd9f6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mJsonImporter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'first_tree.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: import_() takes 2 positional arguments but 3 were given"
     ]
    }
   ],
   "source": [
    "JsonImporter().import_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "TreePlotter.plot_tree(trees[0], 'first_tree.png', idx_to_label, idx_to_label['RES'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'res'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-c471642a40da>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mTreePlotter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'actual_tree_tree.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# TreePlotter.plot_tree(tree, 'actual_tree.png', label_dict)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/9C9AB7DB9AB7B05E/Linux/documents/Thesis-Autoencoders_as_Tools_for_Program_Synthesis/autoencoder_program_synthesis/utils/TreePlotter.py\u001b[0m in \u001b[0;36mplot_tree\u001b[0;34m(root, file_path, label_dict, res_label_dict, binary)\u001b[0m\n\u001b[1;32m     26\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;34mf'label={node.token}'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         UniqueDotExporter(root,\n\u001b[0m\u001b[1;32m     29\u001b[0m                          \u001b[0mnodeattrfunc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mget_label\u001b[0m \u001b[0;31m#lambda n: f'label=\"{get_label(n)}\" shape={\"ellipse\" if n.res else \"box\"}'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m                          ).to_picture(file_path)\n",
      "\u001b[0;32m/mnt/9C9AB7DB9AB7B05E/Linux/documents/Thesis-Autoencoders_as_Tools_for_Program_Synthesis/autoencoder_program_synthesis/venv/lib/python3.8/site-packages/anytree/exporter/dotexporter.py\u001b[0m in \u001b[0;36mto_picture\u001b[0;34m(self, filename)\u001b[0m\n\u001b[1;32m    266\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mNamedTemporaryFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelete\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdotfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m             \u001b[0mdotfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdotfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m                 \u001b[0mdotfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s\\n\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m             \u001b[0mdotfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/9C9AB7DB9AB7B05E/Linux/documents/Thesis-Autoencoders_as_Tools_for_Program_Synthesis/autoencoder_program_synthesis/venv/lib/python3.8/site-packages/anytree/exporter/dotexporter.py\u001b[0m in \u001b[0;36m__iter\u001b[0;34m(self, indent, nodenamefunc, nodeattrfunc, edgeattrfunc, edgetypefunc)\u001b[0m\n\u001b[1;32m    197\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0moption\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__iter_options\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0moption\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mnode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__iter_nodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnodenamefunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnodeattrfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0medge\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__iter_edges\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnodenamefunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medgeattrfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medgetypefunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/9C9AB7DB9AB7B05E/Linux/documents/Thesis-Autoencoders_as_Tools_for_Program_Synthesis/autoencoder_program_synthesis/venv/lib/python3.8/site-packages/anytree/exporter/dotexporter.py\u001b[0m in \u001b[0;36m__iter_nodes\u001b[0;34m(self, indent, nodenamefunc, nodeattrfunc)\u001b[0m\n\u001b[1;32m    212\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mnode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mPreOrderIter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaxlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m             \u001b[0mnodename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnodenamefunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m             \u001b[0mnodeattr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnodeattrfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m             \u001b[0mnodeattr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\" [%s]\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mnodeattr\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnodeattr\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0;34m'%s\"%s\"%s;'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mindent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDotExporter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mesc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnodename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnodeattr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/9C9AB7DB9AB7B05E/Linux/documents/Thesis-Autoencoders_as_Tools_for_Program_Synthesis/autoencoder_program_synthesis/utils/TreePlotter.py\u001b[0m in \u001b[0;36mget_label\u001b[0;34m(node)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mget_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mres\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mres_label_dict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;31m#                 print(f'label={res_label_dict[node.token]}')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m#                 print(re.findall(r'^[a-zA-Z0-9=_]*', f'label={res_label_dict[node.token]}')[0].replace(\"_\", \"x\"))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'res'"
     ]
    }
   ],
   "source": [
    "TreePlotter.plot_tree(tree, 'actual_tree_tree.png')\n",
    "# TreePlotter.plot_tree(tree, 'actual_tree.png', label_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from anytree.exporter import JsonExporter\n",
    "exporter = JsonExporter()\n",
    "with open('test.json', 'w') as f:\n",
    "    f.write(exporter.export(trees[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder.eval()\n",
    "trees = decoder(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1728x432 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "figure, ax = plt.subplots(1, 3, figsize=(24,6))\n",
    "figure.add_subplot(111, frameon=False)\n",
    "\n",
    "ax[0].plot(losses['label_prediction_loss'], label='label pred loss')\n",
    "ax[0].plot(losses['parent_loss'], label='parent pred loss')\n",
    "ax[0].plot(losses['sibling_loss'], label='sibling pred loss')\n",
    "ax[0].plot(losses['kl_loss'][20:], label='KL loss')\n",
    "ax[0].legend()\n",
    "\n",
    "ax[1].plot(np.add(np.add(losses['label_prediction_loss'], losses['parent_loss']), losses['sibling_loss']), label='reconstruction_loss')\n",
    "ax[1].plot(losses['kl_loss'], label='KL loss')\n",
    "ax[1].legend()\n",
    "\n",
    "ax[2].plot(losses['total_loss'], label='total_loss')\n",
    "ax[2].legend()\n",
    "\n",
    "plt.tick_params(labelcolor='none', top=False, bottom=False, left=False, right=False)\n",
    "plt.grid(False)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "parents = list(set([el.item() for el in batch['adjacency_list'][:169][:, 0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_tree(adj_list, features, index=0, parent_node=None):\n",
    "    node = Node(features[index].item(), parent=parent_node)\n",
    "    children = adj_list[adj_list[:, 0] == index][:, 1]\n",
    "\n",
    "    for child in children:\n",
    "        build_tree(adj_list, features, child, node)\n",
    "\n",
    "    return node\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = build_tree(batch['adjacency_list'], batch['features'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_tree = build_tree(batch['adjacency_list'], torch.argmax(output['predicted_labels'], dim=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "TreePlotter.plot_predicted_tree(pred_tree, 'predicted_tree.png')\n",
    "TreePlotter.plot_predicted_tree(tree, 'actual_tree.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.0\n",
      "2 2.0\n",
      "3 3.0\n",
      "4 4.0\n",
      "5 5.0\n",
      "6 25.0\n",
      "5 5.0\n",
      "30 30.0\n",
      "18 18.0\n",
      "43 43.0\n",
      "2 2.0\n",
      "3 3.0\n",
      "4 4.0\n",
      "5 5.0\n",
      "6 34.0\n",
      "43 43.0\n",
      "6 6.0\n",
      "2 2.0\n",
      "3 3.0\n",
      "4 4.0\n",
      "5 5.0\n",
      "6 43.0\n",
      "2 2.0\n",
      "3 3.0\n",
      "4 4.0\n",
      "5 5.0\n",
      "6 6.0\n",
      "2 2.0\n",
      "3 3.0\n",
      "4 4.0\n",
      "5 5.0\n",
      "6 17.0\n",
      "2 15.0\n",
      "5 5.0\n",
      "16 16.0\n",
      "11 11.0\n",
      "19 19.0\n",
      "2 2.0\n",
      "3 3.0\n",
      "4 4.0\n",
      "5 5.0\n",
      "2 2.0\n",
      "3 3.0\n",
      "4 4.0\n",
      "5 5.0\n",
      "19 50.0\n",
      "53 24.0\n",
      "17 24.0\n",
      "17 17.0\n",
      "17 17.0\n",
      "17 17.0\n",
      "11 11.0\n"
     ]
    }
   ],
   "source": [
    "for index, (pred, true) in enumerate(zip(torch.argmax(output['predicted_labels'], dim=-1), output['labels'])):\n",
    "    print(pred.item(), true.item())\n",
    "    if index > 50:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9997850060462952 1.0\n",
      "0.9993454813957214 1.0\n",
      "0.0005445647984743118 0.0\n",
      "0.9997802376747131 1.0\n",
      "0.0003903243341483176 0.0\n",
      "0.32433581352233887 1.0\n",
      "0.0016980406362563372 0.0\n",
      "0.8883258104324341 1.0\n",
      "0.8576392531394958 1.0\n",
      "0.014596741646528244 0.0\n",
      "0.9996651411056519 1.0\n",
      "0.0005445647984743118 0.0\n",
      "0.9997802376747131 1.0\n",
      "0.0003903243341483176 0.0\n",
      "0.32433581352233887 1.0\n",
      "0.1037544310092926 0.0\n",
      "0.0025435499846935272 0.0\n",
      "0.9996651411056519 1.0\n",
      "0.0005445647984743118 0.0\n",
      "0.9997802376747131 1.0\n",
      "0.0003903243341483176 0.0\n",
      "0.32433581352233887 0.0\n",
      "0.9996651411056519 1.0\n",
      "0.0005445647984743118 0.0\n",
      "0.9997802376747131 1.0\n",
      "0.0003903243341483176 0.0\n",
      "0.32433581352233887 0.0\n",
      "0.9996651411056519 1.0\n",
      "0.0005445647984743118 0.0\n",
      "0.9997802376747131 1.0\n",
      "0.0003903243341483176 0.0\n",
      "0.32433581352233887 0.0\n",
      "0.9996651411056519 1.0\n",
      "0.04661606252193451 0.0\n",
      "0.0007113214815035462 0.0\n",
      "0.9885280132293701 1.0\n",
      "0.9675545692443848 1.0\n",
      "0.9997628331184387 1.0\n",
      "0.00014878938964102417 0.0\n",
      "0.9999227523803711 1.0\n",
      "0.00018493508105166256 0.0\n",
      "0.9999232292175293 1.0\n",
      "0.00014878938964102417 0.0\n",
      "0.9999227523803711 1.0\n",
      "0.00018493508105166256 0.0\n",
      "0.9920046925544739 1.0\n",
      "0.8633161187171936 1.0\n",
      "0.18772585690021515 1.0\n",
      "0.10755079239606857 0.0\n",
      "0.0017551489872857928 0.0\n",
      "0.011635581962764263 0.0\n",
      "0.9982078075408936 1.0\n"
     ]
    }
   ],
   "source": [
    "for index, (pred, true) in enumerate(zip(output['predicted_is_parent'], output['is_parent'])):\n",
    "    print(pred.item(), true.item())\n",
    "    if index > 50:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    0,     1],\n",
       "        [    1,     2],\n",
       "        [    1,     3],\n",
       "        ...,\n",
       "        [16335, 16338],\n",
       "        [16338, 16339],\n",
       "        [16339, 16340]], device='cuda:0')"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['adjacency_list']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.],\n",
       "        [69.],\n",
       "        [70.],\n",
       "        ...,\n",
       "        [11.],\n",
       "        [25.],\n",
       "        [ 5.]], device='cuda:0')"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['features']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  0,   1,   1,   0,   4,   4,   4,   7,   7,   9,   4,  11,  11,  13,\n",
       "          4,  15,  16,  17,  18,  18,  20,  21,  21,  23,  24,  24,  26,  26,\n",
       "         20,   0,  30,  30,  32,  32,  34,  34,   0,  37,  37,  37,  40,  40,\n",
       "         42,  37,  44,  44,  46,  37,  48,  49,  50,  50,  49,  53,  54,  48,\n",
       "         56,   0,  58,  58,  58,  61,  62,  63,  63,  65,  61,  67,  67,  61,\n",
       "         70,  71,  71,  73,  70,  75,  75,  77,  61,  79,  80,  80,  79,  61,\n",
       "         84,  85,  85,  87,  84,  89,  89,  91,  61,  93,  94,  94,  93,  61,\n",
       "         98,  99,  99, 101,  98, 103, 103, 105,  61, 107, 108, 108, 107,  61,\n",
       "        112, 113, 113, 115, 115, 117, 118, 119, 120, 120, 122, 122, 119, 125,\n",
       "        125, 127, 127, 118, 130, 131, 131, 133, 133, 130, 136, 136, 138, 138,\n",
       "         61,  61, 142, 143, 143, 143,   0, 147, 147, 147, 150, 151, 151, 153,\n",
       "        151, 150, 156, 157, 157, 159, 159, 150, 162, 163, 162, 165, 166, 165,\n",
       "        165], device='cuda:0')"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['adjacency_list'][:169][:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.],\n",
       "        [69.],\n",
       "        [70.],\n",
       "        [70.],\n",
       "        [71.],\n",
       "        [ 5.],\n",
       "        [16.],\n",
       "        [26.],\n",
       "        [ 3.],\n",
       "        [ 4.],\n",
       "        [ 5.],\n",
       "        [26.],\n",
       "        [ 3.],\n",
       "        [ 4.],\n",
       "        [ 5.],\n",
       "        [11.],\n",
       "        [23.],\n",
       "        [57.],\n",
       "        [25.],\n",
       "        [ 5.],\n",
       "        [30.],\n",
       "        [25.],\n",
       "        [ 5.],\n",
       "        [30.],\n",
       "        [25.],\n",
       "        [ 5.],\n",
       "        [30.],\n",
       "        [17.],\n",
       "        [17.],\n",
       "        [43.],\n",
       "        [ 2.],\n",
       "        [ 3.],\n",
       "        [ 4.],\n",
       "        [ 5.],\n",
       "        [34.],\n",
       "        [43.],\n",
       "        [ 6.],\n",
       "        [15.],\n",
       "        [ 5.],\n",
       "        [16.],\n",
       "        [26.],\n",
       "        [ 3.],\n",
       "        [ 4.],\n",
       "        [ 5.],\n",
       "        [26.],\n",
       "        [ 3.],\n",
       "        [ 4.],\n",
       "        [ 5.],\n",
       "        [11.],\n",
       "        [27.],\n",
       "        [55.],\n",
       "        [17.],\n",
       "        [17.],\n",
       "        [11.],\n",
       "        [23.],\n",
       "        [ 6.],\n",
       "        [23.],\n",
       "        [ 6.],\n",
       "        [15.],\n",
       "        [ 5.],\n",
       "        [16.],\n",
       "        [11.],\n",
       "        [19.],\n",
       "        [ 2.],\n",
       "        [ 3.],\n",
       "        [ 4.],\n",
       "        [ 5.],\n",
       "        [24.],\n",
       "        [17.],\n",
       "        [17.],\n",
       "        [19.],\n",
       "        [ 2.],\n",
       "        [ 3.],\n",
       "        [ 4.],\n",
       "        [ 5.],\n",
       "        [ 2.],\n",
       "        [ 3.],\n",
       "        [ 4.],\n",
       "        [ 5.],\n",
       "        [24.],\n",
       "        [24.],\n",
       "        [17.],\n",
       "        [17.],\n",
       "        [17.],\n",
       "        [19.],\n",
       "        [ 2.],\n",
       "        [ 3.],\n",
       "        [ 4.],\n",
       "        [ 5.],\n",
       "        [ 2.],\n",
       "        [ 3.],\n",
       "        [ 4.],\n",
       "        [ 5.],\n",
       "        [24.],\n",
       "        [24.],\n",
       "        [17.],\n",
       "        [17.],\n",
       "        [17.],\n",
       "        [19.],\n",
       "        [ 2.],\n",
       "        [ 3.],\n",
       "        [ 4.],\n",
       "        [ 5.],\n",
       "        [ 2.],\n",
       "        [ 3.],\n",
       "        [ 4.],\n",
       "        [ 5.],\n",
       "        [24.],\n",
       "        [24.],\n",
       "        [17.],\n",
       "        [17.],\n",
       "        [17.],\n",
       "        [19.],\n",
       "        [ 2.],\n",
       "        [ 3.],\n",
       "        [ 4.],\n",
       "        [ 5.],\n",
       "        [57.],\n",
       "        [28.],\n",
       "        [49.],\n",
       "        [25.],\n",
       "        [ 5.],\n",
       "        [30.],\n",
       "        [17.],\n",
       "        [17.],\n",
       "        [25.],\n",
       "        [ 5.],\n",
       "        [30.],\n",
       "        [17.],\n",
       "        [17.],\n",
       "        [49.],\n",
       "        [25.],\n",
       "        [ 5.],\n",
       "        [30.],\n",
       "        [17.],\n",
       "        [17.],\n",
       "        [25.],\n",
       "        [ 5.],\n",
       "        [30.],\n",
       "        [17.],\n",
       "        [17.],\n",
       "        [17.],\n",
       "        [57.],\n",
       "        [68.],\n",
       "        [17.],\n",
       "        [31.],\n",
       "        [31.],\n",
       "        [15.],\n",
       "        [ 5.],\n",
       "        [16.],\n",
       "        [11.],\n",
       "        [25.],\n",
       "        [ 5.],\n",
       "        [30.],\n",
       "        [51.],\n",
       "        [33.],\n",
       "        [19.],\n",
       "        [ 2.],\n",
       "        [ 3.],\n",
       "        [ 4.],\n",
       "        [ 5.],\n",
       "        [ 6.],\n",
       "        [50.],\n",
       "        [53.],\n",
       "        [17.],\n",
       "        [11.],\n",
       "        [25.],\n",
       "        [ 5.],\n",
       "        [17.],\n",
       "        [31.]], device='cuda:0')"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['features'][:170]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0., device='cuda:0') tensor([0.], device='cuda:0')\n",
      "tensor(69., device='cuda:0') tensor([69.], device='cuda:0')\n",
      "tensor(70., device='cuda:0') tensor([70.], device='cuda:0')\n",
      "tensor(70., device='cuda:0') tensor([70.], device='cuda:0')\n",
      "tensor(71., device='cuda:0') tensor([71.], device='cuda:0')\n",
      "tensor(5., device='cuda:0') tensor([5.], device='cuda:0')\n",
      "tensor(16., device='cuda:0') tensor([16.], device='cuda:0')\n",
      "tensor(26., device='cuda:0') tensor([26.], device='cuda:0')\n",
      "tensor(3., device='cuda:0') tensor([3.], device='cuda:0')\n",
      "tensor(4., device='cuda:0') tensor([4.], device='cuda:0')\n",
      "tensor(5., device='cuda:0') tensor([5.], device='cuda:0')\n",
      "tensor(26., device='cuda:0') tensor([26.], device='cuda:0')\n",
      "tensor(3., device='cuda:0') tensor([3.], device='cuda:0')\n",
      "tensor(4., device='cuda:0') tensor([4.], device='cuda:0')\n",
      "tensor(5., device='cuda:0') tensor([5.], device='cuda:0')\n",
      "tensor(11., device='cuda:0') tensor([11.], device='cuda:0')\n",
      "tensor(23., device='cuda:0') tensor([23.], device='cuda:0')\n",
      "tensor(57., device='cuda:0') tensor([57.], device='cuda:0')\n",
      "tensor(25., device='cuda:0') tensor([25.], device='cuda:0')\n",
      "tensor(5., device='cuda:0') tensor([5.], device='cuda:0')\n",
      "tensor(30., device='cuda:0') tensor([30.], device='cuda:0')\n",
      "tensor(25., device='cuda:0') tensor([25.], device='cuda:0')\n",
      "tensor(5., device='cuda:0') tensor([5.], device='cuda:0')\n",
      "tensor(30., device='cuda:0') tensor([30.], device='cuda:0')\n",
      "tensor(25., device='cuda:0') tensor([25.], device='cuda:0')\n",
      "tensor(5., device='cuda:0') tensor([5.], device='cuda:0')\n",
      "tensor(30., device='cuda:0') tensor([30.], device='cuda:0')\n",
      "tensor(17., device='cuda:0') tensor([17.], device='cuda:0')\n",
      "tensor(17., device='cuda:0') tensor([17.], device='cuda:0')\n",
      "tensor(43., device='cuda:0') tensor([43.], device='cuda:0')\n",
      "tensor(2., device='cuda:0') tensor([2.], device='cuda:0')\n",
      "tensor(3., device='cuda:0') tensor([3.], device='cuda:0')\n",
      "tensor(4., device='cuda:0') tensor([4.], device='cuda:0')\n",
      "tensor(5., device='cuda:0') tensor([5.], device='cuda:0')\n",
      "tensor(34., device='cuda:0') tensor([34.], device='cuda:0')\n",
      "tensor(43., device='cuda:0') tensor([43.], device='cuda:0')\n",
      "tensor(6., device='cuda:0') tensor([6.], device='cuda:0')\n",
      "tensor(15., device='cuda:0') tensor([15.], device='cuda:0')\n",
      "tensor(5., device='cuda:0') tensor([5.], device='cuda:0')\n",
      "tensor(16., device='cuda:0') tensor([16.], device='cuda:0')\n",
      "tensor(26., device='cuda:0') tensor([26.], device='cuda:0')\n",
      "tensor(3., device='cuda:0') tensor([3.], device='cuda:0')\n",
      "tensor(4., device='cuda:0') tensor([4.], device='cuda:0')\n",
      "tensor(5., device='cuda:0') tensor([5.], device='cuda:0')\n",
      "tensor(26., device='cuda:0') tensor([26.], device='cuda:0')\n",
      "tensor(3., device='cuda:0') tensor([3.], device='cuda:0')\n",
      "tensor(4., device='cuda:0') tensor([4.], device='cuda:0')\n",
      "tensor(5., device='cuda:0') tensor([5.], device='cuda:0')\n",
      "tensor(11., device='cuda:0') tensor([11.], device='cuda:0')\n",
      "tensor(27., device='cuda:0') tensor([27.], device='cuda:0')\n",
      "tensor(55., device='cuda:0') tensor([55.], device='cuda:0')\n",
      "tensor(17., device='cuda:0') tensor([17.], device='cuda:0')\n",
      "tensor(17., device='cuda:0') tensor([17.], device='cuda:0')\n",
      "tensor(11., device='cuda:0') tensor([11.], device='cuda:0')\n",
      "tensor(23., device='cuda:0') tensor([23.], device='cuda:0')\n",
      "tensor(6., device='cuda:0') tensor([6.], device='cuda:0')\n",
      "tensor(23., device='cuda:0') tensor([23.], device='cuda:0')\n",
      "tensor(6., device='cuda:0') tensor([6.], device='cuda:0')\n",
      "tensor(15., device='cuda:0') tensor([15.], device='cuda:0')\n",
      "tensor(5., device='cuda:0') tensor([5.], device='cuda:0')\n",
      "tensor(16., device='cuda:0') tensor([16.], device='cuda:0')\n",
      "tensor(11., device='cuda:0') tensor([11.], device='cuda:0')\n",
      "tensor(19., device='cuda:0') tensor([19.], device='cuda:0')\n",
      "tensor(2., device='cuda:0') tensor([2.], device='cuda:0')\n",
      "tensor(3., device='cuda:0') tensor([3.], device='cuda:0')\n",
      "tensor(4., device='cuda:0') tensor([4.], device='cuda:0')\n",
      "tensor(5., device='cuda:0') tensor([5.], device='cuda:0')\n",
      "tensor(24., device='cuda:0') tensor([24.], device='cuda:0')\n",
      "tensor(17., device='cuda:0') tensor([17.], device='cuda:0')\n",
      "tensor(17., device='cuda:0') tensor([17.], device='cuda:0')\n",
      "tensor(19., device='cuda:0') tensor([19.], device='cuda:0')\n",
      "tensor(2., device='cuda:0') tensor([2.], device='cuda:0')\n",
      "tensor(3., device='cuda:0') tensor([3.], device='cuda:0')\n",
      "tensor(4., device='cuda:0') tensor([4.], device='cuda:0')\n",
      "tensor(5., device='cuda:0') tensor([5.], device='cuda:0')\n",
      "tensor(2., device='cuda:0') tensor([2.], device='cuda:0')\n",
      "tensor(3., device='cuda:0') tensor([3.], device='cuda:0')\n",
      "tensor(4., device='cuda:0') tensor([4.], device='cuda:0')\n",
      "tensor(5., device='cuda:0') tensor([5.], device='cuda:0')\n",
      "tensor(24., device='cuda:0') tensor([24.], device='cuda:0')\n",
      "tensor(24., device='cuda:0') tensor([24.], device='cuda:0')\n",
      "tensor(17., device='cuda:0') tensor([17.], device='cuda:0')\n",
      "tensor(17., device='cuda:0') tensor([17.], device='cuda:0')\n",
      "tensor(17., device='cuda:0') tensor([17.], device='cuda:0')\n",
      "tensor(19., device='cuda:0') tensor([19.], device='cuda:0')\n",
      "tensor(2., device='cuda:0') tensor([2.], device='cuda:0')\n",
      "tensor(3., device='cuda:0') tensor([3.], device='cuda:0')\n",
      "tensor(4., device='cuda:0') tensor([4.], device='cuda:0')\n",
      "tensor(5., device='cuda:0') tensor([5.], device='cuda:0')\n",
      "tensor(2., device='cuda:0') tensor([2.], device='cuda:0')\n",
      "tensor(3., device='cuda:0') tensor([3.], device='cuda:0')\n",
      "tensor(4., device='cuda:0') tensor([4.], device='cuda:0')\n",
      "tensor(5., device='cuda:0') tensor([5.], device='cuda:0')\n",
      "tensor(24., device='cuda:0') tensor([24.], device='cuda:0')\n",
      "tensor(24., device='cuda:0') tensor([24.], device='cuda:0')\n",
      "tensor(17., device='cuda:0') tensor([17.], device='cuda:0')\n",
      "tensor(17., device='cuda:0') tensor([17.], device='cuda:0')\n",
      "tensor(17., device='cuda:0') tensor([17.], device='cuda:0')\n",
      "tensor(19., device='cuda:0') tensor([19.], device='cuda:0')\n",
      "tensor(2., device='cuda:0') tensor([2.], device='cuda:0')\n",
      "tensor(3., device='cuda:0') tensor([3.], device='cuda:0')\n",
      "tensor(4., device='cuda:0') tensor([4.], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "for index, (lab, feat) in enumerate(zip(output['labels'], batch['features'])):\n",
    "    print(lab, feat)\n",
    "    if index > 100:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.],\n",
       "        [69.],\n",
       "        [70.],\n",
       "        ...,\n",
       "        [11.],\n",
       "        [25.],\n",
       "        [ 5.]], device='cuda:0')"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['features']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17 0.0\n",
      "15 69.0\n",
      "70 70.0\n",
      "70 70.0\n",
      "71 71.0\n",
      "5 5.0\n",
      "16 16.0\n",
      "26 26.0\n",
      "3 3.0\n",
      "4 4.0\n",
      "5 5.0\n",
      "26 26.0\n",
      "3 3.0\n",
      "4 4.0\n",
      "5 5.0\n",
      "26 11.0\n",
      "19 23.0\n",
      "6 57.0\n",
      "25 25.0\n",
      "5 5.0\n",
      "30 30.0\n",
      "17 25.0\n",
      "5 5.0\n",
      "30 30.0\n",
      "17 25.0\n",
      "5 5.0\n",
      "30 30.0\n",
      "17 17.0\n",
      "17 17.0\n",
      "31 43.0\n",
      "69 2.0\n",
      "3 3.0\n",
      "4 4.0\n",
      "5 5.0\n",
      "6 34.0\n",
      "43 43.0\n",
      "6 6.0\n",
      "2 15.0\n",
      "5 5.0\n",
      "16 16.0\n",
      "11 26.0\n",
      "3 3.0\n",
      "4 4.0\n",
      "5 5.0\n",
      "11 26.0\n",
      "3 3.0\n",
      "4 4.0\n",
      "5 5.0\n",
      "11 11.0\n",
      "19 27.0\n",
      "49 55.0\n",
      "17 17.0\n",
      "6 17.0\n",
      "11 11.0\n",
      "23 23.0\n",
      "6 6.0\n",
      "27 23.0\n",
      "6 6.0\n",
      "15 15.0\n",
      "5 5.0\n",
      "16 16.0\n",
      "11 11.0\n",
      "19 19.0\n",
      "2 2.0\n",
      "3 3.0\n",
      "4 4.0\n",
      "5 5.0\n",
      "24 24.0\n",
      "17 17.0\n",
      "17 17.0\n",
      "50 19.0\n",
      "2 2.0\n",
      "3 3.0\n",
      "4 4.0\n",
      "5 5.0\n",
      "2 2.0\n",
      "3 3.0\n",
      "4 4.0\n",
      "5 5.0\n",
      "24 24.0\n",
      "17 24.0\n",
      "24 17.0\n",
      "17 17.0\n",
      "17 17.0\n",
      "50 19.0\n",
      "2 2.0\n",
      "3 3.0\n",
      "4 4.0\n",
      "5 5.0\n",
      "2 2.0\n",
      "3 3.0\n",
      "4 4.0\n",
      "5 5.0\n",
      "24 24.0\n",
      "17 24.0\n",
      "24 17.0\n",
      "17 17.0\n",
      "17 17.0\n",
      "50 19.0\n",
      "2 2.0\n",
      "3 3.0\n",
      "4 4.0\n",
      "5 5.0\n",
      "2 2.0\n",
      "3 3.0\n",
      "4 4.0\n",
      "5 5.0\n",
      "24 24.0\n",
      "17 24.0\n",
      "24 17.0\n",
      "17 17.0\n",
      "17 17.0\n",
      "50 19.0\n",
      "2 2.0\n",
      "3 3.0\n",
      "4 4.0\n",
      "5 5.0\n",
      "6 57.0\n",
      "6 28.0\n",
      "28 49.0\n",
      "17 25.0\n",
      "5 5.0\n",
      "30 30.0\n",
      "17 17.0\n",
      "17 17.0\n",
      "6 25.0\n",
      "5 5.0\n",
      "30 30.0\n",
      "17 17.0\n",
      "17 17.0\n",
      "11 49.0\n",
      "17 25.0\n",
      "5 5.0\n",
      "30 30.0\n",
      "17 17.0\n",
      "17 17.0\n",
      "6 25.0\n",
      "5 5.0\n",
      "30 30.0\n",
      "17 17.0\n",
      "17 17.0\n",
      "24 17.0\n",
      "17 57.0\n",
      "25 68.0\n",
      "17 17.0\n",
      "17 31.0\n",
      "17 31.0\n",
      "15 15.0\n",
      "5 5.0\n",
      "16 16.0\n",
      "11 11.0\n",
      "19 25.0\n",
      "5 5.0\n",
      "30 30.0\n",
      "31 51.0\n",
      "33 33.0\n",
      "19 19.0\n",
      "2 2.0\n",
      "3 3.0\n",
      "4 4.0\n",
      "5 5.0\n",
      "6 6.0\n",
      "24 50.0\n",
      "53 53.0\n",
      "17 17.0\n",
      "11 11.0\n",
      "19 25.0\n",
      "5 5.0\n",
      "19 17.0\n",
      "19 31.0\n",
      "0 0.0\n",
      "15 15.0\n",
      "5 5.0\n",
      "16 16.0\n",
      "11 11.0\n",
      "19 25.0\n",
      "5 5.0\n",
      "30 30.0\n",
      "31 6.0\n",
      "33 33.0\n",
      "19 19.0\n",
      "2 2.0\n",
      "3 3.0\n",
      "4 4.0\n",
      "5 5.0\n",
      "2 2.0\n",
      "3 3.0\n",
      "4 4.0\n",
      "5 5.0\n",
      "2 2.0\n",
      "3 3.0\n",
      "4 4.0\n",
      "5 5.0\n",
      "2 2.0\n",
      "3 3.0\n",
      "4 4.0\n",
      "5 5.0\n",
      "2 2.0\n",
      "3 3.0\n",
      "4 4.0\n",
      "5 5.0\n",
      "2 2.0\n",
      "3 3.0\n",
      "4 4.0\n",
      "5 5.0\n",
      "2 2.0\n",
      "3 3.0\n",
      "4 4.0\n",
      "5 5.0\n",
      "24 24.0\n",
      "17 24.0\n",
      "24 24.0\n",
      "24 24.0\n",
      "24 24.0\n",
      "24 24.0\n",
      "17 24.0\n",
      "17 17.0\n",
      "17 17.0\n",
      "17 17.0\n",
      "17 17.0\n",
      "17 17.0\n",
      "17 17.0\n",
      "17 17.0\n",
      "17 17.0\n",
      "35 19.0\n",
      "2 2.0\n",
      "3 3.0\n",
      "4 4.0\n",
      "5 5.0\n",
      "24 27.0\n",
      "49 65.0\n",
      "49 65.0\n",
      "28 49.0\n",
      "17 58.0\n",
      "17 17.0\n",
      "17 17.0\n",
      "6 58.0\n",
      "17 17.0\n",
      "17 17.0\n",
      "55 49.0\n",
      "17 17.0\n",
      "6 17.0\n",
      "49 49.0\n",
      "17 17.0\n",
      "6 17.0\n",
      "11 11.0\n",
      "23 17.0\n",
      "31 31.0\n",
      "11 27.0\n",
      "49 28.0\n",
      "49 28.0\n",
      "28 28.0\n",
      "28 36.0\n",
      "17 17.0\n",
      "17 17.0\n",
      "55 36.0\n",
      "17 17.0\n",
      "17 17.0\n",
      "55 36.0\n",
      "17 17.0\n",
      "17 17.0\n",
      "55 36.0\n",
      "17 17.0\n",
      "17 17.0\n",
      "11 11.0\n",
      "23 17.0\n",
      "31 31.0\n",
      "11 27.0\n",
      "49 28.0\n",
      "28 28.0\n",
      "28 28.0\n",
      "28 55.0\n",
      "17 17.0\n",
      "17 17.0\n",
      "55 55.0\n",
      "17 17.0\n",
      "17 17.0\n",
      "55 36.0\n",
      "17 17.0\n",
      "17 17.0\n",
      "55 36.0\n",
      "17 17.0\n",
      "17 17.0\n",
      "11 11.0\n",
      "25 17.0\n",
      "31 31.0\n",
      "11 27.0\n",
      "49 28.0\n",
      "28 28.0\n",
      "28 28.0\n",
      "28 36.0\n",
      "17 17.0\n",
      "17 17.0\n",
      "55 36.0\n",
      "17 17.0\n",
      "17 17.0\n",
      "55 55.0\n",
      "17 17.0\n",
      "17 17.0\n",
      "55 55.0\n",
      "17 17.0\n",
      "17 17.0\n",
      "11 11.0\n",
      "25 17.0\n",
      "31 31.0\n",
      "11 27.0\n",
      "49 28.0\n",
      "28 28.0\n",
      "28 28.0\n",
      "28 55.0\n",
      "17 17.0\n",
      "17 17.0\n",
      "55 55.0\n",
      "17 17.0\n",
      "17 17.0\n",
      "55 55.0\n",
      "17 17.0\n",
      "17 17.0\n",
      "55 55.0\n",
      "17 17.0\n",
      "17 17.0\n",
      "11 11.0\n",
      "25 17.0\n",
      "31 31.0\n",
      "11 11.0\n",
      "25 17.0\n",
      "31 31.0\n",
      "27 22.0\n",
      "17 17.0\n",
      "17 17.0\n",
      "23 23.0\n",
      "6 6.0\n",
      "49 0.0\n",
      "15 7.0\n",
      "8 8.0\n",
      "9 9.0\n",
      "7 7.0\n",
      "8 8.0\n",
      "9 9.0\n",
      "7 15.0\n",
      "5 5.0\n",
      "16 16.0\n",
      "11 26.0\n",
      "3 3.0\n",
      "4 4.0\n",
      "5 5.0\n",
      "11 11.0\n",
      "19 22.0\n",
      "17 17.0\n",
      "17 17.0\n",
      "15 15.0\n",
      "5 5.0\n",
      "16 16.0\n",
      "11 26.0\n",
      "3 3.0\n",
      "4 4.0\n",
      "5 5.0\n",
      "11 11.0\n",
      "19 17.0\n",
      "17 17.0\n",
      "15 15.0\n",
      "5 5.0\n",
      "16 16.0\n",
      "11 26.0\n",
      "3 3.0\n",
      "4 4.0\n",
      "5 5.0\n",
      "11 11.0\n",
      "19 17.0\n",
      "17 17.0\n",
      "15 15.0\n",
      "5 5.0\n",
      "16 16.0\n",
      "11 26.0\n",
      "3 3.0\n",
      "4 4.0\n",
      "5 5.0\n",
      "11 11.0\n",
      "19 22.0\n",
      "17 22.0\n",
      "17 22.0\n",
      "17 17.0\n",
      "17 39.0\n",
      "39 17.0\n",
      "39 39.0\n",
      "15 15.0\n",
      "5 5.0\n",
      "16 16.0\n",
      "11 26.0\n",
      "3 3.0\n",
      "4 4.0\n",
      "5 5.0\n",
      "11 11.0\n",
      "19 25.0\n",
      "5 5.0\n",
      "30 30.0\n",
      "31 22.0\n",
      "17 17.0\n",
      "17 39.0\n",
      "31 17.0\n",
      "31 39.0\n",
      "15 15.0\n",
      "5 5.0\n",
      "16 16.0\n",
      "11 26.0\n",
      "3 3.0\n",
      "4 4.0\n",
      "5 5.0\n",
      "11 11.0\n",
      "19 22.0\n",
      "17 22.0\n",
      "17 22.0\n",
      "17 17.0\n",
      "17 39.0\n",
      "39 17.0\n",
      "39 39.0\n",
      "15 15.0\n",
      "5 5.0\n",
      "16 16.0\n",
      "11 26.0\n",
      "3 3.0\n",
      "4 4.0\n",
      "5 5.0\n",
      "11 11.0\n",
      "19 17.0\n",
      "17 57.0\n",
      "25 68.0\n",
      "17 17.0\n",
      "17 31.0\n",
      "17 31.0\n",
      "15 69.0\n",
      "70 70.0\n",
      "70 70.0\n",
      "71 71.0\n",
      "5 5.0\n",
      "16 16.0\n",
      "26 26.0\n",
      "3 3.0\n",
      "4 4.0\n",
      "5 5.0\n",
      "11 11.0\n",
      "23 22.0\n",
      "17 17.0\n",
      "17 39.0\n",
      "31 25.0\n",
      "5 5.0\n",
      "30 30.0\n",
      "31 17.0\n",
      "23 22.0\n",
      "17 17.0\n",
      "17 39.0\n",
      "31 25.0\n",
      "5 5.0\n",
      "30 30.0\n",
      "31 17.0\n",
      "23 22.0\n",
      "17 17.0\n",
      "17 39.0\n",
      "15 69.0\n",
      "70 70.0\n",
      "71 71.0\n",
      "5 5.0\n",
      "16 16.0\n",
      "26 26.0\n",
      "3 3.0\n",
      "4 4.0\n",
      "5 5.0\n",
      "11 11.0\n",
      "23 19.0\n",
      "2 2.0\n",
      "3 3.0\n",
      "4 4.0\n",
      "5 5.0\n",
      "6 6.0\n",
      "24 22.0\n",
      "17 17.0\n",
      "17 39.0\n",
      "31 90.0\n",
      "25 2.0\n",
      "3 3.0\n",
      "4 4.0\n",
      "5 5.0\n",
      "11 17.0\n",
      "11 11.0\n",
      "25 54.0\n",
      "25 17.0\n",
      "17 57.0\n",
      "25 68.0\n",
      "25 37.0\n",
      "17 17.0\n",
      "11 31.0\n",
      "17 31.0\n",
      "25 25.0\n",
      "5 5.0\n",
      "30 30.0\n",
      "17 17.0\n",
      "23 17.0\n",
      "31 31.0\n",
      "15 15.0\n",
      "5 5.0\n",
      "16 16.0\n",
      "11 11.0\n"
     ]
    }
   ],
   "source": [
    "for index, (pred, true) in enumerate(zip(torch.argmax(output['predicted_labels'], dim=-1), output['labels'])):\n",
    "    print(pred.item(), true.item())\n",
    "    \n",
    "    if index > 500:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.,  2.,  3.,  ..., 17., 23.,  6.], device='cuda:0')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in loader:\n",
    "    break\n",
    "\n",
    "z, _, _ = encoder(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'total_loss': [tensor(161.2562, device='cuda:0', grad_fn=<AddBackward0>),\n",
       "  tensor(79.3005, device='cuda:0', grad_fn=<AddBackward0>),\n",
       "  tensor(47.3698, device='cuda:0', grad_fn=<AddBackward0>),\n",
       "  tensor(40.6093, device='cuda:0', grad_fn=<AddBackward0>),\n",
       "  tensor(26.8318, device='cuda:0', grad_fn=<AddBackward0>),\n",
       "  tensor(25.8960, device='cuda:0', grad_fn=<AddBackward0>),\n",
       "  tensor(20.6566, device='cuda:0', grad_fn=<AddBackward0>),\n",
       "  tensor(17.4204, device='cuda:0', grad_fn=<AddBackward0>),\n",
       "  tensor(17.9077, device='cuda:0', grad_fn=<AddBackward0>),\n",
       "  tensor(15.7321, device='cuda:0', grad_fn=<AddBackward0>)],\n",
       " 'label_prediction_loss': [tensor(4.9460, device='cuda:0', grad_fn=<NllLossBackward>),\n",
       "  tensor(4.9242, device='cuda:0', grad_fn=<NllLossBackward>),\n",
       "  tensor(4.9006, device='cuda:0', grad_fn=<NllLossBackward>),\n",
       "  tensor(4.8806, device='cuda:0', grad_fn=<NllLossBackward>),\n",
       "  tensor(4.8529, device='cuda:0', grad_fn=<NllLossBackward>),\n",
       "  tensor(4.8278, device='cuda:0', grad_fn=<NllLossBackward>),\n",
       "  tensor(4.7961, device='cuda:0', grad_fn=<NllLossBackward>),\n",
       "  tensor(4.7621, device='cuda:0', grad_fn=<NllLossBackward>),\n",
       "  tensor(4.7299, device='cuda:0', grad_fn=<NllLossBackward>),\n",
       "  tensor(4.6919, device='cuda:0', grad_fn=<NllLossBackward>)],\n",
       " 'parent_loss': [tensor(0.6942, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>),\n",
       "  tensor(0.6909, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>),\n",
       "  tensor(0.6878, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>),\n",
       "  tensor(0.6852, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>),\n",
       "  tensor(0.6834, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>),\n",
       "  tensor(0.6809, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>),\n",
       "  tensor(0.6786, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>),\n",
       "  tensor(0.6760, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>),\n",
       "  tensor(0.6725, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>),\n",
       "  tensor(0.6706, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)],\n",
       " 'sibling_loss': [tensor(0.6865, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>),\n",
       "  tensor(0.6852, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>),\n",
       "  tensor(0.6837, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>),\n",
       "  tensor(0.6833, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>),\n",
       "  tensor(0.6824, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>),\n",
       "  tensor(0.6804, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>),\n",
       "  tensor(0.6784, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>),\n",
       "  tensor(0.6767, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>),\n",
       "  tensor(0.6763, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>),\n",
       "  tensor(0.6758, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)],\n",
       " 'kl_loss': [tensor(154.9296, device='cuda:0', grad_fn=<MulBackward0>),\n",
       "  tensor(73.0002, device='cuda:0', grad_fn=<MulBackward0>),\n",
       "  tensor(41.0978, device='cuda:0', grad_fn=<MulBackward0>),\n",
       "  tensor(34.3601, device='cuda:0', grad_fn=<MulBackward0>),\n",
       "  tensor(20.6131, device='cuda:0', grad_fn=<MulBackward0>),\n",
       "  tensor(19.7069, device='cuda:0', grad_fn=<MulBackward0>),\n",
       "  tensor(14.5036, device='cuda:0', grad_fn=<MulBackward0>),\n",
       "  tensor(11.3057, device='cuda:0', grad_fn=<MulBackward0>),\n",
       "  tensor(11.8290, device='cuda:0', grad_fn=<MulBackward0>),\n",
       "  tensor(9.6939, device='cuda:0', grad_fn=<MulBackward0>)]}"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for batch in tqdm(loader, position=0):\n",
    "    if batch['tree_sizes'][0] < 30:\n",
    "        data = batch\n",
    "        break\n",
    "        \n",
    "for key in data.keys():\n",
    "        if key != 'tree_sizes':\n",
    "            data[key] = data[key].to(device)\n",
    "\n",
    "encoder.train()\n",
    "decoder.train()\n",
    "\n",
    "encoder_optimizer = optim.Adam(encoder.parameters(), lr=0.001)\n",
    "decoder_optimizer = optim.Adam(decoder.parameters(), lr=0.001)\n",
    "vae_loss = VaeLoss()\n",
    "\n",
    "pbar = tqdm(unit='batch', position=0)\n",
    "for i in range(1000):\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "            \n",
    "    z, z_mean, z_log_var = encoder(data)\n",
    "    reconstructed_tree, output = decoder(z, data)\n",
    "    \n",
    "    loss = vae_loss(output, z_mean, z_log_var, len(reserved_tokens))\n",
    "    loss.backward()    \n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "    pbar.set_postfix(loss=round(loss.item(), 3))\n",
    "    pbar.update()\n",
    "#     tree = retrieve_tree(batch['features'], batch['adjacency_list'], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TreePlotter.plot_predicted_tree(reconstructed_tree[0], 'predicted_tree.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0x81 in position 10: invalid start byte",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-369bfc626eca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mreader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../data/ast_trees/asts.csv.bz2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mTreePlotter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mJsonImporter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'first_tree.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/codecs.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, input, final)\u001b[0m\n\u001b[1;32m    320\u001b[0m         \u001b[0;31m# decode input (taking the buffer into account)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 322\u001b[0;31m         \u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconsumed\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    323\u001b[0m         \u001b[0;31m# keep undecoded input until the next call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mconsumed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0x81 in position 10: invalid start byte"
     ]
    }
   ],
   "source": [
    "reader = csv.reader(open('../data/ast_trees/asts.csv.bz2'))\n",
    "\n",
    "next(reader)\n",
    "\n",
    "TreePlotter.plot_tree(JsonImporter().import_(next(reader)[1]), 'first_tree.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        trees = []\n",
    "        offset = 0\n",
    "        counter = TreeNodeCounter()\n",
    "                \n",
    "        # Build tree by tree in batch\n",
    "        for index, z in enumerate(inp_batch):\n",
    "            # Initialize hidden_parent values\n",
    "            hidden_parent = (z.unsqueeze(0), torch.zeros(self.latent_size).unsqueeze(0).to(device))\n",
    "          \n",
    "            if self.training:\n",
    "                tree_size = target['tree_sizes'][index]\n",
    "                \n",
    "                adjacency_list_tree = batch['adjacency_list'][(batch['adjacency_list'][:,0] >= offset) & (batch['adjacency_list'][:,0] < offset + tree_size)]\n",
    "                                \n",
    "                tree, counter = self.build_tree(hidden_parent, None, output, None, counter, target['features'], adjacency_list_tree, node_index=offset)\n",
    "                offset += tree_size\n",
    "            else:\n",
    "                tree, counter = self.build_tree(hidden_parent, None, output, None, counter)\n",
    "                \n",
    "            trees.append(tree)\n",
    "            counter.increase()\n",
    "                            \n",
    "        return trees, output\n",
    "            \n",
    "        \n",
    "    def build_tree(self, hidden_parent, hidden_sibling, output, parent_node=None, index=0,\n",
    "                   features=None, adjacency_list=None, siblings=[], node_index=0):\n",
    "                \n",
    "        # Split hidden parent, into state and cell\n",
    "        hidden_state_parent, hidden_cell_parent = hidden_parent      \n",
    "        # Run hidden parent state through U_parent\n",
    "        U_parent = self.U_parent(hidden_state_parent)\n",
    "        \n",
    "        # If there was a previous sibling, calculate U_sibling, otherwise use 0 to not include this value\n",
    "        if hidden_sibling is not None:\n",
    "            hidden_state_sibling, hidden_cell_sibling = hidden_sibling\n",
    "            U_sibling = self.U_sibling(hidden_state_sibling)\n",
    "        else:\n",
    "            U_sibling = 0\n",
    "        \n",
    "        # tanh(U_parent + U_sibling)\n",
    "        h_pred = torch.tanh(U_parent + U_sibling)\n",
    "        label_pred = self.label_prediction(h_pred)\n",
    "        \n",
    "        # Probability of the node having children\n",
    "        p_parent = self.sigmoid(self.depth_pred(h_pred))\n",
    "        # Probability of the node having successor children\n",
    "        p_sibling = self.sigmoid(self.width_pred(h_pred))\n",
    "        \n",
    "        # Teacher forcing on is_parent, has_sibling\n",
    "        if self.training:\n",
    "            label, child_indices = self.get_truth_values(features, adjacency_list, node_index)\n",
    "            is_parent = torch.tensor([1], device=device, dtype=torch.float32) if len(child_indices) > 0 else torch.tensor([0], device=device, dtype=torch.float32)\n",
    "            has_sibling = torch.tensor([1], device=device, dtype=torch.float32) if len(siblings) > 1 else torch.tensor([0], device=device, dtype=torch.float32)\n",
    "        else:\n",
    "            # Sample is_parent and has_sibling from predicted probability of parent/sibling\n",
    "            is_parent = torch.distributions.bernoulli.Bernoulli(p_parent).sample()\n",
    "            has_sibling = torch.distributions.bernoulli.Bernoulli(p_sibling).sample()\n",
    "            \n",
    "            # Could also simply use > 0.5 instead OR TODO BEAM SEARCH\n",
    "            # is_parent = torch.tensor(1) if p_parent > 0.5 else torch.tensor(0)\n",
    "            # has_sibling = torch.tensor(1) if p_sibling > 0.5 else torch.tensor(0)\n",
    "            \n",
    "        \n",
    "        # Node label prediction\n",
    "        predicted_label = self.softmax(label_pred + self.offset_parent(is_parent) + self.offset_sibling(has_sibling))\n",
    "        \n",
    "        # Build tree: Add node to tree\n",
    "        if parent_node is None:\n",
    "            node = Node(torch.argmax(predicted_label, dim=-1), parent=None)\n",
    "        else:\n",
    "            node = Node(torch.argmax(predicted_label, dim=-1), parent=parent_node)\n",
    "            \n",
    "        # For computing loss, save output (predictions and true values)\n",
    "        output['predicted_labels'][index.get()] = predicted_label\n",
    "        output['labels'][index.get()] = label\n",
    "        output['predicted_has_siblings'][index.get()] = p_sibling\n",
    "        output['has_siblings'][index.get()] = has_sibling\n",
    "        output['predicted_is_parent'][index.get()] = p_parent\n",
    "        output['is_parent'][index.get()] = is_parent\n",
    "            \n",
    "        \n",
    "        # Teacher forcing on label\n",
    "        if self.training:\n",
    "            label = F.one_hot(label.long(), self.vocab_size).float()\n",
    "        else:\n",
    "            label = predicted_label\n",
    "            \n",
    "        \n",
    "        if has_sibling:\n",
    "            index.increase()\n",
    "            if hidden_sibling is not None:\n",
    "                hidden_sibling = self.lstm_sibling(label, hidden_sibling)\n",
    "            else:\n",
    "                hidden_sibling = self.lstm_sibling(label)\n",
    "            \n",
    "            if self.training:\n",
    "                siblings.pop(0)\n",
    "                self.build_tree(hidden_parent, hidden_sibling, output, parent_node, index, features, adjacency_list, siblings, siblings[0])\n",
    "                \n",
    "            else:\n",
    "                self.build_tree(hidden_parent, hidden_sibling, output, parent_node, index)\n",
    "            \n",
    "        if is_parent:\n",
    "            index.increase()\n",
    "            hidden_parent = self.lstm_parent(label, hidden_parent)\n",
    "            parent_node = node\n",
    "            \n",
    "            if self.training:\n",
    "                siblings = list(child_indices)\n",
    "                self.build_tree(hidden_parent, None, output, parent_node, index, features, adjacency_list, siblings, siblings[0])\n",
    "                \n",
    "            else:\n",
    "                self.build_tree(hidden_parent, None, output, parent_node, index)\n",
    "                \n",
    "        return parent_node, index\n",
    "        \n",
    "        \n",
    "    def get_truth_values(self, features, adjacency_list, index):\n",
    "        adjacency_list_current = adjacency_list[adjacency_list[:, 0] == index]\n",
    "\n",
    "        x = features[index, :]\n",
    "        child_indices = adjacency_list_current[:, 1]\n",
    "\n",
    "        return x, child_indices\n",
    "    \n",
    "    \n",
    "class TreeNodeCounter:\n",
    "    def __init__(self):\n",
    "        self.counter = 0\n",
    "        \n",
    "    def increase(self):\n",
    "        self.counter += 1\n",
    "    \n",
    "    def get(self):\n",
    "        return self.counter\n",
    "    \n",
    "    def reset(self):\n",
    "        self.counter = 0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
